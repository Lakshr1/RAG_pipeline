{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111eb4c7",
   "metadata": {},
   "source": [
    "### RAG Pipelines- Data Ingestion to Vector DB Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36c3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc034b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PDF files to process\n",
      "\n",
      "Processing: attention-is-all-you-need.pdf\n",
      "✅ Loaded 15 pages\n",
      "\n",
      "Processing: ray-distributed-framework-AI-app.pdf\n",
      "✅ Loaded 17 pages\n",
      "\n",
      "Processing: scaling-transformer-based-synthesis-models-token-disentanglement.pdf\n",
      "✅ Loaded 21 pages\n",
      "\n",
      "Total documents loaded: 53\n"
     ]
    }
   ],
   "source": [
    "### Read all the pdf's inside the directory\n",
    "\n",
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Procees all PDF files in a directory\"\"\"\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    # Find all PDF files recursively\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"Found {len(pdf_files)} PDF files to process\")\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
    "\n",
    "        try:\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file'] = pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "\n",
    "            all_documents.extend(documents)\n",
    "            print(f\"✅ Loaded {len(documents)} pages\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}\") \n",
    "\n",
    "    print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "    return all_documents\n",
    "\n",
    "#Process all PDFs in the data directory\n",
    "all_pdf_documents = process_all_pdfs (\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c242f706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV\\ni ∈ Rdmodel×dv\\nand WO ∈ Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.8 2.3 · 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Ray: A Distributed Framework for Emerging AI Applications\\nPhilipp Moritz∗, Robert Nishihara ∗, Stephanie Wang, Alexey Tumanov, Richard Liaw,\\nEric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, Ion Stoica\\nUniversity of California, Berkeley\\nAbstract\\nThe next generation of AI applications will continuously\\ninteract with the environment and learn from these inter-\\nactions. These applications impose new and demanding\\nsystems requirements, both in terms of performance and\\nﬂexibility. In this paper, we consider these requirements\\nand present Ray—a distributed system to address them.\\nRay implements a uniﬁed interface that can express both\\ntask-parallel and actor-based computations, supported by\\na single dynamic execution engine. To meet the perfor-\\nmance requirements, Ray employs a distributed scheduler\\nand a distributed and fault-tolerant store to manage the\\nsystem’s control state. In our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and\\nbetter performance than existing specialized systems for\\nseveral challenging reinforcement learning applications.\\n1 Introduction\\nOver the past two decades, many organizations have been\\ncollecting—and aiming to exploit—ever-growing quanti-\\nties of data. This has led to the development of a plethora\\nof frameworks for distributed data analysis, including\\nbatch [20, 64, 28], streaming [15, 39, 31], and graph [34,\\n35, 24] processing systems. The success of these frame-\\nworks has made it possible for organizations to analyze\\nlarge data sets as a core part of their business or scientiﬁc\\nstrategy, and has ushered in the age of “Big Data. ”\\nMore recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (AI) or machine learning (ML) techniques [30].\\nThe paradigm case is that of supervised learning, where\\ndata points are accompanied by labels, and where the\\nworkhorse technology for mapping data points to labels\\nis provided by deep neural networks. The complexity of\\nthese deep networks has led to another ﬂurry of frame-\\nworks that focus on the training of deep neural networks\\n∗equal contribution\\nand their use in prediction. These frameworks often lever-\\nage specialized hardware (e.g., GPUs and TPUs), with the\\ngoal of reducing training time in a batch setting. Examples\\ninclude TensorFlow [7], MXNet [18], and PyTorch [46].\\nThe promise of AI is, however, far broader than classi-\\ncal supervised learning. Emerging AI applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-\\ntions to accomplish long-term goals [8, 43]. They must\\naim not only to exploit the data gathered, but also to ex-\\nplore the space of possible actions. These broader require-\\nments are naturally framed within the paradigm of rein-\\nforcement learning (RL). RL deals with learning to oper-\\nate continuously within an uncertain environment based\\non delayed and limited feedback [56]. RL-based systems\\nhave already yielded remarkable results, such as Google’s\\nAlphaGo beating a human world champion [54], and are\\nbeginning to ﬁnd their way into dialogue systems, UA Vs\\n[42], and robotic manipulation [25, 60].\\nThe central goal of an RL application is to learn a\\npolicy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. Finding ef-\\nfective policies in large-scale applications requires three\\nmain capabilities. First, RL methods often rely on simula-\\ntion to evaluate policies. Simulations make it possible to\\nexplore many different choices of action sequences and to\\nlearn about the long-term consequences of those choices.\\nSecond, like their supervised learning counterparts, RL al-\\ngorithms need to perform distributed training to improve\\nthe policy based on data generated through simulations or\\ninteractions with the physical environment. Third, poli-\\ncies are intended to provide solutions to control problems,\\nand thus it is necessary to serve the policy in interactive\\nclosed-loop and open-loop control scenarios.\\nThese characteristics drive new systems requirements:\\na system for RL must support ﬁne-grained computations\\n(e.g., rendering actions in milliseconds when interacting\\nwith the real world, and performing vast numbers of sim-\\narXiv:1712.05889v2  [cs.DC]  30 Sep 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ulations), must support heterogeneity both in time (e.g.,\\na simulation may take milliseconds or hours) and in re-\\nsource usage (e.g., GPUs for training and CPUs for simu-\\nlations), and must support dynamic execution, as results\\nof simulations or interactions with the environment can\\nchange future computations. Thus, we need a dynamic\\ncomputation framework that handles millions of hetero-\\ngeneous tasks per second at millisecond-level latencies.\\nExisting frameworks that have been developed for\\nBig Data workloads or for supervised learning work-\\nloads fall short of satisfying these new requirements for\\nRL. Bulk-synchronous parallel systems such as Map-\\nReduce [20], Apache Spark [64], and Dryad [28] do not\\nsupport ﬁne-grained simulation or policy serving. Task-\\nparallel systems such as CIEL [40] and Dask [48] provide\\nlittle support for distributed training and serving. The\\nsame is true for streaming systems such as Naiad [ 39]\\nand Storm [31]. Distributed deep-learning frameworks\\nsuch as TensorFlow [7] and MXNet [18] do not naturally\\nsupport simulation and serving. Finally, model-serving\\nsystems such as TensorFlow Serving [6] and Clipper [19]\\nsupport neither training nor simulation.\\nWhile in principle one could develop an end-to-end so-\\nlution by stitching together several existing systems (e.g.,\\nHorovod [53] for distributed training, Clipper [ 19] for\\nserving, and CIEL [40] for simulation), in practice this ap-\\nproach is untenable due to thetight coupling of these com-\\nponents within applications. As a result, researchers and\\npractitioners today build one-off systems for specialized\\nRL applications [58, 41, 54, 44, 49, 5]. This approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing\\nstandard systems challenges like scheduling, fault toler-\\nance, and data movement onto each application.\\nIn this paper, we propose Ray, a general-purpose\\ncluster-computing framework that enables simulation,\\ntraining, and serving for RL applications. The require-\\nments of these workloads range from lightweight and\\nstateless computations, such as for simulation, to long-\\nrunning and stateful computations, such as for training.\\nTo satisfy these requirements, Ray implements a uniﬁed\\ninterface that can express both task-parallel and actor-\\nbased computations. Tasks enable Ray to efﬁciently and\\ndynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. In contrast, actors enable Ray to efﬁciently\\nsupport stateful computations, such as model training, and\\nexpose shared mutable state to clients, (e.g., a parameter\\nserver). Ray implements the actor and the task abstrac-\\ntions on top of a single dynamic execution engine that is\\nhighly scalable and fault tolerant.\\nTo meet the performance requirements, Ray distributes\\ntwo components that are typically centralized in existing\\nframeworks [64, 28, 40]: (1) the task scheduler and (2) a\\nstate (si+1) \\n(observation)\\nreward (ri+1)\\naction (ai)\\nPolicy \\nimprovement\\n(e.g., SGD)\\ntrajectory: s0, (s1, r1), … , (sn, rn)\\npolicy\\nTraining Serving Simulation\\nPolicy\\nevaluation \\nEnvironment\\nAgent\\nFigure 1: Example of an RL system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. This allows Ray to sched-\\nule millions of tasks per second with millisecond-level\\nlatencies. Furthermore, Ray provides lineage-based fault\\ntolerance for tasks and actors, and replication-based fault\\ntolerance for the metadata store.\\nWhile Ray supports serving, training, and simulation\\nin the context of RL applications, this does not mean that\\nit should be viewed as a replacement for systems that pro-\\nvide solutions for these workloads in other contexts. In\\nparticular, Ray does not aim to substitute for serving sys-\\ntems like Clipper [ 19] and TensorFlow Serving [ 6], as\\nthese systems address a broader set of challenges in de-\\nploying models, including model management, testing,\\nand model composition. Similarly, despite its ﬂexibility,\\nRay is not a substitute for generic data-parallel frame-\\nworks, such as Spark [64], as it currently lacks the rich\\nfunctionality and APIs (e.g., straggler mitigation, query\\noptimization) that these frameworks provide.\\nWe make the following contributions:\\n•We design and build the ﬁrst distributed frame-\\nwork that uniﬁes training, simulation, and serving—\\nnecessary components of emerging RL applications.\\n•To support these workloads, we unify the actor and\\ntask-parallel abstractions on top of a dynamic task\\nexecution engine.\\n•To achieve scalability and fault tolerance, we pro-\\npose a system design principle in which control state\\nis stored in a sharded metadata store and all other\\nsystem components are stateless.\\n•To achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 Motivation and Requirements\\nWe begin by considering the basic components of an RL\\nsystem and ﬂeshing out the key requirements for Ray. As\\nshown in Figure 1, in an RL setting, an agent interacts\\nrepeatedly with the environment. The goal of the agent\\nis to learn a policy that maximizes a reward. A policy is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='// evaluate policyby interacting with env. (e.g., simulator)rollout(policy, environment):trajectory=[]state= environment.initial_state()while(notenvironment.has_terminated()):action= policy.compute(state) // Servingstate,reward= environment.step(action) // Simulationtrajectory.append(state,reward)returntrajectory// improve policy iteratively until it convergestrain_policy(environment):policy= initial_policy()while(policyhas not converged):trajectories = []forifrom1 tok:// evaluate policyby generating krolloutstrajectories.append(rollout(policy, environment))// improve policypolicy= policy.update(trajectories) // Trainingreturnpolicy\\nFigure 2: Typical RL pseudocode for learning a policy.\\na mapping from the state of the environment to a choice\\nof action. The precise deﬁnitions of environment, agent,\\nstate, action, and reward are application-speciﬁc.\\nTo learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement.\\nTo evaluate the policy, the agent interacts with the envi-\\nronment (e.g., with a simulation of the environment) to\\ngenerate trajectories, where a trajectory consists of a se-\\nquence of (state, reward) tuples produced by the current\\npolicy. Then, the agent uses these trajectories to improve\\nthe policy; i.e., to update the policy in the direction of the\\ngradient that maximizes the reward. Figure 2 shows an\\nexample of the pseudocode used by an agent to learn a\\npolicy. This pseudocode evaluates the policy by invok-\\ning rollout(environment, policy) to generate trajectories.\\ntrain policy() then uses these trajectories to improve the\\ncurrent policy via policy.update(trajectories). This pro-\\ncess repeats until the policy converges.\\nThus, a framework for RL applications must provide\\nefﬁcient support for training, serving, and simulation\\n(Figure 1). Next, we brieﬂy describe these workloads.\\nTraining typically involves running stochastic gradient\\ndescent (SGD), often in a distributed setting, to update the\\npolicy. Distributed SGD typically relies on an allreduce\\naggregation step or a parameter server [32].\\nServing uses the trained policy to render an action based\\non the current state of the environment. A serving system\\naims to minimize latency, and maximize the number of\\ndecisions per second. To scale, load is typically balanced\\nacross multiple nodes serving the policy.\\nFinally, most existing RL applications use simulations\\nto evaluate the policy—current RL algorithms are not\\nsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. These simula-\\ntions vary widely in complexity. They might take a few ms\\n(e.g., simulate a move in a chess game) to minutes (e.g.,\\nsimulate a realistic environment for a self-driving car).\\nIn contrast with supervised learning, in which train-\\ning and serving can be handled separately by different\\nsystems, in RL all three of these workloads are tightly\\ncoupled in a single application, with stringent latency re-\\nquirements between them. Currently, no framework sup-\\nports this coupling of workloads. In theory, multiple spe-\\ncialized frameworks could be stitched together to provide\\nthe overall capabilities, but in practice, the resulting data\\nmovement and latency between systems is prohibitive in\\nthe context of RL. As a result, researchers and practition-\\ners have been building their own one-off systems.\\nThis state of affairs calls for the development of new\\ndistributed frameworks for RL that can efﬁciently support\\ntraining, serving, and simulation. In particular, such a\\nframework should satisfy the following requirements:\\nFine-grained, heterogeneous computations. The dura-\\ntion of a computation can range from milliseconds (e.g.,\\ntaking an action) to hours (e.g., training a complex pol-\\nicy). Additionally, training often requires heterogeneous\\nhardware (e.g., CPUs, GPUs, or TPUs).\\nFlexible computation model. RL applications require\\nboth stateless and stateful computations. Stateless compu-\\ntations can be executed on any node in the system, which\\nmakes it easy to achieve load balancing and movement\\nof computation to data, if needed. Thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and\\ndata processing, such as extracting features from images\\nor videos. In contrast stateful computations are a good ﬁt\\nfor implementing parameter servers, performing repeated\\ncomputation on GPU-backed data, or running third-party\\nsimulators that do not expose their state.\\nDynamic execution. Several components of RL appli-\\ncations require dynamic execution, as the order in which\\ncomputations ﬁnish is not always known in advance (e.g.,\\nthe order in which simulations ﬁnish), and the results of a\\ncomputation can determine future computations (e.g., the\\nresults of a simulation will determine whether we need to\\nperform more simulations).\\nWe make two ﬁnal comments. First, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second.∗Second, such a framework\\nis not intended for implementing deep neural networks\\nor complex simulators from scratch. Instead, it should\\nenable seamless integration with existing simulators [13,\\n11, 59] and deep learning frameworks [7, 18, 46, 29].\\n∗Assume 5ms single-core tasks and a cluster of 200 32-core nodes.\\nThis cluster can run (1s/5ms) ×32 ×200 = 1.28M tasks/sec.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Name Description\\nfutures = f.remote(args) Execute function f remotely. f.remote() can take objects or futures as inputs\\nand returns one or more futures. This is non-blocking.\\nobjects = ray.get(futures) Return the values associated with one or more futures. This is blocking.\\nready futures = ray.wait(futures,k,timeout) Return the futures whose corresponding tasks have completed as soon as either\\nk have completed or the timeout expires.\\nactor = Class.remote(args) Instantiate class Class as a remote actor, and return a handle to it. Call a method\\nfutures = actor.method.remote(args) on the remote actor and return one or more futures. Both are non-blocking.\\nTable 1: Ray API\\n3 Programming and Computation Model\\nRay implements a dynamic task graph computation\\nmodel, i.e., it models an application as a graph of depen-\\ndent tasks that evolves during execution. On top of this\\nmodel, Ray provides both an actor and a task-parallel\\nprogramming abstraction. This uniﬁcation differentiates\\nRay from related systems like CIEL, which only pro-\\nvides a task-parallel abstraction, and from Orleans [14] or\\nAkka [1], which primarily provide an actor abstraction.\\n3.1 Programming Model\\nTasks. A task represents the execution of a remote func-\\ntion on a stateless worker. When a remote function is\\ninvoked, a future representing the result of the task is\\nreturned immediately. Futures can be retrieved using\\nray.get() and passed as arguments into other remote func-\\ntions without waiting for their result. This allows the user\\nto express parallelism while capturing data dependencies.\\nTable 1 shows Ray’s API.\\nRemote functions operate on immutable objects and\\nare expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. This implies\\nidempotence, which simpliﬁes fault tolerance through\\nfunction re-execution on failure.\\nActors. An actor represents a stateful computation. Each\\nactor exposes methods that can be invoked remotely and\\nare executed serially. A method execution is similar to a\\ntask, in that it executes remotely and returns a future, but\\ndiffers in that it executes on a stateful worker. A handle\\nto an actor can be passed to other actors or tasks, making\\nit possible for them to invoke methods on that actor.\\nTasks (stateless) Actors (stateful)\\nFine-grained load balancing Coarse-grained load balancing\\nSupport for object locality Poor locality support\\nHigh overhead for small updates Low overhead for small updates\\nEfﬁcient failure handling Overhead from checkpointing\\nTable 2: Tasks vs. actors tradeoffs.\\nTable 2 summarizes the properties of tasks and actors.\\nTasks enable ﬁne-grained load balancing through leverag-\\ning load-aware scheduling at task granularity, input data\\nlocality, as each task can be scheduled on the node stor-\\ning its inputs, and low recovery overhead, as there is no\\nneed to checkpoint and recover intermediate state. In con-\\ntrast, actors provide much more efﬁcient ﬁne-grained up-\\ndates, as these updates are performed on internal rather\\nthan external state, which typically requires serialization\\nand deserialization. For example, actors can be used to\\nimplement parameter servers [32] and GPU-based itera-\\ntive computations (e.g., training). In addition, actors can\\nbe used to wrap third-party simulators and other opaque\\nhandles that are hard to serialize.\\nTo satisfy the requirements for heterogeneity and ﬂex-\\nibility (Section 2), we augment the API in three ways.\\nFirst, to handle concurrent tasks with heterogeneous du-\\nrations, we introduce ray.wait(), which waits for the\\nﬁrst k available results, instead of waiting for all results\\nlike ray.get(). Second, to handle resource-heterogeneous\\ntasks, we enable developers to specify resource require-\\nments so that the Ray scheduler can efﬁciently manage re-\\nsources. Third, to improve ﬂexibility, we enablenested re-\\nmote functions, meaning that remote functions can invoke\\nother remote functions. This is also critical for achiev-\\ning high scalability (Section 4), as it enables multiple pro-\\ncesses to invoke remote functions in a distributed fashion.\\n3.2 Computation Model\\nRay employs a dynamic task graph computation\\nmodel [21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the\\nsystem when their inputs become available. In this sec-\\ntion, we describe how the computation graph (Figure 4) is\\nconstructed from a user program (Figure 3). This program\\nuses the API in Table 1 to implement the pseudocode\\nfrom Figure 2.\\nIgnoring actors ﬁrst, there are two types of nodes in\\na computation graph: data objects and remote function\\ninvocations, or tasks. There are also two types of edges:\\ndata edges and control edges. Data edges capture the de-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='@ray.remote\\ndef create_policy():\\n# Initialize the policy randomly.\\nreturn policy\\n@ray.remote(num_gpus=1)\\nclass Simulator(object):\\ndef __init__(self):\\n# Initialize the environment.\\nself.env = Environment()\\ndef rollout(self, policy, num_steps):\\nobservations = []\\nobservation = self.env.current_state()\\nfor _ in range(num_steps):\\naction = policy(observation)\\nobservation = self.env.step(action)\\nobservations.append(observation)\\nreturn observations\\n@ray.remote(num_gpus=2)\\ndef update_policy(policy, *rollouts):\\n# Update the policy.\\nreturn policy\\n@ray.remote\\ndef train_policy():\\n# Create a policy.\\npolicy_id = create_policy.remote()\\n# Create 10 actors.\\nsimulators = [Simulator.remote() for _ in range(10)]\\n# Do 100 steps of training.\\nfor _ in range(100):\\n# Perform one rollout on each actor.\\nrollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# Update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)\\nFigure 3: Python code implementing the example in Figure 2\\nin Ray. Note that @ray.remote indicates remote functions and\\nactors. Invocations of remote functions and actor methods return\\nfutures, which can be passed to subsequent remote functions or\\nactor methods to encode task dependencies. Each actor has an\\nenvironment object self.env shared between all of its methods.\\npendencies between data objects and tasks. More pre-\\ncisely, if data object D is an output of task T , we add a\\ndata edge from T to D. Similarly, if D is an input to T ,\\nwe add a data edge from D to T . Control edges capture\\nthe computation dependencies that result from nested re-\\nmote functions (Section 3.1): if task T1 invokes task T2,\\nthen we add a control edge from T1 to T2.\\nActor method invocations are also represented as nodes\\nin the computation graph. They are identical to tasks\\nwith one key difference. To capture the state dependency\\nacross subsequent method invocations on the same actor,\\nwe add a third type of edge: a stateful edge. If method\\nMj is called right after method Mi on the same actor,\\nthen we add a stateful edge from Mi to Mj. Thus, all\\npolicy1\\nT1create_policy\\nT2update_policy\\nA11rollout\\nA12rollout policy2\\nT3update_policy\\nrollout11\\nrollout12\\nA21rollout\\nA22rolloutrollout22\\nA10Simulator A20Simulator\\n… ……data\\tedges statefuledgesobject task/methodcontrol\\tedges\\nrollout21\\nT0train_policy\\nFigure 4: The task graph corresponding to an invocation of\\ntrain policy.remote() in Figure 3. Remote function calls and the\\nactor method calls correspond to tasks in the task graph. The\\nﬁgure shows two actors. The method invocations for each actor\\n(the tasks labeled A1i and A2i) have stateful edges between them\\nindicating that they share the mutable actor state. There are con-\\ntrol edges from train policy to the tasks that it invokes. To train\\nmultiple policies in parallel, we could call train policy.remote()\\nmultiple times.\\nmethods invoked on the same actor object form a chain\\nthat is connected by stateful edges (Figure 4). This chain\\ncaptures the order in which these methods were invoked.\\nStateful edges help us embed actors in an otherwise\\nstateless task graph, as they capture the implicit data de-\\npendency between successive method invocations sharing\\nthe internal state of an actor. Stateful edges also enable\\nus to maintain lineage. As in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. By explic-\\nitly including stateful edges in the lineage graph, we can\\neasily reconstruct lost data, whether produced by remote\\nfunctions or actor methods (Section 4.2.3).\\n4 Architecture\\nRay’s architecture comprises (1) an application layer im-\\nplementing the API, and (2) a system layer providing high\\nscalability and fault tolerance.\\n4.1 Application Layer\\nThe application layer consists of three types of processes:\\n•Driver: A process executing the user program.\\n•Worker: A stateless process that executes tasks\\n(remote functions) invoked by a driver or another'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Local Scheduler\\nActorDriver\\nObject Store\\nGlobal SchedulerGlobal Scheduler\\nObject TableTask TableFunction TableEvent Logs\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nDriverWorker\\nObject Store\\nNode\\nGlobal Scheduler\\nWeb UIDebugging ToolsProfiling Tools\\nError Diagnosis\\nLocal Scheduler\\nWorkerWorker\\nObject Store\\nNode Node\\nApp LayerSystem Layer (backend)\\nFigure 5: Ray’s architecture consists of two parts: anapplica-\\ntion layer and a system layer. The application layer implements\\nthe API and the computation model described in Section 3, the\\nsystem layer implements task scheduling and data management\\nto satisfy the performance and fault-tolerance requirements.\\nworker. Workers are started automatically and as-\\nsigned tasks by the system layer. When a remote\\nfunction is declared, the function is automatically\\npublished to all workers. A worker executes tasks\\nserially, with no local state maintained across tasks.\\n•Actor: A stateful process that executes, when in-\\nvoked, only the methods it exposes. Unlike a worker,\\nan actor is explicitly instantiated by a worker or a\\ndriver. Like workers, actors execute methods seri-\\nally, except that each method depends on the state\\nresulting from the previous method execution.\\n4.2 System Layer\\nThe system layer consists of three major components: a\\nglobal control store, a distributed scheduler, and a dis-\\ntributed object store. All components are horizontally\\nscalable and fault-tolerant.\\n4.2.1 Global Control Store (GCS)\\nThe global control store (GCS) maintains the entire con-\\ntrol state of the system, and it is a unique feature of our\\ndesign. At its core, GCS is a key-value store with pub-\\nsub functionality. We use sharding to achieve scale, and\\nper-shard chain replication [61] to provide fault tolerance.\\nThe primary reason for the GCS and its design is to main-\\ntain fault tolerance and low latency for a system that can\\ndynamically spawn millions of tasks per second.\\nFault tolerance in case of node failure requires a solu-\\ntion to maintain lineage information. Existing lineage-\\nbased solutions [64, 63, 40, 28] focus on coarse-grained\\nparallelism and can therefore use a single node (e.g., mas-\\nter, driver) to store the lineage without impacting perfor-\\nmance. However, this design is not scalable for a ﬁne-\\ngrained and dynamic workload like simulation. Therefore,\\nwe decouple the durable lineage storage from the other\\nsystem components, allowing each to scale independently.\\nMaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where\\nto execute, and subsequently task dispatch, which in-\\nvolves retrieving remote inputs from other nodes. Many\\nexisting dataﬂow systems [ 64, 40, 48] couple these by\\nstoring object locations and sizes in a centralized sched-\\nuler, a natural design when the scheduler is not a bottle-\\nneck. However, the scale and granularity that Ray targets\\nrequires keeping the centralized scheduler off the critical\\npath. Involving the scheduler in each object transfer is pro-\\nhibitively expensive for primitives important to distributed\\ntraining like allreduce, which is both communication-\\nintensive and latency-sensitive. Therefore, we store the\\nobject metadata in the GCS rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nIn summary, the GCS signiﬁcantly simpliﬁes Ray’s\\noverall design, as it enables every component in the sys-\\ntem to be stateless. This not only simpliﬁes support for\\nfault tolerance (i.e., on failure, components simply restart\\nand read the lineage from the GCS), but also makes it\\neasy to scale the distributed object store and scheduler in-\\ndependently, as all components share the needed state via\\nthe GCS. An added beneﬁt is the easy development of de-\\nbugging, proﬁling, and visualization tools.\\n4.2.2 Bottom-Up Distributed Scheduler\\nAs discussed in Section 2, Ray needs to dynamically\\nschedule millions of tasks per second, tasks which may\\ntake as little as a few milliseconds. None of the clus-\\nter schedulers we are aware of meet these requirements.\\nMost cluster computing frameworks, such as Spark [64],\\nCIEL [40], and Dryad [28] implement a centralized sched-\\nuler, which can provide locality but at latencies in the tens\\nof ms. Distributed schedulers such as work stealing [12],\\nSparrow [45] and Canary [47] can achieve high scale, but\\nthey either don’t consider data locality [12], or assume\\ntasks belong to independent jobs [45], or assume the com-\\nputation graph is known [47].\\nTo satisfy the above requirements, we design a two-\\nlevel hierarchical scheduler consisting of a global sched-\\nuler and per-node local schedulers. To avoid overloading\\nthe global scheduler, the tasks created at a node are sub-\\nmitted ﬁrst to the node’s local scheduler. A local sched-\\nuler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a\\nGPU). If a local scheduler decides not to schedule a task\\nlocally, it forwards it to the global scheduler. Since this\\nscheduler attempts to schedule tasks locally ﬁrst (i.e., at\\nthe leaves of the scheduling hierarchy), we call it abottom-\\nup scheduler.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Global Scheduler\\nLocal Scheduler\\nGlobal Scheduler\\nWorkerDriverWorker…\\nGlobal Control        State (GCS)\\nLocal Scheduler\\nWorkerWorkerWorker\\nSubmit tasksSchedule tasksLoadinfo\\nNode 1 Node N\\nFigure 6: Bottom-up distributed scheduler. Tasks are submitted\\nbottom-up, from drivers and workers to a local scheduler and\\nforwarded to the global scheduler only if needed (Section 4.2.2).\\nThe thickness of each arrow is proportional to its request rate.\\nThe global scheduler considers each node’s load and\\ntask’s constraints to make scheduling decisions. More pre-\\ncisely, the global scheduler identiﬁes the set of nodes that\\nhave enough resources of the type requested by the task,\\nand of these nodes selects the node which provides the\\nlowest estimated waiting time. At a given node, this time\\nis the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s\\nremote inputs (i.e., total size of remote inputs divided by\\naverage bandwidth). The global scheduler gets the queue\\nsize at each node and the node resource availability via\\nheartbeats, and the location of the task’s inputs and their\\nsizes from GCS. Furthermore, the global scheduler com-\\nputes the average task execution and the average transfer\\nbandwidth using simple exponential averaging. If the\\nglobal scheduler becomes a bottleneck, we can instantiate\\nmore replicas all sharing the same information via GCS.\\nThis makes our scheduler architecture highly scalable.\\n4.2.3 In-Memory Distributed Object Store\\nTo minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. On each node, we\\nimplement the object store via shared memory. This al-\\nlows zero-copy data sharing between tasks running on the\\nsame node. As a data format, we use Apache Arrow [2].\\nIf a task’s inputs are not local, the inputs are replicated\\nto the local object store before execution. Also, a task\\nwrites its outputs to the local object store. Replication\\neliminates the potential bottleneck due to hot data ob-\\njects and minimizes task execution time as a task only\\nreads/writes data from/to the local memory. This in-\\ncreases throughput for computation-bound workloads, a\\nproﬁle shared by many AI applications. For low latency,\\nwe keep objects entirely in memory and evict them as\\nneeded to disk using an LRU policy.\\nAs with existing cluster computing frameworks, such\\nas Spark [64], and Dryad [28], the object store is limited\\nto immutable data. This obviates the need for complex\\nconsistency protocols (as objects are not updated), and\\nsimpliﬁes support for fault tolerance. In the case of node\\nfailure, Ray recovers any needed objects through lineage\\nre-execution. The lineage stored in the GCS tracks both\\nstateless tasks and stateful actors during initial execution;\\nwe use the former to reconstruct objects in the store.\\nFor simplicity, our object store does not support dis-\\ntributed objects, i.e., each object ﬁts on a single node. Dis-\\ntributed objects like large matrices or trees can be imple-\\nmented at the application level as collections of futures.\\n4.2.4 Implementation\\nRay is an active open source project†developed at the Uni-\\nversity of California, Berkeley. Ray fully integrates with\\nthe Python environment and is easy to install by simply\\nrunning pip install ray. The implementation com-\\nprises ≈ 40K lines of code (LoC), 72% in C++ for the\\nsystem layer, 28% in Python for the application layer. The\\nGCS uses one Redis [50] key-value store per shard, with\\nentirely single-key operations. GCS tables are sharded\\nby object and task IDs to scale, and every shard is chain-\\nreplicated [61] for fault tolerance. We implement both\\nthe local and global schedulers as event-driven, single-\\nthreaded processes. Internally, local schedulers maintain\\ncached state for local object metadata, tasks waiting for\\ninputs, and tasks ready for dispatch to a worker. To trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple TCP connections.\\n4.3 Putting Everything Together\\nFigure 7 illustrates how Ray works end-to-end with a\\nsimple example that adds two objects a and b, which\\ncould be scalars or matrices, and returns result c. The\\nremote function add() is automatically registered with the\\nGCS upon initialization and distributed to every worker\\nin the system (step 0 in Figure 7a).\\nFigure 7a shows the step-by-step operations triggered\\nby a driver invoking add.remote(a,b), where a and b are\\nstored on nodes N1 and N2, respectively. The driver sub-\\nmits add(a, b) to the local scheduler (step 1), which for-\\nwards it to a global scheduler (step 2).‡Next, the global\\nscheduler looks up the locations of add(a, b)’s arguments\\nin the GCS (step 3) and decides to schedule the task on\\nnode N2, which stores argument b (step 4). The local\\nscheduler at node N2 checks whether the local object\\nstore contains add(a, b)’s arguments (step 5). Since the\\n†https://github.com/ray-project/ray\\n‡Note that N1 could also decide to schedule the task locally.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Object store\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\n45\\n6\\nLocal Scheduler\\nObject store\\nidaa1\\n2\\n8\\nGlobal Scheduler\\n7\\n9\\nidaaidbb\\n0\\n3 Local Scheduler\\n(a) Executing a task remotely\\nLocal Scheduler\\nidbb\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nidaa1 idaaidcc idc N2, N14257 3\\nGlobal Scheduler\\nidcc6\\n(b) Returning the result of a remote task\\nFigure 7: An end-to-end example that adds a and b and returns\\nc. Solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) The function add() is registered\\nwith the GCS by node 1 ( N1), invoked on N1, and executed\\non N2. (b) N1 gets add()’s result usingray.get(). The Object\\nTable entry for c is created in step 4 and updated in step 6 after\\nc is copied to N1.\\nlocal store doesn’t have objecta, it looks up a’s location\\nin the GCS (step 6). Learning that a is stored at N1, N2’s\\nobject store replicates it locally (step 7). As all arguments\\nof add() are now stored locally, the local scheduler in-\\nvokes add() at a local worker (step 8), which accesses the\\narguments via shared memory (step 9).\\nFigure 7b shows the step-by-step operations triggered\\nby the execution of ray.get() at N1, and of add() at N2,\\nrespectively. Upon ray.get(idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idc returned by add() (step 1). Since the local\\nobject store doesn’t storec, it looks up its location in the\\nGCS. At this time, there is no entry for c, as c has not\\nbeen created yet. As a result, N1’s object store registers a\\ncallback with the Object Table to be triggered when c’s\\nentry has been created (step 2). Meanwhile, at N2, add()\\ncompletes its execution, stores the result c in the local\\nobject store (step 3), which in turn adds c’s entry to the\\nGCS (step 4). As a result, the GCS triggers a callback\\nto N1’s object store with c’s entry (step 5). Next, N1\\nreplicates c from N2 (step 6), and returns c to ray.get()\\n(step 7), which ﬁnally completes the task.\\nWhile this example involves a large number of RPCs,\\n100KB 1MB 10MB 100MB\\nObject size\\n10-5\\n10-4\\n10-3\\n10-2\\n10-1\\nMean task latency (s)\\nLocality Aware\\nUnaware\\n(a) Ray locality scheduling\\n10 20 30 40 50 60 100\\nnumber of nodes\\n0.0\\n0.4\\n0.8\\n1.2\\n1.6Millions of tasks/s (b) Ray scalability\\nFigure 8: (a) Tasks leverage locality-aware placement. 1000\\ntasks with a random object dependency are scheduled onto one\\nof two nodes. With locality-aware policy, task latency remains\\nindependent of the size of task inputs instead of growing by 1-2\\norders of magnitude. (b) Near-linear scalability leveraging the\\nGCS and bottom-up distributed scheduler. Ray reaches 1 million\\ntasks per second throughput with 60 nodes. x ∈{70,80,90}\\nomitted due to cost.\\nin many cases this number is much smaller, as most tasks\\nare scheduled locally, and the GCS replies are cached by\\nthe global and local schedulers.\\n5 Evaluation\\nIn our evaluation, we study the following questions:\\n1. How well does Ray meet the latency, scalability,\\nand fault tolerance requirements listed in Section 2?\\n(Section 5.1)\\n2. What overheads are imposed on distributed primi-\\ntives (e.g., allreduce) written using Ray’s API? (Sec-\\ntion 5.1)\\n3. In the context of RL workloads, how does Ray com-\\npare against specialized systems for training, serv-\\ning, and simulation? (Section 5.2)\\n4. What advantages does Ray provide for RL applica-\\ntions, compared to custom systems? (Section 5.3)\\nAll experiments were run on Amazon Web Services.\\nUnless otherwise stated, we use m4.16xlarge CPU in-\\nstances and p3.16xlarge GPU instances.\\n5.1 Microbenchmarks\\nLocality-aware task placement. Fine-grain load bal-\\nancing and locality-aware placement are primary beneﬁts\\nof tasks in Ray. Actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.\\nIn Figure 8a, tasks placed without data locality awareness\\n(as is the case for actor methods), suffer 1-2 orders of\\nmagnitude latency increase at 10-100MB input data sizes.\\nRay uniﬁes tasks and actors through the shared object\\nstore, allowing developers to use tasks for e.g., expensive\\npostprocessing on output produced by simulation actors.\\nEnd-to-end scalability. One of the key beneﬁts of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='1KB 10KB100KB 1MB 10MB100MB 1GB\\nobject size\\n0\\n5000\\n10000\\n15000\\n20000IOPS\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\nthroughput (GB/s)\\nFigure 9: Object store write throughput and IOPS. From a\\nsingle client, throughput exceeds 15GB/s (red) for large objects\\nand 18K IOPS (cyan) for small objects on a 16 core instance\\n(m4.4xlarge). It uses 8 threads to copy objects larger than 0.5MB\\nand 1 thread for small objects. Bar plots report throughput with\\n1, 2, 4, 8, 16 threads. Results are averaged over 5 runs.\\nthe Global Control Store (GCS) and the bottom-up dis-\\ntributed scheduler is the ability to horizontally scale the\\nsystem to support a high throughput of ﬁne-grained tasks,\\nwhile maintaining fault tolerance and low-latency task\\nscheduling. In Figure 8b, we evaluate this ability on an\\nembarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. We observe near-perfect\\nlinearity in progressively increasing task throughput. Ray\\nexceeds 1 million tasks per second throughput at 60 nodes\\nand continues to scale linearly beyond 1.8 million tasks\\nper second at 100 nodes. The rightmost datapoint shows\\nthat Ray can process 100 million tasks in less than a\\nminute (54s), with minimum variability. As expected, in-\\ncreasing task duration reduces throughput proportionally\\nto mean task duration, but the overall scalability remains\\nlinear. While many realistic workloads may exhibit more\\nlimited scalability due to object dependencies and inher-\\nent limits to application parallelism, this demonstrates the\\nscalability of our overall architecture under high load.\\nObject store performance. To evaluate the perfor-\\nmance of the object store (Section 4.2.3), we track two\\nmetrics: IOPS (for small objects) and write throughput\\n(for large objects). In Figure 9, the write throughput from\\na single client exceeds 15GB/s as object size increases.\\nFor larger objects, memcpy dominates object creation\\ntime. For smaller objects, the main overheads are in seri-\\nalization and IPC between the client and object store.\\nGCS fault tolerance. To maintain low latency while\\nproviding strong consistency and fault tolerance, we build\\na lightweight chain replication [61] layer on top of Redis.\\nFigure 10a simulates recording Ray tasks to and reading\\ntasks from the GCS, where keys are 25 bytes and values\\nare 512 bytes. The client sends requests as fast as it can,\\nhaving at most one in-ﬂight request at a time. Failures are\\nreported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10\\nTime since start (s)\\n103 103\\n104 104\\nLatency (μs) write\\nread\\nnode dead\\n(a) A timeline for GCS read and write latencies as viewed from\\na client submitting tasks. The chain starts with 2 replicas. We\\nmanually trigger reconﬁguration as follows. At t ≈4.2s, a chain\\nmember is killed; immediately after, a new chain member joins,\\ninitiates state transfer, and restores the chain to 2-way replication.\\nThe maximum client-observed latency is under 30ms despite\\nreconﬁgurations.\\n0 10000 20000 30000 40000 50000 60000\\nElasped Time (seconds)\\n0\\n2000\\n4000\\n6000\\n8000GCS Used Memory (MB)\\n50 million no-op tasks\\nRay, no GCS flush\\nRay, GCS flush\\n(b) The Ray GCS maintains a constant memory footprint with\\nGCS ﬂushing. Without GCS ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete\\nwithin a predetermined duration (indicated by the red cross).\\nFigure 10: Ray GCS fault tolerance and ﬂushing.\\nfrom any server in the chain (having received explicit\\nerrors). Overall, reconﬁgurations caused a maximum\\nclient-observed delay of under 30ms (this includes both\\nfailure detection and recovery delays).\\nGCS ﬂushing. Ray is equipped to periodically ﬂush\\nthe contents of GCS to disk. In Figure 10b we submit 50\\nmillion empty tasks sequentially and monitor GCS mem-\\nory consumption. As expected, it grows linearly with the\\nnumber of tasks tracked and eventually reaches the mem-\\nory capacity of the system. At that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. With periodic GCS ﬂushing, we\\nachieve two goals. First, the memory footprint is capped\\nat a user-conﬁgurable level (in the microbenchmark we\\nemploy an aggressive strategy where consumed memory\\nis kept as low as possible). Second, the ﬂushing mecha-\\nnism provides a natural way to snapshot lineage to disk\\nfor long-running Ray applications.\\nRecovering from task failures. In Figure 11a, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='0 50 100 150 200\\nTime since start (s)\\n0\\n500\\n1000\\n1500\\n2000Throughput (tasks/s)\\n0\\n20\\n40\\n60\\nNumber of nodes\\nOriginal tasks\\nRe-executed tasks\\n(a) Task reconstruction\\n100 200 300 400 500 600\\nTime since start (s)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700Throughput (tasks/s)\\nOriginal tasks\\nRe-executed tasks\\nCheckpoint tasks\\n(b) Actor reconstruction\\nFigure 11: Ray fault-tolerance. (a) Ray reconstructs lost task\\ndependencies as nodes are removed (dotted line), and recovers\\nto original throughput when nodes are added back. Each task\\nis 100ms and depends on an object generated by a previously\\nsubmitted task. (b) Actors are reconstructed from their last\\ncheckpoint. At t = 200s, we kill 2 of the 10 nodes, causing 400\\nof the 2000 actors in the cluster to be recovered on the remaining\\nnodes (t = 200–270s).\\ndemonstrate Ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable GCS lineage storage. The workload, run on\\nm4.xlarge instances, consists of linear chains of 100ms\\ntasks submitted by the driver. As nodes are removed (at\\n25s, 50s, 100s), the local schedulers reconstruct previous\\nresults in the chain in order to continue execution. Over-\\nall per-node throughput remains stable throughout.\\nRecovering from actor failures. By encoding actor\\nmethod calls as stateful edges directly in the dependency\\ngraph, we can reuse the same object reconstruction mech-\\nanism as in Figure 11a to provide transparent fault tol-\\nerance for stateful computation. Ray additionally lever-\\nages user-deﬁned checkpoint functions to bound the re-\\nconstruction time for actors (Figure 11b). With minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-\\ning. In the future, we hope to further reduce actor recon-\\nstruction time, e.g., by allowing users to annotate meth-\\nods that do not mutate state.\\nAllreduce. Allreduce is a distributed communication\\n10MB 100MB 1GB\\nObject size\\n100\\n101\\n102\\n103\\n104\\nIteration time (milliseconds)\\nOpenMPI\\nRay*\\nRay\\n(a) Ray vs OpenMPI\\n+0 +1 +5 +10\\nAdded scheduler latency (ms)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700\\n800Iteration time (milliseconds)\\nRay ring reduce latency\\n(16 nodes, 100MB) (b) Ray scheduler ablation\\nFigure 12: (a) Mean execution time of allreduce on 16 m4.16xl\\nnodes. Each worker runs on a distinct node. Ray* restricts Ray\\nto 1 thread for sending and 1 thread for receiving. (b) Ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.\\nHere, we evaluate whether Ray can natively support a\\nring allreduce [57] implementation with low enough over-\\nhead to match existing implementations [53]. We ﬁnd that\\nRay completes allreduce across 16 nodes on 100MB in\\n∼200ms and 1GB in ∼1200ms, surprisingly outperform-\\ning OpenMPI (v1.10), a popular MPI implementation,\\nby 1.5×and 2×respectively (Figure 12a). We attribute\\nRay’s performance to its use of multiple threads for net-\\nwork transfers, taking full advantage of the 25Gbps con-\\nnection between nodes on AWS, whereas OpenMPI se-\\nquentially sends and receives data on a single thread [22].\\nFor smaller objects, OpenMPI outperforms Ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nRay’s scheduler performance is critical to implement-\\ning primitives such as allreduce. In Figure 12b, we inject\\nartiﬁcial task execution delays and show that performance\\ndrops nearly 2×with just a few ms of extra latency. Sys-\\ntems with centralized schedulers like Spark and CIEL typ-\\nically have scheduler overheads in the tens of millisec-\\nonds [62, 38], making such workloads impractical. Sched-\\nuler throughput also becomes a bottleneck since the num-\\nber of tasks required by ring reduce scales quadratically\\nwith the number of participants.\\n5.2 Building blocks\\nEnd-to-end applications (e.g., AlphaGo [ 54]) require a\\ntight coupling of training, serving, and simulation. In this\\nsection, we isolate each of these workloads to a setting\\nthat illustrates a typical RL application’s requirements.\\nDue to a ﬂexible programming model targeted to RL, and\\na system designed to support this programming model,\\nRay matches and sometimes exceeds the performance of\\ndedicated systems for these individual workloads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='4 8 16 32 64\\nNum GPUs (V100)\\n0\\n1000\\n2000\\n3000\\n4000\\n5000\\n6000\\n7000Mean images / s\\nHorovod + TF\\nDistributed TF\\nRay + TF\\nFigure 13: Images per second reached when distributing the\\ntraining of a ResNet-101 TensorFlow model (from the ofﬁcial\\nTF benchmark). All experiments were run on p3.16xl instances\\nconnected by 25Gbps Ethernet, and workers allocated 4 GPUs\\nper node as done in Horovod [53]. We note some measurement\\ndeviations from previously reported, likely due to hardware\\ndifferences and recent TensorFlow performance improvements.\\nWe used OpenMPI 3.0, TF 1.8, and NCCL2 for all runs.\\n5.2.1 Distributed Training\\nWe implement data-parallel synchronous SGD leverag-\\ning the Ray actor abstraction to represent model replicas.\\nModel weights are synchronized via allreduce (5.1) or pa-\\nrameter server, both implemented on top of the Ray API.\\nIn Figure 13, we evaluate the performance of the\\nRay (synchronous) parameter-server SGD implementa-\\ntion against state-of-the-art implementations [ 53], us-\\ning the same TensorFlow model and synthetic data gen-\\nerator for each experiment. We compare only against\\nTensorFlow-based systems to accurately measure the over-\\nhead imposed by Ray, rather than differences between the\\ndeep learning frameworks themselves. In each iteration,\\nmodel replica actors compute gradients in parallel, send\\nthe gradients to a sharded parameter server, then read the\\nsummed gradients from the parameter server for the next\\niteration.\\nFigure 13 shows that Ray matches the performance of\\nHorovod and is within 10% of distributed TensorFlow\\n(in distributed replicated mode). This is due to\\nthe ability to express the same application-level optimiza-\\ntions found in these specialized systems in Ray’s general-\\npurpose API. A key optimization is the pipelining of gra-\\ndient computation, transfer, and summation within a sin-\\ngle iteration. To overlap GPU computation with network\\ntransfer, we use a custom TensorFlow operator to write\\ntensors directly to Ray’s object store.\\n5.2.2 Serving\\nModel serving is an important component of end-to-end\\napplications. Ray focuses primarily on the embedded\\nserving of models to simulators running within the same\\ndynamic task graph (e.g., within an RL application on\\nRay). In contrast, systems like Clipper [ 19] focus on\\nserving predictions to external clients.\\nIn this setting, low latency is critical for achieving high\\nutilization. To show this, in Table 3 we compare the\\nSystem Small Input Larger Input\\nClipper 4400 ±15 states/sec 290 ±1.3 states/sec\\nRay 6200 ±21 states/sec 6900 ±150 states/sec\\nTable 3: Throughput comparisons for Clipper [19], a dedicated\\nserving system, and Ray for two embedded serving workloads.\\nWe use a residual network and a small fully connected network,\\ntaking 10ms and 5ms to evaluate, respectively. The server is\\nqueried by clients that each send states of size 4KB and 100KB\\nrespectively in batches of 64.\\nserver throughput achieved using a Ray actor to serve\\na policy versus using the open source Clipper system\\nover REST. Here, both client and server processes are co-\\nlocated on the same machine (a p3.8xlarge instance). This\\nis often the case for RL applications but not for the general\\nweb serving workloads addressed by systems like Clipper.\\nDue to its low-overhead serialization and shared memory\\nabstractions, Ray achieves an order of magnitude higher\\nthroughput for a small fully connected policy model that\\ntakes in a large input and is also faster on a more expensive\\nresidual network policy model, similar to one used in\\nAlphaGo Zero, that takes smaller input.\\n5.2.3 Simulation\\nSimulators used in RL produce results with variable\\nlengths (“timesteps”) that, due to the tight loop with train-\\ning, must be used as soon as they are available. The task\\nheterogeneity and timeliness requirements make simu-\\nlations hard to support efﬁciently in BSP-style systems.\\nTo demonstrate, we compare (1) an MPI implementation\\nthat submits 3n parallel simulation runs on n cores in 3\\nrounds, with a global barrier between rounds §, to (2) a\\nRay program that issues the same 3n tasks while concur-\\nrently gathering simulation results back to the driver. Ta-\\nble 4 shows that both systems scale well, yet Ray achieves\\nup to 1.8×throughput. This motivates a programming\\nmodel that can dynamically spawn and collect the results\\nof ﬁne-grained simulation tasks.\\nSystem, programming model 1 CPU 16 CPUs 256 CPUs\\nMPI, bulk synchronous 22.6K 208K 2.16M\\nRay, asynchronous tasks 22.3K 290K 4.03M\\nTable 4: Timesteps per second for the Pendulum-v0 simulator\\nin OpenAI Gym [ 13]. Ray allows for better utilization when\\nrunning heterogeneous simulations at scale.\\n§Note that experts can use MPI’s asynchronous primitives to get\\naround barriers—at the expense of increased program complexity —we\\nnonetheless chose such an implementation to simulate BSP.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='5.3 RL Applications\\nWithout a system that can tightly couple the training, sim-\\nulation, and serving steps, reinforcement learning algo-\\nrithms today are implemented as one-off solutions that\\nmake it difﬁcult to incorporate optimizations that, for ex-\\nample, require a different computation structure or that\\nutilize different architectures. Consequently, with imple-\\nmentations of two representative reinforcement learning\\napplications in Ray, we are able to match and even out-\\nperform custom systems built speciﬁcally for these algo-\\nrithms. The primary reason is the ﬂexibility of Ray’s pro-\\ngramming model, which can express application-level op-\\ntimizations that would require substantial engineering ef-\\nfort to port to custom-built systems, but are transparently\\nsupported by Ray’s dynamic task graph execution engine.\\n5.3.1 Evolution Strategies\\nTo evaluate Ray on large-scale RL workloads, we imple-\\nment the evolution strategies (ES) algorithm and com-\\npare to the reference implementation [49]—a system spe-\\ncially built for this algorithm that relies on Redis for mes-\\nsaging and low-level multiprocessing libraries for data-\\nsharing. The algorithm periodically broadcasts a new pol-\\nicy to a pool of workers and aggregates the results of\\nroughly 10000 tasks (each performing 10 to 1000 simula-\\ntion steps).\\nAs shown in Figure 14a, an implementation on Ray\\nscales to 8192 cores. Doubling the cores available yields\\nan average completion time speedup of 1.6×. Conversely,\\nthe special-purpose system fails to complete at 2048 cores,\\nwhere the work in the system exceeds the processing\\ncapacity of the application driver. To avoid this issue, the\\nRay implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice\\nas fast as the best published result (10 minutes).\\nInitial parallelization of a serial implementation using\\nRay required modifying only 7 lines of code. Performance\\nimprovement through hierarchical aggregation was easy\\nto realize with Ray’s support for nested tasks and actors.\\nIn contrast, the reference implementation had several hun-\\ndred lines of code dedicated to a protocol for communi-\\ncating tasks and data between workers, and would require\\nfurther engineering to support optimizations like hierar-\\nchical aggregation.\\n5.3.2 Proximal Policy Optimization\\nWe implement Proximal Policy Optimization (PPO) [51]\\nin Ray and compare to a highly-optimized reference im-\\nplementation [5] that uses OpenMPI communication prim-\\nitives. The algorithm is an asynchronous scatter-gather,\\nwhere new tasks are assigned to simulation actors as they\\n256 1024 8192\\nNumber of CPUs\\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\n90Mean time to solve (minutes)\\nx x x\\nReference ES\\nRay ES\\n(a) Evolution Strategies\\n8x1 64x8 512x64\\nCPUs x GPUs\\n0\\n100\\n200\\n300\\n400\\n500Mean time to solve (minutes)\\nMPI PPO\\nRay PPO (b) PPO\\nFigure 14: Time to reach a score of 6000 in the Humanoid-\\nv1 task [ 13]. (a) The Ray ES implementation scales well to\\n8192 cores and achieves a median time of 3.7 minutes, over\\ntwice as fast as the best published result. The special-purpose\\nsystem failed to run beyond 1024 cores. ES is faster than PPO\\non this benchmark, but shows greater runtime variance. (b)\\nThe Ray PPO implementation outperforms a specialized MPI\\nimplementation [5] with fewer GPUs, at a fraction of the cost.\\nThe MPI implementation required 1 GPU for every 8 CPUs,\\nwhereas the Ray version required at most 8 GPUs (and never\\nmore than 1 GPU per 8 CPUs).\\nreturn rollouts to the driver. Tasks are submitted un-\\ntil 320000 simulation steps are collected (each task pro-\\nduces between 10 and 1000 steps). The policy update per-\\nforms 20 steps of SGD with a batch size of 32768. The\\nmodel parameters in this example are roughly 350KB.\\nThese experiments were run using p2.16xlarge (GPU) and\\nm4.16xlarge (high CPU) instances.\\nAs shown in Figure 14b, the Ray implementation out-\\nperforms the optimized MPI implementation in all exper-\\niments, while using a fraction of the GPUs. The reason\\nis that Ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource\\nrequirements at the granularity of a task or actor. The Ray\\nimplementation can then leverage TensorFlow’s single-\\nprocess multi-GPU support and can pin objects in GPU\\nmemory when possible. This optimization cannot be eas-\\nily ported to MPI due to the need to asynchronously gather\\nrollouts to a single GPU process. Indeed, [5] includes two\\ncustom implementations of PPO, one using MPI for large\\nclusters and one that is optimized for GPUs but that is re-\\nstricted to a single node. Ray allows for an implementa-\\ntion suitable for both scenarios.\\nRay’s ability to handle resource heterogeneity also de-\\ncreased PPO’s cost by a factor of 4.5 [4], since CPU-only\\ntasks can be scheduled on cheaper high-CPU instances.\\nIn contrast, MPI applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and\\nrequire identical resources, in this case preventing the\\nuse of CPU-only machines for scale-out. Furthermore,\\nthe MPI implementation requires on-demand instances\\nsince it does not transparently handle failure. Assum-\\ning 4×cheaper spot instances, Ray’s fault tolerance and\\nresource-aware scheduling together cut costs by 18×.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='6 Related Work\\nDynamic task graphs. Ray is closely related to\\nCIEL [40] and Dask [ 48]. All three support dynamic\\ntask graphs with nested tasks and implement the futures\\nabstraction. CIEL also provides lineage-based fault toler-\\nance, while Dask, like Ray, fully integrates with Python.\\nHowever, Ray differs in two aspects that have important\\nperformance consequences. First, Ray extends the task\\nmodel with an actor abstraction. This is necessary for\\nefﬁcient stateful computation in distributed training and\\nserving, to keep the model data collocated with the com-\\nputation. Second, Ray employs a fully distributed and de-\\ncoupled control plane and scheduler, instead of relying on\\na single master storing all metadata. This is critical for ef-\\nﬁciently supporting primitives like allreduce without sys-\\ntem modiﬁcation. At peak performance for 100MB on 16\\nnodes, allreduce on Ray (Section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. Meanwhile, Dask reports a maxi-\\nmum scheduler throughput of 3k tasks/s on 512 cores [3].\\nWith a centralized scheduler, each round of allreduce\\nwould then incur a minimum of ∼5ms of scheduling\\ndelay, translating to up to2×worse completion time (Fig-\\nure 12b). Even with a decentralized scheduler, coupling\\nthe control plane information with the scheduler leaves\\nthe latter on the critical path for data transfer, adding an\\nextra roundtrip to every round of allreduce.\\nDataﬂow systems. Popular dataﬂow systems, such\\nas MapReduce [ 20], Spark [ 65], and Dryad [ 28] have\\nwidespread adoption for analytics and ML workloads,\\nbut their computation model is too restrictive for a ﬁne-\\ngrained and dynamic simulation workload. Spark and\\nMapReduce implement the BSP execution model, which\\nassumes that tasks within the same stage perform the\\nsame computation and take roughly the same amount of\\ntime. Dryad relaxes this restriction but lacks support for\\ndynamic task graphs. Furthermore, none of these systems\\nprovide an actor abstraction, nor implement a distributed\\nscalable control plane and scheduler. Finally, Naiad [39]\\nis a dataﬂow system that provides improved scalability\\nfor some workloads, but only supports static task graphs.\\nMachine learning frameworks. TensorFlow [7] and\\nMXNet [ 18] target deep learning workloads and efﬁ-\\nciently leverage both CPUs and GPUs. While they\\nachieve great performance for training workloads consist-\\ning of static DAGs of linear algebra operations, they have\\nlimited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. TensorFlow Fold [33] provides some support for\\ndynamic task graphs, as well as MXNet through its inter-\\nnal C++ APIs, but neither fully supports the ability to mod-\\nify the DAG during execution in response to task progress,\\ntask completion times, or faults. TensorFlow and MXNet\\nin principle achieve generality by allowing the program-\\nmer to simulate low-level message-passing and synchro-\\nnization primitives, but the pitfalls and user experience in\\nthis case are similar to those of MPI. OpenMPI [22] can\\nachieve high performance, but it is relatively hard to pro-\\ngram as it requires explicit coordination to handle hetero-\\ngeneous and dynamic task graphs. Furthermore, it forces\\nthe programmer to explicitly handle fault tolerance.\\nActor systems. Orleans [14] and Akka [1] are two ac-\\ntor frameworks well suited to developing highly available\\nand concurrent distributed systems. However, compared\\nto Ray, they provide less support for recovery from data\\nloss. To recover stateful actors, the Orleans developer\\nmust explicitly checkpoint actor state and intermediate re-\\nsponses. Stateless actors in Orleans can be replicated for\\nscale-out, and could therefore act as tasks, but unlike in\\nRay, they have no lineage. Similarly, while Akka explic-\\nitly supports persisting actor state across failures, it does\\nnot provide efﬁcient fault tolerance for stateless computa-\\ntion (i.e., tasks). For message delivery, Orleans provides\\nat-least-once and Akka provides at-most-once semantics.\\nIn contrast, Ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe GCS and both arguments and results are immutable.\\nWe ﬁnd that in practice these limitations do not affect the\\nperformance of our applications. Erlang [10] and C++ Ac-\\ntor Framework [17], two other actor-based systems, have\\nsimilarly limited support for fault tolerance.\\nGlobal control store and scheduling. The concept\\nof logically centralizing the control plane has been pre-\\nviously proposed in software deﬁned networks (SDNs)\\n[16], distributed ﬁle systems (e.g., GFS [ 23]), resource\\nmanagement (e.g., Omega [52]), and distributed frame-\\nworks (e.g., MapReduce [ 20], BOOM [ 9]), to name a\\nfew. Ray draws inspiration from these pioneering efforts,\\nbut provides signiﬁcant improvements. In contrast with\\nSDNs, BOOM, and GFS, Ray decouples the storage of\\nthe control plane information (e.g., GCS) from the logic\\nimplementation (e.g., schedulers). This allows both stor-\\nage and computation layers to scale independently, which\\nis key to achieving our scalability targets. Omega uses\\na distributed architecture in which schedulers coordinate\\nvia globally shared state. To this architecture, Ray adds\\nglobal schedulers to balance load across local schedulers,\\nand targets ms-level, not second-level, task scheduling.\\nRay implements a unique distributed bottom-up sched-\\nuler that is horizontally scalable, and can handle dynami-\\ncally constructed task graphs. Unlike Ray, most existing\\ncluster computing systems [20, 64, 40] use a centralized\\nscheduler architecture. While Sparrow [45] is decentral-\\nized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. Mesos [ 26] im-\\nplements a two-level hierarchical scheduler, but its top-\\nlevel scheduler manages frameworks, not individual tasks.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Canary [47] achieves impressive performance by having\\neach scheduler instance handle a portion of the task graph,\\nbut does not handle dynamic computation graphs.\\nCilk [12] is a parallel programming language whose\\nwork-stealing scheduler achieves provably efﬁcient load-\\nbalancing for dynamic task graphs. However, with no cen-\\ntral coordinator like Ray’s global scheduler, this fully par-\\nallel design is also difﬁcult to extend to support data lo-\\ncality and resource heterogeneity in a distributed setting.\\n7 Discussion and Experiences\\nBuilding Ray has been a long journey. It started two years\\nago with a Spark library to perform distributed training\\nand simulations. However, the relative inﬂexibility of the\\nBSP model, the high per-task overhead, and the lack of an\\nactor abstraction led us to develop a new system. Since we\\nreleased Ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. Here we discuss our experience developing\\nand using Ray, and some early user feedback.\\nAPI. In designing the API, we have emphasized mini-\\nmalism. Initially we started with a basic task abstraction.\\nLater, we added the wait() primitive to accommodate roll-\\nouts with heterogeneous durations and the actor abstrac-\\ntion to accommodate third-party simulators and amortize\\nthe overhead of expensive initializations. While the re-\\nsulting API is relatively low-level, it has proven both pow-\\nerful and simple to use. We have already used this API to\\nimplement many state-of-the-art RL algorithms on top of\\nRay, including A3C [36], PPO [51], DQN [37], ES [49],\\nDDPG [55], and Ape-X [ 27]. In most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nRay. Based on early user feedback, we are considering\\nenhancing the API to include higher level primitives and\\nlibraries, which could also inform scheduling decisions.\\nLimitations. Given the workload generality, special-\\nized optimizations are hard. For example, we must make\\nscheduling decisions without full knowledge of the com-\\nputation graph. Scheduling optimizations in Ray might\\nrequire more complex runtime proﬁling. In addition, stor-\\ning lineage for each task requires the implementation of\\ngarbage collection policies to bound storage costs in the\\nGCS, a feature we are actively developing.\\nFault tolerance. We are often asked if fault tolerance\\nis really needed for AI applications. After all, due to the\\nstatistical nature of many AI algorithms, one could sim-\\nply ignore failed rollouts. Based on our experience, our\\nanswer is “yes”. First, the ability to ignore failures makes\\napplications much easier to write and reason about. Sec-\\nond, our particular implementation of fault tolerance via\\ndeterministic replay dramatically simpliﬁes debugging as\\nit allows us to easily reproduce most errors. This is par-\\nticularly important since, due to their stochasticity, AI al-\\ngorithms are notoriously hard to debug. Third, fault toler-\\nance helps save money since it allows us to run on cheap\\nresources like spot instances on AWS. Of course, this\\ncomes at the price of some overhead. However, we found\\nthis overhead to be minimal for our target workloads.\\nGCS and Horizontal Scalability. The GCS dramati-\\ncally simpliﬁed Ray development and debugging. It en-\\nabled us to query the entire system state while debugging\\nRay itself, instead of having to manually expose internal\\ncomponent state. In addition, the GCS is also the backend\\nfor our timeline visualization tool, used for application-\\nlevel debugging.\\nThe GCS was also instrumental to Ray’s horizontal\\nscalability. In Section 5, we were able to scale by adding\\nmore shards whenever the GCS became a bottleneck. The\\nGCS also enabled the global scheduler to scale by sim-\\nply adding more replicas. Due to these advantages, we\\nbelieve that centralizing control state will be a key design\\ncomponent of future distributed systems.\\n8 Conclusion\\nNo general-purpose system today can efﬁciently support\\nthe tight loop of training, serving, and simulation. To ex-\\npress these core building blocks and meet the demands of\\nemerging AI applications, Ray uniﬁes task-parallel and\\nactor programming models in a single dynamic task graph\\nand employs a scalable architecture enabled by the global\\ncontrol store and a bottom-up distributed scheduler. The\\nprogramming ﬂexibility, high throughput, and low laten-\\ncies simultaneously achieved by this architecture is partic-\\nularly important for emerging artiﬁcial intelligence work-\\nloads, which produce tasks diverse in their resource re-\\nquirements, duration, and functionality. Our evaluation\\ndemonstrates linear scalability up to 1.8 million tasks per\\nsecond, transparent fault tolerance, and substantial perfor-\\nmance improvements on several contemporary RL work-\\nloads. Thus, Ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future AI applications.\\n9 Acknowledgments\\nThis research is supported in part by NSF CISE Expedi-\\ntions Award CCF-1730628 and gifts from Alibaba, Ama-\\nzon Web Services, Ant Financial, Arm, CapitalOne, Eric-\\nsson, Facebook, Google, Huawei, Intel, Microsoft, Sco-\\ntiabank, Splunk and VMware as well as by NSF grant\\nDGE-1106400. We are grateful to our anonymous review-\\ners and our shepherd, Miguel Castro, for thoughtful feed-\\nback, which helped improve the quality of this paper.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Akka. https://akka.io/.\\n[2] Apache Arrow. https://arrow.apache.org/.\\n[3] Dask Benchmarks. http://matthewrocklin.com/blog/\\nwork/2017/07/03/scaling.\\n[4] EC2 Instance Pricing. https://aws.amazon.com/ec2/\\npricing/on-demand/.\\n[5] OpenAI Baselines: high-quality implementations of reinforce-\\nment learning algorithms. https://github.com/openai/\\nbaselines.\\n[6] TensorFlow Serving. https://www.tensorflow.org/\\nserving/.\\n[7] ABADI , M., B ARHAM , P., C HEN , J., C HEN , Z., D AVIS, A.,\\nDEAN , J., D EVIN , M., G HEMAWAT, S., I RVING , G., I SARD , M.,\\nET AL . TensorFlow: A system for large-scale machine learning.\\nIn Proceedings of the 12th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI). Savannah, Georgia,\\nUSA (2016).\\n[8] A GARWAL , A., B IRD , S., C OZOWICZ , M., H OANG , L., L ANG -\\nFORD , J., L EE, S., L I, J., M ELAMED , D., O SHRI , G., R IBAS ,\\nO., S EN, S., AND SLIVKINS , A. A multiworld testing decision\\nservice. arXiv preprint arXiv:1606.03966 (2016).\\n[9] ALVARO, P., C ONDIE , T., C ONWAY, N., E LMELEEGY , K.,\\nHELLERSTEIN , J. M., AND SEARS , R. BOOM Analytics: ex-\\nploring data-centric, declarative programming for the cloud. In\\nProceedings of the 5th European conference on Computer systems\\n(2010), ACM, pp. 223–236.\\n[10] ARMSTRONG , J., V IRDING , R., W IKSTR ¨OM, C., AND\\nWILLIAMS , M. Concurrent programming in ERLANG.\\n[11] BEATTIE , C., L EIBO , J. Z., T EPLYASHIN , D., W ARD , T.,\\nWAINWRIGHT , M., K ¨UTTLER , H., L EFRANCQ , A., G REEN , S.,\\nVALD ´ES, V., SADIK , A., ET AL . DeepMind Lab. arXiv preprint\\narXiv:1612.03801 (2016).\\n[12] BLUMOFE , R. D., AND LEISERSON , C. E. Scheduling mul-\\ntithreaded computations by work stealing. J. ACM 46, 5 (Sept.\\n1999), 720–748.\\n[13] B ROCKMAN , G., C HEUNG , V., PETTERSSON , L., S CHNEIDER ,\\nJ., S CHULMAN , J., T ANG , J., AND ZAREMBA , W. OpenAI gym.\\narXiv preprint arXiv:1606.01540 (2016).\\n[14] BYKOV, S., G ELLER , A., K LIOT , G., L ARUS , J. R., P ANDYA ,\\nR., AND THELIN , J. Orleans: Cloud computing for everyone. In\\nProceedings of the 2nd ACM Symposium on Cloud Computing\\n(2011), ACM, p. 16.\\n[15] CARBONE , P., E WEN , S., F ´ORA , G., H ARIDI , S., R ICHTER ,\\nS., AND TZOUMAS , K. State management in Apache Flink:\\nConsistent stateful distributed stream processing. Proc. VLDB\\nEndow. 10, 12 (Aug. 2017), 1718–1729.\\n[16] CASADO , M., F REEDMAN , M. J., P ETTIT , J., L UO, J., M CKE-\\nOWN , N., AND SHENKER , S. Ethane: Taking control of the enter-\\nprise. SIGCOMM Comput. Commun. Rev. 37, 4 (Aug. 2007), 1–12.\\n[17] CHAROUSSET , D., S CHMIDT , T. C., H IESGEN , R., AND\\nW ¨AHLISCH , M. Native actors: A scalable software platform for\\ndistributed, heterogeneous environments. In Proceedings of the\\n2013 workshop on Programming based on actors, agents, and de-\\ncentralized control (2013), ACM, pp. 87–96.\\n[18] CHEN , T., L I, M., L I, Y., L IN, M., W ANG , N., W ANG , M.,\\nXIAO , T., X U, B., Z HANG , C., AND ZHANG , Z. MXNet: A\\nﬂexible and efﬁcient machine learning library for heterogeneous\\ndistributed systems. In NIPS Workshop on Machine Learning\\nSystems (LearningSys’16)(2016).\\n[19] CRANKSHAW , D., W ANG , X., Z HOU , G., F RANKLIN , M. J.,\\nGONZALEZ , J. E., AND STOICA , I. Clipper: A low-latency\\nonline prediction serving system. In 14th USENIX Symposium\\non Networked Systems Design and Implementation (NSDI 17)\\n(Boston, MA, 2017), USENIX Association, pp. 613–627.\\n[20] DEAN , J., AND GHEMAWAT, S. MapReduce: Simpliﬁed data\\nprocessing on large clusters. Commun. ACM 51, 1 (Jan. 2008),\\n107–113.\\n[21] DENNIS , J. B., AND MISUNAS , D. P. A preliminary architecture\\nfor a basic data-ﬂow processor. In Proceedings of the 2Nd An-\\nnual Symposium on Computer Architecture (New York, NY , USA,\\n1975), ISCA ’75, ACM, pp. 126–132.\\n[22] GABRIEL , E., F AGG , G. E., B OSILCA , G., A NGSKUN , T., D ON-\\nGARRA , J. J., S QUYRES , J. M., S AHAY, V., K AMBADUR , P.,\\nBARRETT , B., L UMSDAINE , A., C ASTAIN , R. H., D ANIEL ,\\nD. J., G RAHAM , R. L., AND WOODALL , T. S. Open MPI: Goals,\\nconcept, and design of a next generation MPI implementation. In\\nProceedings, 11th European PVM/MPI Users’ Group Meeting\\n(Budapest, Hungary, September 2004), pp. 97–104.\\n[23] GHEMAWAT, S., G OBIOFF , H., AND LEUNG , S.-T. The Google\\nﬁle system. 29–43.\\n[24] GONZALEZ , J. E., X IN, R. S., D AVE, A., C RANKSHAW , D.,\\nFRANKLIN , M. J., AND STOICA , I. GraphX: Graph processing\\nin a distributed dataﬂow framework. In Proceedings of the 11th\\nUSENIX Conference on Operating Systems Design and Implemen-\\ntation (Berkeley, CA, USA, 2014), OSDI’14, USENIX Associa-\\ntion, pp. 599–613.\\n[25] GU*, S., H OLLY *, E., L ILLICRAP , T., AND LEVINE , S. Deep re-\\ninforcement learning for robotic manipulation with asynchronous\\noff-policy updates. In IEEE International Conference on Robotics\\nand Automation (ICRA 2017) (2017).\\n[26] HINDMAN , B., K ONWINSKI , A., Z AHARIA , M., G HODSI , A.,\\nJOSEPH , A. D., K ATZ, R., S HENKER , S., AND STOICA , I.\\nMesos: A platform for ﬁne-grained resource sharing in the data\\ncenter. In Proceedings of the 8th USENIX Conference on Net-\\nworked Systems Design and Implementation (Berkeley, CA, USA,\\n2011), NSDI’11, USENIX Association, pp. 295–308.\\n[27] HORGAN , D., Q UAN , J., B UDDEN , D., B ARTH -MARON , G.,\\nHESSEL , M., VAN HASSELT , H., AND SILVER , D. Distributed\\nprioritized experience replay. International Conference on Learn-\\ning Representations (2018).\\n[28] ISARD , M., B UDIU , M., Y U, Y., B IRRELL , A., AND FETTERLY ,\\nD. Dryad: Distributed data-parallel programs from sequential\\nbuilding blocks. In Proceedings of the 2nd ACM SIGOPS/EuroSys\\nEuropean Conference on Computer Systems 2007 (New York, NY ,\\nUSA, 2007), EuroSys ’07, ACM, pp. 59–72.\\n[29] JIA, Y., SHELHAMER , E., D ONAHUE , J., K ARAYEV, S., L ONG ,\\nJ., G IRSHICK , R., G UADARRAMA , S., AND DARRELL , T. Caffe:\\nConvolutional architecture for fast feature embedding. arXiv\\npreprint arXiv:1408.5093 (2014).\\n[30] JORDAN , M. I., AND MITCHELL , T. M. Machine learning:\\nTrends, perspectives, and prospects. Science 349, 6245 (2015),\\n255–260.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[31] LEIBIUSKY , J., E ISBRUCH , G., AND SIMONASSI , D. Getting\\nStarted with Storm. O’Reilly Media, Inc., 2012.\\n[32] LI, M., A NDERSEN , D. G., P ARK , J. W., S MOLA , A. J.,\\nAHMED , A., J OSIFOVSKI , V., LONG , J., S HEKITA , E. J., AND\\nSU, B.-Y. Scaling distributed machine learning with the parame-\\nter server. In Proceedings of the 11th USENIX Conference on Op-\\nerating Systems Design and Implementation (Berkeley, CA, USA,\\n2014), OSDI’14, pp. 583–598.\\n[33] L OOKS , M., H ERRESHOFF , M., H UTCHINS , D., AND NORVIG ,\\nP. Deep learning with dynamic computation graphs.arXiv preprint\\narXiv:1702.02181 (2017).\\n[34] LOW, Y., G ONZALEZ , J., K YROLA , A., B ICKSON , D.,\\nGUESTRIN , C., AND HELLERSTEIN , J. GraphLab: A new frame-\\nwork for parallel machine learning. In Proceedings of the Twenty-\\nSixth Conference on Uncertainty in Artiﬁcial Intelligence (Arling-\\nton, Virginia, United States, 2010), UAI’10, pp. 340–349.\\n[35] MALEWICZ , G., A USTERN , M. H., B IK, A. J., D EHNERT , J. C.,\\nHORN , I., L EISER , N., AND CZAJKOWSKI , G. Pregel: A system\\nfor large-scale graph processing. In Proceedings of the 2010 ACM\\nSIGMOD International Conference on Management of Data(New\\nYork, NY , USA, 2010), SIGMOD ’10, ACM, pp. 135–146.\\n[36] MNIH , V., BADIA , A. P., M IRZA , M., G RAVES , A., L ILLICRAP ,\\nT. P., HARLEY , T., S ILVER , D., AND KAVUKCUOGLU , K. Asyn-\\nchronous methods for deep reinforcement learning. In Interna-\\ntional Conference on Machine Learning (2016).\\n[37] MNIH , V., K AVUKCUOGLU , K., S ILVER , D., R USU , A. A.,\\nVENESS , J., B ELLEMARE , M. G., G RAVES , A., R IEDMILLER ,\\nM., F IDJELAND , A. K., O STROVSKI , G., ET AL . Human-level\\ncontrol through deep reinforcement learning. Nature 518, 7540\\n(2015), 529–533.\\n[38] MURRAY, D. A Distributed Execution Engine Supporting Data-\\ndependent Control Flow. University of Cambridge, 2012.\\n[39] MURRAY, D. G., M CSHERRY, F., I SAACS , R., I SARD , M.,\\nBARHAM , P., AND ABADI , M. Naiad: A timely dataﬂow system.\\nIn Proceedings of the Twenty-Fourth ACM Symposium on Operat-\\ning Systems Principles (New York, NY , USA, 2013), SOSP ’13,\\nACM, pp. 439–455.\\n[40] MURRAY, D. G., S CHWARZKOPF , M., S MOWTON , C., S MITH ,\\nS., M ADHAVAPEDDY , A., AND HAND , S. CIEL: A universal exe-\\ncution engine for distributed data-ﬂow computing. In Proceedings\\nof the 8th USENIX Conference on Networked Systems Design and\\nImplementation (Berkeley, CA, USA, 2011), NSDI’11, USENIX\\nAssociation, pp. 113–126.\\n[41] NAIR , A., S RINIVASAN , P., B LACKWELL , S., A LCICEK , C.,\\nFEARON , R., M ARIA , A. D., P ANNEERSHELVAM , V., SULEY -\\nMAN , M., B EATTIE , C., P ETERSEN , S., L EGG , S., M NIH , V.,\\nKAVUKCUOGLU , K., AND SILVER , D. Massively parallel meth-\\nods for deep reinforcement learning, 2015.\\n[42] NG, A., C OATES , A., D IEL , M., G ANAPATHI , V., S CHULTE , J.,\\nTSE, B., B ERGER , E., AND LIANG , E. Autonomous inverted he-\\nlicopter ﬂight via reinforcement learning. Experimental Robotics\\nIX (2006), 363–372.\\n[43] NISHIHARA , R., M ORITZ , P., WANG , S., T UMANOV , A., P AUL ,\\nW., SCHLEIER -SMITH , J., L IAW, R., N IKNAMI , M., J ORDAN ,\\nM. I., AND STOICA , I. Real-time machine learning: The missing\\npieces. In Workshop on Hot Topics in Operating Systems(2017).\\n[44] OPEN AI. OpenAI Dota 2 1v1 bot. https://openai.com/\\nthe-international/, 2017.\\n[45] OUSTERHOUT , K., W ENDELL , P., Z AHARIA , M., AND STOICA ,\\nI. Sparrow: Distributed, low latency scheduling. In Proceedings\\nof the Twenty-Fourth ACM Symposium on Operating Systems\\nPrinciples (New York, NY , USA, 2013), SOSP ’13, ACM, pp. 69–\\n84.\\n[46] PASZKE , A., G ROSS , S., C HINTALA , S., C HANAN , G., Y ANG ,\\nE., D EVITO , Z., L IN, Z., D ESMAISON , A., A NTIGA , L., AND\\nLERER , A. Automatic differentiation in PyTorch.\\n[47] QU, H., M ASHAYEKHI , O., T EREI , D., AND LEVIS , P. Canary:\\nA scheduling architecture for high performance cloud computing.\\narXiv preprint arXiv:1602.01412 (2016).\\n[48] ROCKLIN , M. Dask: Parallel computation with blocked algo-\\nrithms and task scheduling. In Proceedings of the 14th Python in\\nScience Conference (2015), K. Huff and J. Bergstra, Eds., pp. 130\\n– 136.\\n[49] S ALIMANS , T., H O, J., C HEN , X., AND SUTSKEVER , I. Evolu-\\ntion strategies as a scalable alternative to reinforcement learning.\\narXiv preprint arXiv:1703.03864 (2017).\\n[50] SANFILIPPO , S. Redis: An open source, in-memory data structure\\nstore. https://redis.io/, 2009.\\n[51] SCHULMAN , J., W OLSKI , F., D HARIWAL , P., R ADFORD , A.,\\nAND KLIMOV, O. Proximal policy optimization algorithms. arXiv\\npreprint arXiv:1707.06347 (2017).\\n[52] SCHWARZKOPF , M., K ONWINSKI , A., A BD-EL-MALEK , M.,\\nAND WILKES , J. Omega: Flexible, scalable schedulers for large\\ncompute clusters. In Proceedings of the 8th ACM European Con-\\nference on Computer Systems (New York, NY , USA, 2013), Eu-\\nroSys ’13, ACM, pp. 351–364.\\n[53] SERGEEV , A., AND DEL BALSO , M. Horovod: fast and\\neasy distributed deep learning in tensorﬂow. arXiv preprint\\narXiv:1802.05799 (2018).\\n[54] SILVER , D., H UANG , A., M ADDISON , C. J., G UEZ , A.,\\nSIFRE , L., V AN DEN DRIESSCHE , G., S CHRITTWIESER , J.,\\nANTONOGLOU , I., P ANNEERSHELVAM , V., L ANCTOT , M.,\\nET AL . Mastering the game of Go with deep neural networks and\\ntree search. Nature 529, 7587 (2016), 484–489.\\n[55] SILVER , D., L EVER , G., H EESS , N., D EGRIS , T., W IERSTRA ,\\nD., AND RIEDMILLER , M. Deterministic policy gradient algo-\\nrithms. In ICML (2014).\\n[56] SUTTON , R. S., AND BARTO , A. G. Reinforcement Learning:\\nAn Introduction. MIT press Cambridge, 1998.\\n[57] THAKUR , R., R ABENSEIFNER , R., AND GROPP, W. Optimiza-\\ntion of collective communication operations in MPICH. The Inter-\\nnational Journal of High Performance Computing Applications\\n19, 1 (2005), 49–66.\\n[58] TIAN , Y., GONG , Q., S HANG , W., W U, Y., AND ZITNICK , C. L.\\nELF: An extensive, lightweight and ﬂexible research platform\\nfor real-time strategy games. Advances in Neural Information\\nProcessing Systems (NIPS) (2017).\\n[59] TODOROV , E., E REZ , T., AND TASSA , Y. Mujoco: A physics\\nengine for model-based control. In Intelligent Robots and Systems\\n(IROS), 2012 IEEE/RSJ International Conference on(2012), IEEE,\\npp. 5026–5033.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[60] VAN DEN BERG , J., M ILLER , S., D UCKWORTH , D., H U, H.,\\nWAN, A., F U, X.-Y., G OLDBERG , K., AND ABBEEL , P. Su-\\nperhuman performance of surgical tasks by robots using iterative\\nlearning from human-guided demonstrations. In Robotics and Au-\\ntomation (ICRA), 2010 IEEE International Conference on (2010),\\nIEEE, pp. 2074–2081.\\n[61] VAN RENESSE , R., AND SCHNEIDER , F. B. Chain replication for\\nsupporting high throughput and availability. In Proceedings of the\\n6th Conference on Symposium on Opearting Systems Design &\\nImplementation - Volume 6 (Berkeley, CA, USA, 2004), OSDI’04,\\nUSENIX Association.\\n[62] VENKATARAMAN , S., P ANDA , A., O USTERHOUT , K., G HODSI ,\\nA., A RMBRUST , M., R ECHT , B., F RANKLIN , M., AND STOICA ,\\nI. Drizzle: Fast and adaptable stream processing at scale. In\\nProceedings of the Twenty-Sixth ACM Symposium on Operating\\nSystems Principles (2017), SOSP ’17, ACM.\\n[63] WHITE , T. Hadoop: The Deﬁnitive Guide. O’Reilly Media, Inc.,\\n2012.\\n[64] ZAHARIA , M., C HOWDHURY , M., D AS, T., D AVE, A., M A, J.,\\nMCCAULEY, M., F RANKLIN , M. J., S HENKER , S., AND STO-\\nICA , I. Resilient distributed datasets: A fault-tolerant abstrac-\\ntion for in-memory cluster computing. In Proceedings of the 9th\\nUSENIX conference on Networked Systems Design and Implemen-\\ntation (2012), USENIX Association, pp. 2–2.\\n[65] ZAHARIA , M., X IN, R. S., W ENDELL , P., DAS, T., A RMBRUST ,\\nM., D AVE, A., M ENG , X., R OSEN , J., V ENKATARAMAN , S.,\\nFRANKLIN , M. J., G HODSI , A., G ONZALEZ , J., S HENKER , S.,\\nAND STOICA , I. Apache Spark: A uniﬁed engine for big data\\nprocessing. Commun. ACM 59, 11 (Oct. 2016), 56–65.'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Scaling Transformer-Based Novel View Synthesis Models with\\nToken Disentanglement and Synthetic Data\\nNithin Gopalakrishnan Nair1∗ Srinivas Kaza2∗ Xuan Luo2 Vishal M. Patel1\\nStephen Lombardi2 Jungyeon Park2\\n1 Johns Hopkins University 2 Google\\n{ngopala2,vpatel36}@jhu.edu{srinivaskaza,xuluo,salombardi,jungyeonp}@google.com\\nhttps://scaling3dnvs.github.io\\nLVSM\\nOURS\\nLVSM\\nOURS\\nLVSM\\nOURS\\nFigure 1.Overview.Our method performs feed-forward novel-view synthesis from a series of input images, such as the pairs shown\\nabove. We demonstrate strong results in terms of quality and generalization capacity, performing well across a variety of common novel-\\nview synthesis datasets, including scenes that are out-of-distribution.\\nAbstract\\nLarge transformer-based models have made significant\\nprogress in generalizable novel view synthesis (NVS) from\\nsparse input views, generating novel viewpoints without the\\nneed for test-time optimization. However, these models\\nare constrained by the limited diversity of publicly avail-\\nable scene datasets, making most real-world (in-the-wild)\\nscenes out-of-distribution. To overcome this, we incorpo-\\nrate synthetic training data generated from diffusion mod-\\nels, which improves generalization across unseen domains.\\nWhile synthetic data offers scalability, we identify artifacts\\nintroduced during data generation as a key bottleneck af-\\nfecting reconstruction quality. To address this, we propose\\na token disentanglement process within the transformer ar-\\nchitecture, enhancing feature separation and ensuring more\\neffective learning. This refinement not only improves re-\\narXiv:2509.06950v1  [cs.GR]  8 Sep 2025'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='construction quality over standard transformers but also\\nenables scalable training with synthetic data. As a result,\\nour method outperforms existing models on both in-dataset\\nand cross-dataset evaluations, achieving state-of-the-art re-\\nsults across multiple benchmarks while significantly reduc-\\ning computational costs.\\n1. Introduction\\nNovel view synthesis (NVS) [20, 27] is a well-studied and\\nimportant problem in computer vision, where the task is to\\ngenerate unseen perspectives of a scene from a given set of\\nimages. Many approaches utilize volumetric [2, 5, 27, 28]\\nor differentiable rendering [20] to optimize for each scene\\nindividually, achieving high-quality NVS from arbitrary\\nviewpoints. More recently, advancements have enabled\\ntraining a single model that generalizes to novel scenes\\nwithout requiring per-scene optimization. Most existing\\nmethods address NVS by incorporating hand-crafted 3D\\npriors and architectural biases [4, 16, 39]. While these de-\\nsign choices provide structure, they limit scalability with\\ndata and hinder generalization.\\nRecently, Large View Synthesis Model (LVSM) [19]\\nproposed a promising foundation for an NVS model scal-\\nable with large datasets. LVSM introduces an architec-\\nture that doesn’t require 3D inductive biases for scene re-\\nconstruction. It employs a decoder-only transformer ar-\\nchitecture that achieves state-of-the-art results by a sig-\\nnificant margin, with the performance improving with in-\\ncreased compute. However, we observed during our exper-\\niments that the decoder-only design causes an inherent fea-\\nture alignment problem which causes the target and source\\nfeatures to look similar at all layers. Thus, part of the trans-\\nformer’s computational capacity is spent modifying source\\ntoken information that is ultimately discarded at the end\\nof the transformer block, reducing efficiency. This design\\nchoice also makes LVSM susceptible to unwanted noise\\nor compression artifacts that may be present in the source\\nviews. In addition, we noticed that LVSM presents limited\\ncross-domain performance when tested on datasets outside\\nthe training dataset domains.\\nMoreover, these issues are not unique to LVSM; many\\nNVS models face similar challenges due to data scarcity\\nin 3D vision. All existing multi-view 3D scene datasets\\n[24, 25, 49] combined contain fewer than 100,000 scenes,\\nseverely limiting the performance of NVS models on in-\\nthe-wild cases beyond the training distribution. One pos-\\nsible solution for alleviating this 3D data scarcity is using\\nsynthetic data from generative models. Recent research has\\nexplored adapting pre-trained image [33, 34] and video dif-\\nfusion models [14, 15] for multi-view dataset generation\\n*Equal contribution. Nair designed the methodology, conducted pre-\\nrebuttal experiments, and drafted the initial manuscript. Kaza helped ad-\\nvise the project, led the rebuttal, and conducted camera-ready experiments.\\n[10, 26, 36, 44]. However, previous feed-forward mod-\\nels trained using synthetic data perform worse than those\\ntrained with real data. We hypothesize that the inability of\\nsynthetic data to improve reconstruction quality stems from\\ntwo types of degradation artifacts in scenes generated by\\ndiffusion models [15, 29, 38] (1) artifacts influenced by the\\ninitial noise of the diffusion process and (2) artifacts intro-\\nduced during decoding, as most diffusion-based scene syn-\\nthesis models operate in latent space and rely on a diffusion\\nV AE [33]. We address both issues, leading to improved per-\\nformance when using synthetic data. We provide a detailed\\nexplanation of our data pipeline in Section 4.2.\\nIn this work, we tackle a key challenge in developing\\na feed-forward NVS model that performs well on out-of-\\ndistribution data – the need for a scalable and efficient\\ntransformer-based NVS architecture. We introduce the To-\\nken Distentangled (Tok-D) transformer block, which ap-\\nplies layer-wise modulation of source and target tokens, ex-\\nplicitly distinguishing the two at each layer. These model\\nmodifications improve out-of-distribution training, which\\nintroduces the possibility of training on synthetic data. We\\nuse the CAT3D model to generate a large dataset of syn-\\nthetic multi-view samples. We then employ a novel data\\ngeneration strategy that significantly improves the quality\\nof these synthetic samples. We show that the Tok-D trans-\\nformer block can be trained with synthetic data augmenta-\\ntion, unlike the baseline LVSM method which suffers from\\nthe inclusion of synthetic data.\\n• We enhance the scalability of transformer architectures\\nfor NVS, enabling more efficient modeling.\\n• We introduce a new training scheme that is less suscepti-\\nble to artifacts from synthetic data.\\n• We improve the training efficiency of transformer for\\nNVS by introducing a new transformer block.\\n• Our approach achieves state-of-the-art results across mul-\\ntiple benchmarks for scene level NVS.\\n2. Related Works\\n2.1. Offline Novel View Synthesis\\nThe advent of neural rendering in recent years has substan-\\ntially improved the quality of NVS. Early neural scene rep-\\nresentations focused on the 4D plenoptic function [11, 23]\\nthat represents the lightfield of a scene [1, 37, 39]. Other\\nmethods modeled the geometry of the scene (e.g. as a\\nsigned distance function) separately from material proper-\\nties [40, 45]. Either way, a differentiable rendering process\\nwas used to render these neural representations into 2D im-\\nages [27]. Most of these methods focused on fitting neu-\\nral fields to sparse observations of a scene at test time—\\nwe refer to this as test-time or offline optimization. There\\nis a substantial amount of heterogeneity in these methods,\\nboth in terms of the rendering method and the scene repre-\\n2'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Tok-D Transformer Blocks\\nSource Patchify Patchify\\nSource tokens\\nTarget tokens\\nMulti-View Diﬀusion Model\\n   Input View\\n                           Generated Views\\nSynthetic Data Generation NVS Model Training\\nUnPatchify\\nFigure 2.An illustration of the architecture.We use CAT3D, a multi-view diffusion model, to generate synthetic views conditioned on\\nrandom spline camera trajectories and a random image. From the two random views form the generated views as the source views and\\nthe input conditioning view to be the target of our large reconstruction network. Our large reconstruction model uses a special transformer\\nblock which we name Tok-D Transformer. When real data is available, we just use the reconstruction transformer.\\nsentation used. Multi-layer perceptrons (MLPs) [27], vox-\\nels [9, 26], hashing-based representations [3, 28], triplanes\\n[5], and, most recently, Gaussian splats [17, 20, 21, 31]\\nhave been used as scene representations. These meth-\\nods have trade-offs between reconstruction quality, training\\ntime, inference time, memory/space requirements, capacity\\nto model view-dependent effects, etc. Some of these offline\\nmethods can even fit dynamic scenes. These test-time opti-\\nmization methods demonstrate compelling results given the\\nsparsity of the observations provided. However, they often\\nstruggle to incorporate priors learned from larger datasets.\\n2.2. Online Novel View Synthesis\\nSometimes referred to as “feed-forward” or “generaliz-\\nable” NVS models, these methods attempt to directly pro-\\nduce 3D representations from input images. Early efforts\\ninclude the image-based rendering-inspired IBRNet [41],\\nwhich directly produces 2D images based on epipolar cor-\\nrespondences on the viewing ray. The Large Reconstruc-\\ntion Model (LRM) [16] family of methods attempt to pro-\\nduce a triplane that represents an object, in some cases with\\nnear-real time performance. PixelSplat [4], MVSplat [4],\\nand GS-LRM [47] attempt to predict 3DGS [20] representa-\\ntions, which exploit the sparse Gaussian splat representation\\nand fast rasterization to achieve quasi-interactive inference.\\nThese methods are trained on large datasets of real-world\\nscenes, which helps them outperform even test-time opti-\\nmization methods. Quark [8] couples an easily-rasterizable\\nlayered depth map representation with a render-and-refine\\nstrategy to achieve state-of-the-art quality at a much higher\\nresolution. Other efforts in this space include GPNR [39]\\nand SRT [35], which are parameterized in a similar fash-\\nion to IBRNet [41] and attempt to scale up the image and\\nray transformers. LRF [22] attempts to perform 3D recon-\\nstruction in the latent space of a V AE, bypassing learning\\n3D representation altogether [48]. Finally, the LVSM [19]\\nremoves all 3D priors by simply using one transformer to\\nperform NVS. LVSM performs favorably compared to both\\ngeometry-free and geometry-based feed-forward models.\\n2.3. Synthetic Data\\nRecent efforts have leveraged synthetic data to train exist-\\ning feed-forward NVS methods and investigate its efficacy\\nas a training dataset. However, it is important to note that\\nthe synthetic data in many of these efforts are generated\\nprocedurally from systems like Blender, whereas ours are\\ngenerated from a multi-view diffusion model. Two recent\\nworks LRM-Zero [43] and MegaSynth [18] are examples\\nof models trained either entirely or mostly on procedurally\\ngenerated synthetic data. In LRM-Zero, they demonstrate\\nthat the LRM model can be trained entirely on synthetic\\ndata. However, the synthetic-data-only model shows a sub-\\nstantial decrease in reconstruction quality compared to the\\nreal-world-data equivalent. Improving training data diver-\\nsity using synthetic data for 4D generation has also been\\nexplored in CAT4D [42].\\n3. Background\\nLVSM is a feed-forward NVS method that has no 3D in-\\nductive bias. Since our model builds upon its architecture,\\n3'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Feedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\nEmbedding \\nLayer\\n𝐑d\\n𝐑k\\nPre-Modulate\\nLinear Layer\\n𝐑6d\\nStyle \\nembed\\nPost-Modulate\\nPre-Modulate\\nPost-Modulate\\n 0\\n 1\\nStyle Tokens\\nFeedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\n 0\\n 1\\nEmbedding \\nLayer\\n 𝐑d\\n𝐑k\\nModulate\\nLinear Layer\\n𝐑2d\\nStyle Tokens\\nStyle \\nembed\\nFigure 3.An illustration of the Tok-D transformer block.Our transformer blocks that differentiates between source and target tokens.\\nTok-D transformer modulates the input to all transformer blocks. Tok-D plus transformer modulates the attention and MLP layers.\\nwe outline the details here for clarity. Whereidenotes the\\nimage index andjdenotes the token index, source images\\npatches are written asIs\\nij ∈R p×p×3, source Pl¨ucker coordi-\\nnates patchesP s\\nij ∈R p×p×6, and target Pl¨ucker coordinates\\nPt\\nj ∈R p×p×6. The source images and pl ¨ucker embeddings\\nare tokenized together using a linear layer embedder.\\nSij =Linear([I s\\nij, Ps\\nij]) (1)\\nThe target Pl ¨ucker coordinates are also embedded using a\\nlinear layer.\\nTij =Linear(P t\\nij) (2)\\nFinally, the transformer network is trained to reconstruct the\\ntarget output tokensOt\\nj from the Pl¨ucker patch embeddings.\\nOt\\nj =M(T j|Sij) (3)\\nThe target output tokens are detokenized using a linear\\nlayer which is converted to target image embeddingsT j ∈\\nRp×p×3\\nTj =Linear([O t\\nj]) (4)\\nThe target patches are unpatchified to get the target image\\nT∈R H×W×3 (see Figure 2). The training is supervised\\nusing MSE loss and perceptual loss designed to reconstruct.\\nTransformer BlockConsider a transformer block at\\nlayerl, which includes aMulti-head Self Attentionlayer\\n(SelfAttnl), a Feed-forward network (FFN l), and a Layer\\nNorm operation (LNl). For an input[x s\\nl ,x t\\nl], wherex s\\nl and\\nxt\\nl represent the source and target tokens, the data flow as\\nfollows:\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +SelfAttnl([xs\\nl ,x t\\nl])(5)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +FFNl(LNl([xs\\nl ,x t\\nl])).\\nGiven the basic self attention based transformer blocks in\\nLVSM. At the end of the optimization process there arises a\\nneed for all token outputs of a particular layer to be aligned\\nsince they are processed by the same set of weights. Hence,\\nLVSM inherently has a chance to infuse noise or atifacts\\nthat maybe present in the source images to the target. More-\\nover this alignment also causes some part of the computa-\\ntional power of the model being used to model source token\\ninformation although those tokens are discarded at the last\\nlayer. Hence, we call for a need to distinguish between the\\nsource and target tokens of the transformer network.\\n4. Method\\nOur proposed method consists of two major contributions.\\nFirst, ourToken-Disentangled (Tok-D)transformer block\\nis specialized for NVS and distinguishes information from\\nthe source and target views, leading to more efficient allo-\\ncation of representation capacity. Second, to address the\\nscarcity of multi-view data, we generate synthetic data us-\\ning CAT3D [10] and propose a model training scheme that\\nis robust to artifacts in this synthetic data. In this section,\\nwe describe each component in detail.\\n4.1. Token-Disentangled Transformer\\nIn LVSM, the transformer blocks process source and target\\ntokens in the same manner, even though the source consists\\nof images and Pl ¨ucker rays, while the target includes only\\nPl¨ucker rays. Additionally, source and target image quality\\ncan differ when training with synthetic data. To address this,\\nwe introduce theToken-Disentangled (Tok-D) Transformer\\nblock (see Figure 3), which enables differentiated process-\\ning of source and target tokens through modulation. The\\nTok-D Transformer uses an indicator variable (δ), where\\nδ= 1for target tokens andδ= 0for source tokens, to\\nmodulate tokens based on their origin. This mechanism ex-\\ntracts distinct style vectors and computes specific scale and\\nbias parameters for each layer and token type, allowing for\\nprecise and adaptive token modulation.\\nstyle=Linear(Embed(δ))(6)\\nModl(x) = (1 +σl)x+µ l,where[σ l, µl] =Linearl(style)\\n[xs\\nl ,x t\\nl] =Mods,t\\nl ([xs\\nl ,x t\\nl]) = [Mods\\nl (xs\\nl ),Mod t\\nl(xt\\nl)]\\nModulating the input of each transformer block improves\\nperforamnce. Drawing inspiration from DiT [30], we\\n4'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='extend this modulation to the Attention and MLP lay-\\ners, achieving further improvements. This modulation is\\ntermedpre-modulationif applied before a layer andpost-\\nmodulationif after. Pre-modulation includes both scaling\\nand shifting, and post-modulation involves only scaling.\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl1 ([xs\\nl ,x t\\nl])(7)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl1, σt\\nl1]⊙SelfAttn([ ˆxs\\nl , ˆxt\\nl])\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl2 ([xs\\nl ,x t\\nl])\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl2, σt\\nl2]⊙FFN l(LNl([ˆxs\\nl , ˆxt\\nl]))\\nwhere⊙denotes element-wise multiplication which scales\\nthe corresponding source and target tokens.\\nOur Tok-D transformer block enhances the distinction\\nbetween source and target tokens, as reflected in their dis-\\ntinct feature representations (Figure 6, Section 5.4). This\\nspecialization highlights the superior representational ca-\\npacity of our model. Furthermore, when trained on syn-\\nthetic data (Section 4.2), out-of-distribution artifacts can\\nintroduce quality disparities between source and target to-\\nkens. By leveraging its token-aware architecture, our model\\ndemonstrates greater robustness to these artifacts, resulting\\nin improved performance, as shown in Section 5.3.\\n4.2. Synthetic Data Generation & Training Scheme\\nTraining a naive transformer model with synthetic data can\\nlead to degraded performance rather than improvement due\\nto two key factors: (1) The model struggles to distinguish\\nbetween tokens from source images and target images, al-\\nlowing artifacts from one to propagate into the other dur-\\ning alignment. (2) The model is trained to generate novel\\nviews from sparse input views, and if the target is a syn-\\nthetic image with artifacts, it may learn a distribution bi-\\nased toward unrealistic images. While these issues might\\nnot arise with perfect synthetic data, in-practice synthetic\\ndatasets often contain noise, making the model vulnerable\\nto errors through either mechanism. However, for image-to-\\nmultiview synthesis models like CAT3D, we propose a sim-\\nple yet effective solution: assigning the conditioned image\\nas the target view and the generated views as input views.\\nFormally letI c, Cc denote the input image and camera\\nconditioning used for the multiview diffusion model. We\\nsample additional random spline camera trajectory poses\\nCtgt relative to this particular view, and use the state-of-\\nthe-art multi-view diffusion model CAT3D to generate the\\ntarget viewsI src conditioned on the input conditioning and\\ntarget poses\\nIgen ∼DM(I gen|Cgen, Cc, Ic) (8)\\nHere DM represents inferencing through the state of the art\\ndiffusion model, After obtaining the generated views, we\\nsample 2 generated viewsI src\\nIsrc, Csrc ∼I gen, Cgen (9)\\nand their camera poses as the source imagesI src, Csrc\\nand utilize the conditioned image and its camera as the tar-\\ngetI c, Cc. Sampling the source and target images this way\\nforces the transformer to always generate a realistic image,\\nmaking our model robust to artifacts from synthetic data.\\n5. Experiments\\n5.1. Implementation Details\\nTraining detailsWe perform all experiments on 8 H100\\nGPUs. We use the AdamW optimizer withβparameters\\n0.9and0.95, and we use weight decay with a rate of0.05\\nfor all layers except the normalization layers. Moreover, we\\nuse a linear learning rate scheduler with with a peak learn-\\ning rate of2e −4, and a warmup of 2500 iterations. In total,\\nall experiments have100ktraining iterations. In addition,\\nwe use exponential moving averaging (EMA) with a rate of\\n0.99for stabilizing the training process. Although previous\\nworks required gradient clipping for a stable training pro-\\ncess, our training processes were smooth without a need for\\nan explicit gradient clipping.\\nTraining and Evaluation DatasetsFor scene-level synthe-\\nsis model training, we use Re10K [49], ACID [25] and\\nDL3DV [24] with their originally released train and test\\nsplits. We also perform an experiment where the model\\nis trained together with a mix of all of these datasets. For\\nscene-level synthesis, we follow LVSM and train using 2\\ninput views and test using 6 target views fed one at a time.\\nFor DL3DV dataset evaluation, we choose the farthest cam-\\nera from a randomly selected target view as the input view.\\nThe training and evaluation of DL3DV dataset for in dis-\\ntribution metrics is done using 2 input views and 2 target\\nviews. For cross dataset testing, we use 2 input views and 6\\ntarget views for DL3DV dataset. We use a batch size of 64\\nfor our experiments.\\nSynthetic DataFor generating the synthetic data we use the\\nstate-of-the-art 3D generation model CAT3D. CAT3D was\\ntrained using a single scene dataset Re10K and three object-\\nbased datasets: Objaverse [7], MVImgNet [46] and Co3D\\n[32]. To create synthetic data, we use two variants: one with\\n1 conditioning view and 7 generated views, and another\\nwith 3 conditioning views and 5 generated views. We match\\nthe focal lengths of Re10K and DL3DV during generation.\\nFor the camera trajectory, we sample a random spline tra-\\njectory with a random position rotation matrix, converting it\\ninto ray maps before passing it into the network. As CAT3D\\nis originally trained with a resolution of 512, we convert the\\nimages and camera parameters to a resolution of256before\\npassing them through our network.\\n5'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Input Views LVSM Ours GT\\nFigure 4.Qualitative results on in-distribution datasets.We illustrate the cases Tok-D transformer works better than LVSM. We notice\\nthat we obtain substantial improvement in cases where the novel views needs to reconstruct regions present only in one of the views as\\nshown in the highlighted regions in the images. The results presented here are taken from our in-distribution trained model. We present\\ntwo diffrent views to show that this problem is persistent across views.\\nTable 1.Quantitative comparisons for in-distribution scene synthesis at 256 resolution.LVSM and our method are trained with a\\nbatch size of 64. LVSM results are taken from the original paper rather than our re-implementation. Our method outperforms the previous\\nSOTA method across all exisiting datasets. ( , , ) denotes the first, second and third best results.\\nMethod Venue RealEstate10k [49] ACID [25] DL3DV [24]\\nPSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nGPNR [39] CVPR’23 24.11 0.793 0.255 25.28 0.764 0.332 - - -\\nPixelSplat [4] CVPR’24 25.89 0.858 0.142 28.14 0.839 0.533 - - -\\nMVSplat [6] ECCV’25 26.39 0.869 0.128 28.25 0.843 0.144 17.54 0.529 0.402\\nDepthSplat [44] CVPR’25 27.44 0.887 0.119 - - - 19.05 0.610 0.313\\nLVSM [19] ICLR’25 28.89 0.894 0.108 29.19 0.836 0.095 19.91 0.600 0.273\\nOurs 30.02 0.919 0.058 29.47 0.846 0.086 21.55 0.643 0.208\\n5.2. Scene Synthesis\\nWe evaluate our method qualitatively and quantitatively\\nfor scene synthesis using very recent feed-forward meth-\\nods GPNR, PixelSplat, MVSplat, DepthSplat and LVSM.\\nThese methods were chosen because they outperform con-\\nventional approaches in 2-view reconstruction. Quantita-\\ntive results are shown in Table 1. We observe that Tok-D-\\nPlus outperforms LVSM by 1.2 dB on the Re10K evaluation\\nbenchmark when both models are trained with 8 GPUs. Fur-\\nthermore, despite using only 8 GPUs, our method still sur-\\npasses LVSM trained with 64 GPUs by a margin of 0.2 dB.\\nMoreover we obtain an improvement of 1.6dB over LVSM\\nin a more diverse scene-level dataset, DL3DV [24] dataset\\nas well. We also observe that our performance improvement\\nis0.2in ACID dataset. We emphasize that this happens be-\\ncause ACID has a relatively smaller training and testing set\\nand the dataset is generally clean and easier to reconstruct.\\nWe also provide the corresponding qualitative comparisons\\non Re10K and DL3DV dataset in Figure 4 . Comparing the\\nmain results we find that our method usually outperforms\\nLVSM when the generated content is only visible in one of\\nthe source views. When the camera is far from both views\\nand the information is present only in one of the views, our\\nmethod is still able to extract the relevant content from the\\ncorresponding input image. As can be seen from rows 1\\nand 2, the reconstruction form LVSM fails to reconstruct\\nobjects present in only one of the views, whereas Tok-D\\ntransformer can effectively reconstruct these regions.\\n5.3. Cross-Dataset Scene Synthesis\\nTo analyze the generalization capacity of our method, we\\nevaluate our method trained with Re10K dataset on two dif-\\nferent datasets: ACID and DL3DV [24]. ACID is a dataset\\nwith aerial views similar to Re10K. DL3DV [24] is a di-\\nverse dataset comprising natural scenes and various indoor\\nand outdoor settings. The scene geometry and appearance\\nof DL3DV [24] is very different from Re10k. We test the\\nRe10K and ACID datasets at a resolution of 256×265. For\\ntesting on DL3DV [24], we choose a resolution of 256×448\\nto maintain the original aspect ratio in the DL3DV [24]\\ndataset and well as maintain consistent evaluation settings\\nwith DepthSplat. We choose 2 source views and 6 tar-\\nget views for all of these datasets. Looking closely at the\\nquantitative results on Table 1 and Table 2, we find that the\\nmodel trained on Re10K underperformed the in-distribution\\ntrained model by a small margin. The drop is higher in the\\ncase of DL3DV due to resolution and diversity differences\\nin the datasets. Next we add a small portion of synthetic\\n6'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='LVSM Ours GTInput\\nFigure 5.Out-of-distribution Evaluation:We evaluate our the version of our method fine-tuned on synthetic data and LVSM on DL3DV\\nand ACID (i.e. out-of-distribution datasets). We also evaluate the model with resolutions that were not used during training. We notice that\\nLVSM’s visual quality degrades when substantial camera motion reveals previously-occluded regions.\\nTable 2.Quantitative comparisons for scaling up with synthetic data.We evaluate LVSM and our method, which are both trained with\\na batch size of 64. A mixture of synthesized DL3DV and Re10K data is used for the synthetic tab. For MVSplat and DepthSplat we include\\nthe numbers reported in their papers\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K[49] Synthetic PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nMVSplat [6] ✓ 26.39 0.869 0.128 28.15 0.147 0.841 17.72 0.534 0.371\\nDepthsplat [44] ✓ 27.44 0.887 0.119 - - - 18.90 0.640 0.317\\nLVSM [19] ✓ 28.89 0.894 0.108 28.29 0.809 0.104 20.52 0.621 0.223\\nLVSM [19] ✓ ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nOurs ✓ 30.02 0.910 0.058 29.31 0.838 0.091 21.18 0.652 0.205\\nOurs ✓ ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\ndata comprising about half the size of Re10K dataset and\\nperform training with the new framework. We also retrain\\nLVSM for the same setting. We find thatLVSM’s perfor-\\nmance drops rather than improving when synthetic data is\\nadded. We emphasize that this arises due to the introduc-\\ntion of artifacts during feature alignment. In contrast, we\\nobserve an improvement in quality on our method when a\\nsmall amount of synthetic data is added.\\n5.4. Analysis and Discussion\\nVisualization of source and target features.To visually\\nillustrate the representation alignment problem mentioned\\nin the previous sections, we visualize the 3 channel PCA\\nof each transformer block output after unpatchifying for all\\n24 layers of LVSM and our method in Figure 6. The first\\nrow shows the first 6 layer outputs, second row shows layer\\n6-12, and so on. We can see that for a particular scene the\\nsource and target layer tokens are aligned at all layers even\\nthough the training objective is to reconstruct the target.\\nThis causes inefficient usage of the transformer parameters\\nto maintain the source information throughout the layers.\\nMoreover this also makes the model prone tonoise in the\\nsource data. However, with our Tok-D transformer there is\\nno alignment and the source information is infused much\\nearlier, leaving more room for the transformer blocks to re-\\nconstruct the target. Another important observation is that\\nalthough both source image and Pl¨ucker coordinates are fed\\nas input to the source, the source tokens look similar to the\\nPl¨ucker coordinates. Whereas in our case the image compo-\\nnents in the source PCA components leading to much more\\neffective information extraction from each source token.\\nImpact of additional real data.Incorporating synthetic\\ndata into the training process facilitates the introduction of\\ndiverse scenes and camera motion, enhancing model gener-\\nalizability. While the proposed Tok-D transformer demon-\\n7'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='(a)\\nTarget\\n (b)\\nSource\\n (c) LVSM Target PCA\\n (d) LVSM Source PCA\\n (e) Ours Source PCA\\n (f) Ours Target PCA\\nFigure 6.A visualization of the principal components of transformer layer outputs for source and target of LVSM. The 24 images\\nin each subfigure show the layer output of each layer of the transformer. LVSM features for source and target images looks similar even\\nthough the source is conditioned with image and Pl ¨ucker coordinates and target is conditioned with Pl ¨ucker coordinates alone. This leads\\nto inefficient transformer usage requiring explicit alignment of source and target features across different layers\\nTable 3.Ablation studies on scaling up with more real data.Although including synthetic data in training is helpful for improving\\nquality, including additional real data significantly improves reconstruction quality.\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K [49]+Synthetic DL3DV [24]PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nLVSM [19] ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nLVSM [19] ✓ ✓ 28.10 0.892 0.073 28.79 0.826 0.096 21.37 0.665 0.196\\nOurs ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\nOurs ✓ ✓ 29.78 0.917 0.0604 30.13 0.857 0.082 23.14 0.726 0.156\\nTable 4.Ablation analysisWe analyze the performance improve-\\nment of our design choices.PreandPostdemonstrate the effects\\nof including or not including pre/post-modulation.\\nPre Post Whole Attn MLP PSNR↑ SSIM↑ LPIPS↓\\n28.50 0.893 0.070\\n✓ ✓ 29.69 0.911 0.063\\n✓ ✓ ✓ 28.51 0.894 0.070\\n✓ ✓ ✓ ✓ 30.02 0.918 0.058\\nstrates reduced sensitivity to synthetic data artifacts and in-\\ncreased generative diversity, its photorealistic reconstruc-\\ntion performance remains comparable to the baseline model\\ntrained solely on real data. To investigate the impact of\\naugmenting the training dataset with additional real data,\\nwe integrated the DL3DV dataset into the existing exper-\\nimental setup. This modification resulted in a significant\\nimprovement in photorealistic reconstruction, as evidenced\\nby a substantial increase in PSNR on the ACID dataset. Fur-\\nthermore, the relative performance gains observed with our\\nmodel, compared to LVSM, were considerably greater, sug-\\ngesting a reduced susceptibility to noise.\\n5.5. Ablation Studies\\nWe analyze the impact of various design choices in the net-\\nwork. Specifically, we examine three aspects: (1) The effect\\nof modulation in different parts of the network, (2) The role\\nof EMA in performance, (3) Number of input views.\\nImpact of modulation at different locations of Tok-D\\ntransformer.We examine the effect of modulating differ-\\nent parts of the network. For this, we consider four differ-\\nent cases. We present the corresponding results in Table 4.\\nHaving a common modulation premodulation worked better\\nthan separate premodulation for both layers.\\nImpact of EMA.We also observe that performing Expo-\\nnential moving average (EMA) [13] during training results\\nin a performance boost for the base model. For the sake of\\nTable 5.Effect of EMA on runtime performance and quality.\\nComparison performed on Re10k.\\nMethod TrainRenderGFLOPs No EMA With EMA(ms) (ms) PSNR SSIM LPIPSPSNR SSIM LPIPS\\nLVSM-1024706.1171.6 2896.8827.68 0.88 0.07728.65 0.90 0.070Ours 734.6174.4 2900.7828.75 0.90 0.06430.02 0.92 0.058\\nTable 6.Effect of adding more source views. Our method works\\nwell as additional source views are introduced.\\nMethod 2 views 4 views 8 views\\nPSNR SSIM LPIPSPSNR SSIM LPIPSPSNR SSIM LPIPS\\nOurs 30.02 0.92 0.058 31.51 0.94 0.048 33.09 0.94 0.042\\nconsistency, we show the results of our model and our re-\\nimplementation of LVSM with 1024 channels trained with\\nand without EMA in Table 5.\\nImpact of number of source frames.Our model scales\\nwith the number of input views and results in better re-\\nconstruction quality when more input views are fed to the\\nmodel to the model as presented in Table 6.\\n6. Conclusion\\nIn this paper, we introduce a new approach to scaling up\\nNVS by addressing two key limitations in existing mod-\\nels: efficiency and diversity. To enhance the efficiency\\nof transformer-based NVS models, we propose the Token-\\nDisentangled (Tok-D) Transformer, which reduces redun-\\ndancies and improves data efficiency, enabling higher re-\\nconstruction quality with less compute. Additionally, the\\nTok-D Transformer mitigates training artifacts through its\\ndisentangling property, allowing for effective scaling us-\\ning synthetic data. Incorporating synthetic data into train-\\ning significantly improves cross-dataset performance com-\\npared to existing models. By integrating the Tok-D Trans-\\nformer and synthetic data, we achieve state-of-the-art re-\\nsults across three large-scale NVS benchmarks, surpassing\\nprevious methods with lower computational cost and by a\\nsubstantial margin.\\n8'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Benjamin Attal, Jia-Bin Huang, Michael Zollh ¨ofer, Johannes\\nKopf, and Changil Kim. Learning neural light fields with\\nray-space embedding. InProceedings of the IEEE/CVF Con-\\nference on Computer Vision and Pattern Recognition, pages\\n19819–19829, 2022. 2\\n[2] Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased\\ngrid-based neural radiance fields. InProceedings of the\\nIEEE/CVF International Conference on Computer Vision,\\npages 19697–19705, 2023. 2\\n[3] Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P.\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased grid-\\nbased neural radiance fields.ICCV, 2023. 3\\n[4] David Charatan, Sizhe Lester Li, Andrea Tagliasacchi, and\\nVincent Sitzmann. pixelsplat: 3d gaussian splats from image\\npairs for scalable generalizable 3d reconstruction. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 19457–19467, 2024. 2, 3, 6\\n[5] Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and\\nHao Su. Tensorf: Tensorial radiance fields. InEuropean\\nConference on Computer Vision (ECCV), 2022. 2, 3\\n[6] Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang,\\nMarc Pollefeys, Andreas Geiger, Tat-Jen Cham, and Jianfei\\nCai. Mvsplat: Efficient 3d gaussian splatting from sparse\\nmulti-view images. InEuropean Conference on Computer\\nVision, pages 370–386. Springer, 2024. 6, 7\\n[7] Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs,\\nOscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana\\nEhsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse:\\nA universe of annotated 3d objects. InProceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 13142–13153, 2023. 5\\n[8] John Flynn, Michael Broxton, Lukas Murmann, Lucy Chai,\\nMatthew DuVall, Cl ´ement Godard, Kathryn Heal, Srinivas\\nKaza, Stephen Lombardi, Xuan Luo, et al. Quark: Real-time,\\nhigh-resolution, and general neural view synthesis.ACM\\nTransactions on Graphics (TOG), 43(6):1–20, 2024. 3\\n[9] Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong\\nChen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels:\\nRadiance fields without neural networks. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 5501–5510, 2022. 3\\n[10] Ruiqi Gao, Aleksander Holynski, Philipp Henzler, Arthur\\nBrussee, Ricardo Martin Brualla, Pratul Srinivasan, Jonathan\\nBarron, and Ben Poole. Cat3d: Create anything in 3d with\\nmulti-view diffusion models.Advances in Neural Informa-\\ntion Processing Systems, 37:75468–75494, 2024. 2, 4\\n[11] Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and\\nMichael F. Cohen. The lumigraph. InProceedings of the\\n23rd Annual Conference on Computer Graphics and Inter-\\nactive Techniques, page 43–54, New York, NY , USA, 1996.\\nAssociation for Computing Machinery. 2\\n[12] Albert Gu and Tri Dao. Mamba: Linear-time sequence mod-\\neling with selective state spaces, 2024. 12\\n[13] David Haynes, Steven Corns, and Ganesh Kumar Venayag-\\namoorthy. An exponential moving average algorithm. In\\n2012 IEEE Congress on Evolutionary Computation, pages\\n1–8. IEEE, 2012. 8\\n[14] Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and\\nQifeng Chen. Latent video diffusion models for high-fidelity\\nlong video generation.arXiv preprint arXiv:2211.13221,\\n2022. 2\\n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-\\nfusion probabilistic models.Advances in neural information\\nprocessing systems, 33:6840–6851, 2020. 2\\n[16] Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou,\\nDifan Liu, Feng Liu, Kalyan Sunkavalli, Trung Bui, and Hao\\nTan. LRM: Large reconstruction model for single image to\\n3d. InThe Twelfth International Conference on Learning\\nRepresentations, 2024. 2, 3\\n[17] Binbin Huang, Zehao Yu, Anpei Chen, Andreas Geiger, and\\nShenghua Gao. 2d gaussian splatting for geometrically accu-\\nrate radiance fields. InSpecial Interest Group on Computer\\nGraphics and Interactive Techniques Conference Conference\\nPapers, page 1–11. ACM, 2024. 3\\n[18] Hanwen Jiang, Zexiang Xu, Desai Xie, Ziwen Chen, Haian\\nJin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Ji-\\nuxiang Gu, Qixing Huang, Georgios Pavlakos, and Hao Tan.\\nMegasynth: Scaling up 3d scene reconstruction with syn-\\nthesized data. InProceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition (CVPR), pages\\n16441–16452, 2025. 3\\n[19] Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi,\\nTianyuan Zhang, Fujun Luan, Noah Snavely, and Zexiang\\nXu. LVSM: A large view synthesis model with minimal 3d\\ninductive bias. InThe Thirteenth International Conference\\non Learning Representations, 2025. 2, 3, 6, 7, 8\\n[20] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk ¨uhler,\\nand George Drettakis. 3d gaussian splatting for real-time\\nradiance field rendering.ACM Trans. Graph., 42(4):139–1,\\n2023. 2, 3\\n[21] Shakiba Kheradmand, Delio Vicini, George Kopanas,\\nDmitry Lagun, Kwang Moo Yi, Mark Matthews, and An-\\ndrea Tagliasacchi. Stochasticsplats: Stochastic rasterization\\nfor sorting-free 3d gaussian splatting, 2025. 3\\n[22] Diederik P Kingma, Max Welling, et al. Auto-encoding vari-\\national bayes, 2013. 3\\n[23] Marc Levoy and Pat Hanrahan. Light field rendering. In\\nProceedings of the 23rd Annual Conference on Computer\\nGraphics and Interactive Techniques, page 31–42, New\\nYork, NY , USA, 1996. Association for Computing Machin-\\nery. 2\\n[24] Lu Ling, Yichen Sheng, Zhi Tu, Wentian Zhao, Cheng Xin,\\nKun Wan, Lantao Yu, Qianyu Guo, Zixun Yu, Yawen Lu,\\net al. Dl3dv-10k: A large-scale scene dataset for deep\\nlearning-based 3d vision. InProceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition,\\npages 22160–22169, 2024. 2, 5, 6, 7, 8\\n[25] Andrew Liu, Richard Tucker, Varun Jampani, Ameesh\\nMakadia, Noah Snavely, and Angjoo Kanazawa. Infinite na-\\nture: Perpetual view generation of natural scenes from a sin-\\ngle image. InProceedings of the IEEE/CVF International\\nConference on Computer Vision, pages 14458–14467, 2021.\\n2, 5, 6, 7, 8\\n9'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[26] Lingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, and\\nChristian Theobalt. Neural sparse voxel fields.Advances\\nin Neural Information Processing Systems, 33:15651–15663,\\n2020. 2, 3\\n[27] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,\\nJonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:\\nRepresenting scenes as neural radiance fields for view syn-\\nthesis. InEuropean conference on computer vision, 2020. 2,\\n3\\n[28] Thomas M ¨uller, Alex Evans, Christoph Schied, and Alexan-\\nder Keller. Instant neural graphics primitives with a mul-\\ntiresolution hash encoding.ACM transactions on graphics\\n(TOG), 41(4):1–15, 2022. 2, 3\\n[29] Alexander Quinn Nichol and Prafulla Dhariwal. Improved\\ndenoising diffusion probabilistic models. InInternational\\nconference on machine learning, pages 8162–8171. PMLR,\\n2021. 2\\n[30] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. InProceedings of the IEEE/CVF inter-\\nnational conference on computer vision, pages 4195–4205,\\n2023. 4\\n[31] Lukas Radl, Michael Steiner, Mathias Parger, Alexan-\\nder Weinrauch, Bernhard Kerbl, and Markus Steinberger.\\nStopThePop: Sorted Gaussian Splatting for View-Consistent\\nReal-time Rendering.ACM Transactions on Graphics, 4\\n(43), 2024. 3\\n[32] Jeremy Reizenstein, Roman Shapovalov, Philipp Henzler,\\nLuca Sbordone, Patrick Labatut, and David Novotny. Com-\\nmon objects in 3d: Large-scale learning and evaluation\\nof real-life 3d category reconstruction. InProceedings of\\nthe IEEE/CVF international conference on computer vision,\\npages 10901–10911, 2021. 5\\n[33] Robin Rombach, Andreas Blattmann, Dominik Lorenz,\\nPatrick Esser, and Bj ¨orn Ommer. High-resolution image\\nsynthesis with latent diffusion models. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 10684–10695, 2022. 2\\n[34] Chitwan Saharia, William Chan, Saurabh Saxena, Lala\\nLi, Jay Whang, Emily L Denton, Kamyar Ghasemipour,\\nRaphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans,\\net al. Photorealistic text-to-image diffusion models with deep\\nlanguage understanding.Advances in neural information\\nprocessing systems, 35:36479–36494, 2022. 2\\n[35] Mehdi SM Sajjadi, Henning Meyer, Etienne Pot, Urs\\nBergmann, Klaus Greff, Noha Radwan, Suhani V ora, Mario\\nLuˇci´c, Daniel Duckworth, Alexey Dosovitskiy, et al. Scene\\nrepresentation transformer: Geometry-free novel view syn-\\nthesis through set-latent scene representations. InProceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 6229–6238, 2022. 3\\n[36] Yichun Shi, Peng Wang, Jianglong Ye, Long Mai, Kejie Li,\\nand Xiao Yang. MVDream: Multi-view diffusion for 3d gen-\\neration. InThe Twelfth International Conference on Learn-\\ning Representations, 2024. 2\\n[37] Vincent Sitzmann, Semon Rezchikov, Bill Freeman, Josh\\nTenenbaum, and Fredo Durand. Light field networks: Neu-\\nral scene representations with single-evaluation rendering.\\nAdvances in Neural Information Processing Systems, 34:\\n19313–19325, 2021. 2\\n[38] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-\\nhishek Kumar, Stefano Ermon, and Ben Poole. Score-based\\ngenerative modeling through stochastic differential equa-\\ntions. InInternational Conference on Learning Represen-\\ntations, 2021. 2\\n[39] Mohammed Suhail, Carlos Esteves, Leonid Sigal, and\\nAmeesh Makadia. Generalizable patch-based neural render-\\ning. InEuropean Conference on Computer Vision, pages\\n156–174. Springer, 2022. 2, 3, 6\\n[40] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku\\nKomura, and Wenping Wang. Neus: Learning neural im-\\nplicit surfaces by volume rendering for multi-view recon-\\nstruction.Advances in Neural Information Processing Sys-\\ntems, 34:27171–27183, 2021. 2\\n[41] Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P\\nSrinivasan, Howard Zhou, Jonathan T Barron, Ricardo\\nMartin-Brualla, Noah Snavely, and Thomas Funkhouser. Ibr-\\nnet: Learning multi-view image-based rendering. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 4690–4699, 2021. 3\\n[42] Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi\\nZheng, Jonathan T Barron, and Aleksander Holynski. Cat4d:\\nCreate anything in 4d with multi-view video diffusion mod-\\nels. InProceedings of the Computer Vision and Pattern\\nRecognition Conference, pages 26057–26068, 2025. 3\\n[43] Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, Zexiang Xu, Yi\\nZhou, Soren Pirk, Arie Kaufman, Xin Sun, and Hao Tan.\\nLRM-zero: Training large reconstruction models with syn-\\nthesized data. InThe Thirty-eighth Annual Conference on\\nNeural Information Processing Systems, 2024. 3\\n[44] Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann\\nBlum, Daniel Barath, Andreas Geiger, and Marc Pollefeys.\\nDepthsplat: Connecting gaussian splatting and depth. InPro-\\nceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR), pages 16453–16463, 2025.\\n2, 6, 7\\n[45] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V ol-\\nume rendering of neural implicit surfaces, 2021. 2\\n[46] Xianggang Yu, Mutian Xu, Yidan Zhang, Haolin Liu,\\nChongjie Ye, Yushuang Wu, Zizheng Yan, Chenming Zhu,\\nZhangyang Xiong, Tianyou Liang, et al. Mvimgnet: A\\nlarge-scale dataset of multi-view images. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 9150–9161, 2023. 5\\n[47] Kai Zhang, Sai Bi, Hao Tan, Yuanbo Xiangli, Nanxuan Zhao,\\nKalyan Sunkavalli, and Zexiang Xu. Gs-lrm: Large recon-\\nstruction model for 3d gaussian splatting.European Confer-\\nence on Computer Vision, 2024. 3\\n[48] Chaoyi Zhou, Xi Liu, Feng Luo, and Siyu Huang. Latent\\nradiance fields with 3d-aware 2d representations. InThe\\nThirteenth International Conference on Learning Represen-\\ntations, 2025. 3\\n[49] Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe,\\nand Noah Snavely. Stereo magnification: learning view syn-\\nthesis using multiplane images.ACM Trans. Graph., 37(4),\\n2018. 2, 5, 6, 7, 8\\n10'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[50] Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang,\\nWenyu Liu, and Xinggang Wang. Vision mamba: Efficient\\nvisual representation learning with bidirectional state space\\nmodel, 2024. 12\\n7. Design choices\\nWe provide further details of the exact transformer model\\nused here.Transformer blocksWe find the claims regard-\\ning the naive transformer architecture to be unstable for im-\\nage generative tasks to be true. We use QK-Norm to stabi-\\nlize the transformer block. We use24transformer blocks\\nwith an embedding dimension of1024. In addition to this,\\ndifferent from LVSM, we use attention biases at all layers\\nand include the bias for the last transformer block, as we\\nfind this design choice particularly stable with linear learn-\\ning rate decay. We use a patch size of 8 for all experiments.\\n7.1. Enhancing 3D generative models for 3D consis-\\ntent generation\\nThe use of diffusion models has been widely explored for\\ngenerating 3D scenes. Multiple works in the literature\\nadapt pretrained text-to-image and image-to-video models\\nfor 3D-consistent scene generation. Most of these works\\ncondition the diffusion model on camera parameters and\\nlearn the conditional distribution of multiple views given the\\ncamera poses. Given the ability to cherry-pick and sample\\nthrough the diffusion model multiple times, these models\\nproduce high-quality results. However, existing 3D scene\\ngeneration models cannot mass-produce synthetic data for\\nfine-tuning substream models for high-fidelity generation.\\nUntil now, no generalizable models with high-fidelity re-\\nsults have been proposed that can directly utilize the data\\ngenerated by diffusion models. We argue that this draw-\\nback is caused by a lack of analysis of the inference-time\\ngeneration process of diffusion models. Although extensive\\nstudies have been performed on different training strategies\\nfor 3D-consistent generation using diffusion models, much\\nless effort has been put into improving inference-time gen-\\neration quality.\\nMost 3D generative models generateNviews of a scene,\\neach of dimension(H×W×C), in parallel to preserve\\n3D consistency. The generation process starts with random\\nisotropic Gaussian noise of dimensionN×H×W×C,\\nwhich undergoes a diffusion process ofTsteps. This either\\nconverts it into a latent representation, which is then de-\\ncoded by a V AE decoder to produce multiview images, or\\ngenerates images directly. These multiview images are fur-\\nther used to train a NeRF or a Gaussian Splat model to gen-\\nerate novel views of the scene. When the diffusion model\\ngenerates high-quality, 3D-consistent images, this frame-\\nwork works perfectly. However, in reality, diffusion models\\nare sensitive to input noise. Even for the simple case of\\nimage generation, different noise inputs produce different\\nquality results. Recent works have shed light on inference-\\ntime scaling laws for generation, claiming that the quality of\\ndiffusion model outputs can be controlled by selecting the\\ncorrect input noise via rejection sampling. Similar claims\\nhave been made for video generation models, where per-\\nformance improves significantly by refining the input noise\\nschedule.\\nTo understand this, consider a toy example: Suppose we\\nwant to generate an image (I 1) using the diffusion model\\nconditioned on a text prompt. Starting with Gaussian noise\\nN1, if we want to generate another image (I2) close to (I1),\\nthe desired noise is most likely closer toN1. Previous works\\nhave demonstrated enhanced video generation results by se-\\nlecting starting noises that are close across different frames.\\nIn our case, we use the image-to-multiview variant of\\nCAT3D as the base model for generating multiview images.\\nFor choosing the initial noise, we follow a specific heuris-\\ntic. Specifically, we ensure that the noise across different\\nviews remains 3D-consistent. CAT3D is a multiview diffu-\\nsion model that generates eight views simultaneously, con-\\nditioned on the camera poses. CAT3D allows conditioning\\non a particular view to generate the remaining views. Given\\nthe view to be conditioned, we select a random noise for\\nthis view, denoted asV 1, with its noise represented asN 1\\nand the corresponding rotation-translation matrices denoted\\nasR 1, t1. To estimate the starting noise for other views, we\\nperform a warping operation onN 1, denoted by:\\nNi =warp(N 1, inv([Ri, ti])[R1, t1]) (10)\\nwhere the warp operation transforms the coordinates of\\nN1 toN i. However, we noticed that such a warping op-\\neration fails in regions outside the scene. To handle these\\ncases while enhancing consistency, we marginally modify\\nthe noise. Specifically, for these cases, we assign the noise\\nas:\\nN2 =αN 1 + (1−α)N(0, I) (11)\\nThus, our effective starting noise is defined as:\\nNfinal =\\n(\\nN1,overlapping regions\\nN2,non overlapping regions\\nWe perform the effective noising operation parallely with\\nrespect to the reference view. First we take view 1, warp to\\nview 2. then add noise, then we Although we use CAT3D,\\nour method is generalizable across any 3D scene generation\\nmodel.\\nUnderstanding the value that synthetic data from gen-\\nerative models can bring, we propose a method to en-\\nhance diffusion-based 3D generative models to produce\\nhigh-quality, 3D-consistent results.\\n11'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='7.2. Loss functions\\nSimilar to LVSM, we utilize Mean Square Error (MSE) loss\\nfor training our network. Instead of using Perceptual Loss,\\nwe utilize LPIPS loss for training. Given the ground-truth\\ntarget view of dimension ˆI∈R H×W×C and the recon-\\nstructed target viewI, the effective objective function used\\nfor optimization is defined as:\\nL=MSE(I, ˆI) +λ·LP IP S(I,ˆI) (12)\\nwhereλis a scaling factor set to0.5for all experiments.\\n7.3. Emergent Properties\\nOne surprisingemergent propertyof our newly proposed\\ntransformer block is its ability to disentangle the source\\nand target tokens, which allows it to scale better for syn-\\nthetic data compared to a naive transformer block. We\\npresent these results in Figure X, where we observe sig-\\nnificant improvements. We hypothesize that this emergent\\nproperty arises because synthetic data is generally prone to\\nartifacts and out-of-distribution noise. When transformer\\nblocks cannot distinguish between source and target tokens,\\nthe model learns using both real and synthetic data, leading\\nto reconstructions that inherit these artifacts. However, in\\nour case, only the relevant information from clean images\\nis used for backpropagation, allowing the model to utilize\\nuseful context from synthetic data while discarding artifacts\\nduring token fusion for target view generation.\\n8. Limitations\\nOur model struggles when regions occluded in the source\\nimages become visible in the target view. As shown in Fig-\\nure 17, when a new object enters the scene, the model hallu-\\ncinates the affected region. We argue that this phenomenon\\nis inherently ill-posed and lacks a definitive solution. Ad-\\nditionally, the model uses a token size of 8 for all blocks,\\nresulting in 1024 tokens per source image, which demands\\nsignificant memory. We leave further architectural opti-\\nmizations, such as hierarchical transformers and more ef-\\nficient networks like linear attention and state-space models\\n(e.g., Mamba [12], [50]), for future work.\\n9. Failure cases of our method\\nWe notice that our method contains two main failure modes\\n(1) when an new object comes into the view in between the\\nconditioned frames. (2) When too many shiny artifacts are\\npresent in the image\\n12'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 7.Figure illustrating results from DL3DV dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n13'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 8.Figure illustrating results from Re10k dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n14'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 9.Figure illustrating results from ACID dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n15'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 10.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 11.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n16'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 12.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 13.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n17'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 14.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 15.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and\\n18'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 16.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 17.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n19'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 18.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 19.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n20'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 20.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 21.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene moreover, our method also fails to reconstruct properly when there are some shiny obejcts in the scene. Figure ordering is OURS,\\nGT, DIFF\\n21')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5903636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # Show example of a chunk\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c0fcd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 53 documents into 238 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "...\n",
      "Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='mechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='best models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='sequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='In this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='into a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='dot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV\\ni ∈ Rdmodel×dv\\nand WO ∈ Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='The Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='encoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='P Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='One is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='or O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='and semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.8 2.3 · 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='the competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='inference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='for both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='comments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='and interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Ray: A Distributed Framework for Emerging AI Applications\\nPhilipp Moritz∗, Robert Nishihara ∗, Stephanie Wang, Alexey Tumanov, Richard Liaw,\\nEric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, Ion Stoica\\nUniversity of California, Berkeley\\nAbstract\\nThe next generation of AI applications will continuously\\ninteract with the environment and learn from these inter-\\nactions. These applications impose new and demanding\\nsystems requirements, both in terms of performance and\\nﬂexibility. In this paper, we consider these requirements\\nand present Ray—a distributed system to address them.\\nRay implements a uniﬁed interface that can express both\\ntask-parallel and actor-based computations, supported by\\na single dynamic execution engine. To meet the perfor-\\nmance requirements, Ray employs a distributed scheduler\\nand a distributed and fault-tolerant store to manage the\\nsystem’s control state. In our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='and a distributed and fault-tolerant store to manage the\\nsystem’s control state. In our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and\\nbetter performance than existing specialized systems for\\nseveral challenging reinforcement learning applications.\\n1 Introduction\\nOver the past two decades, many organizations have been\\ncollecting—and aiming to exploit—ever-growing quanti-\\nties of data. This has led to the development of a plethora\\nof frameworks for distributed data analysis, including\\nbatch [20, 64, 28], streaming [15, 39, 31], and graph [34,\\n35, 24] processing systems. The success of these frame-\\nworks has made it possible for organizations to analyze\\nlarge data sets as a core part of their business or scientiﬁc\\nstrategy, and has ushered in the age of “Big Data. ”\\nMore recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (AI) or machine learning (ML) techniques [30].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='More recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (AI) or machine learning (ML) techniques [30].\\nThe paradigm case is that of supervised learning, where\\ndata points are accompanied by labels, and where the\\nworkhorse technology for mapping data points to labels\\nis provided by deep neural networks. The complexity of\\nthese deep networks has led to another ﬂurry of frame-\\nworks that focus on the training of deep neural networks\\n∗equal contribution\\nand their use in prediction. These frameworks often lever-\\nage specialized hardware (e.g., GPUs and TPUs), with the\\ngoal of reducing training time in a batch setting. Examples\\ninclude TensorFlow [7], MXNet [18], and PyTorch [46].\\nThe promise of AI is, however, far broader than classi-\\ncal supervised learning. Emerging AI applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='cal supervised learning. Emerging AI applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-\\ntions to accomplish long-term goals [8, 43]. They must\\naim not only to exploit the data gathered, but also to ex-\\nplore the space of possible actions. These broader require-\\nments are naturally framed within the paradigm of rein-\\nforcement learning (RL). RL deals with learning to oper-\\nate continuously within an uncertain environment based\\non delayed and limited feedback [56]. RL-based systems\\nhave already yielded remarkable results, such as Google’s\\nAlphaGo beating a human world champion [54], and are\\nbeginning to ﬁnd their way into dialogue systems, UA Vs\\n[42], and robotic manipulation [25, 60].\\nThe central goal of an RL application is to learn a\\npolicy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. Finding ef-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='policy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. Finding ef-\\nfective policies in large-scale applications requires three\\nmain capabilities. First, RL methods often rely on simula-\\ntion to evaluate policies. Simulations make it possible to\\nexplore many different choices of action sequences and to\\nlearn about the long-term consequences of those choices.\\nSecond, like their supervised learning counterparts, RL al-\\ngorithms need to perform distributed training to improve\\nthe policy based on data generated through simulations or\\ninteractions with the physical environment. Third, poli-\\ncies are intended to provide solutions to control problems,\\nand thus it is necessary to serve the policy in interactive\\nclosed-loop and open-loop control scenarios.\\nThese characteristics drive new systems requirements:\\na system for RL must support ﬁne-grained computations'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='closed-loop and open-loop control scenarios.\\nThese characteristics drive new systems requirements:\\na system for RL must support ﬁne-grained computations\\n(e.g., rendering actions in milliseconds when interacting\\nwith the real world, and performing vast numbers of sim-\\narXiv:1712.05889v2  [cs.DC]  30 Sep 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ulations), must support heterogeneity both in time (e.g.,\\na simulation may take milliseconds or hours) and in re-\\nsource usage (e.g., GPUs for training and CPUs for simu-\\nlations), and must support dynamic execution, as results\\nof simulations or interactions with the environment can\\nchange future computations. Thus, we need a dynamic\\ncomputation framework that handles millions of hetero-\\ngeneous tasks per second at millisecond-level latencies.\\nExisting frameworks that have been developed for\\nBig Data workloads or for supervised learning work-\\nloads fall short of satisfying these new requirements for\\nRL. Bulk-synchronous parallel systems such as Map-\\nReduce [20], Apache Spark [64], and Dryad [28] do not\\nsupport ﬁne-grained simulation or policy serving. Task-\\nparallel systems such as CIEL [40] and Dask [48] provide\\nlittle support for distributed training and serving. The\\nsame is true for streaming systems such as Naiad [ 39]\\nand Storm [31]. Distributed deep-learning frameworks'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='little support for distributed training and serving. The\\nsame is true for streaming systems such as Naiad [ 39]\\nand Storm [31]. Distributed deep-learning frameworks\\nsuch as TensorFlow [7] and MXNet [18] do not naturally\\nsupport simulation and serving. Finally, model-serving\\nsystems such as TensorFlow Serving [6] and Clipper [19]\\nsupport neither training nor simulation.\\nWhile in principle one could develop an end-to-end so-\\nlution by stitching together several existing systems (e.g.,\\nHorovod [53] for distributed training, Clipper [ 19] for\\nserving, and CIEL [40] for simulation), in practice this ap-\\nproach is untenable due to thetight coupling of these com-\\nponents within applications. As a result, researchers and\\npractitioners today build one-off systems for specialized\\nRL applications [58, 41, 54, 44, 49, 5]. This approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='RL applications [58, 41, 54, 44, 49, 5]. This approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing\\nstandard systems challenges like scheduling, fault toler-\\nance, and data movement onto each application.\\nIn this paper, we propose Ray, a general-purpose\\ncluster-computing framework that enables simulation,\\ntraining, and serving for RL applications. The require-\\nments of these workloads range from lightweight and\\nstateless computations, such as for simulation, to long-\\nrunning and stateful computations, such as for training.\\nTo satisfy these requirements, Ray implements a uniﬁed\\ninterface that can express both task-parallel and actor-\\nbased computations. Tasks enable Ray to efﬁciently and\\ndynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. In contrast, actors enable Ray to efﬁciently'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='dynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. In contrast, actors enable Ray to efﬁciently\\nsupport stateful computations, such as model training, and\\nexpose shared mutable state to clients, (e.g., a parameter\\nserver). Ray implements the actor and the task abstrac-\\ntions on top of a single dynamic execution engine that is\\nhighly scalable and fault tolerant.\\nTo meet the performance requirements, Ray distributes\\ntwo components that are typically centralized in existing\\nframeworks [64, 28, 40]: (1) the task scheduler and (2) a\\nstate (si+1) \\n(observation)\\nreward (ri+1)\\naction (ai)\\nPolicy \\nimprovement\\n(e.g., SGD)\\ntrajectory: s0, (s1, r1), … , (sn, rn)\\npolicy\\nTraining Serving Simulation\\nPolicy\\nevaluation \\nEnvironment\\nAgent\\nFigure 1: Example of an RL system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. This allows Ray to sched-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Policy\\nevaluation \\nEnvironment\\nAgent\\nFigure 1: Example of an RL system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. This allows Ray to sched-\\nule millions of tasks per second with millisecond-level\\nlatencies. Furthermore, Ray provides lineage-based fault\\ntolerance for tasks and actors, and replication-based fault\\ntolerance for the metadata store.\\nWhile Ray supports serving, training, and simulation\\nin the context of RL applications, this does not mean that\\nit should be viewed as a replacement for systems that pro-\\nvide solutions for these workloads in other contexts. In\\nparticular, Ray does not aim to substitute for serving sys-\\ntems like Clipper [ 19] and TensorFlow Serving [ 6], as\\nthese systems address a broader set of challenges in de-\\nploying models, including model management, testing,\\nand model composition. Similarly, despite its ﬂexibility,\\nRay is not a substitute for generic data-parallel frame-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ploying models, including model management, testing,\\nand model composition. Similarly, despite its ﬂexibility,\\nRay is not a substitute for generic data-parallel frame-\\nworks, such as Spark [64], as it currently lacks the rich\\nfunctionality and APIs (e.g., straggler mitigation, query\\noptimization) that these frameworks provide.\\nWe make the following contributions:\\n•We design and build the ﬁrst distributed frame-\\nwork that uniﬁes training, simulation, and serving—\\nnecessary components of emerging RL applications.\\n•To support these workloads, we unify the actor and\\ntask-parallel abstractions on top of a dynamic task\\nexecution engine.\\n•To achieve scalability and fault tolerance, we pro-\\npose a system design principle in which control state\\nis stored in a sharded metadata store and all other\\nsystem components are stateless.\\n•To achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 Motivation and Requirements\\nWe begin by considering the basic components of an RL'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='system components are stateless.\\n•To achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 Motivation and Requirements\\nWe begin by considering the basic components of an RL\\nsystem and ﬂeshing out the key requirements for Ray. As\\nshown in Figure 1, in an RL setting, an agent interacts\\nrepeatedly with the environment. The goal of the agent\\nis to learn a policy that maximizes a reward. A policy is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='// evaluate policyby interacting with env. (e.g., simulator)rollout(policy, environment):trajectory=[]state= environment.initial_state()while(notenvironment.has_terminated()):action= policy.compute(state) // Servingstate,reward= environment.step(action) // Simulationtrajectory.append(state,reward)returntrajectory// improve policy iteratively until it convergestrain_policy(environment):policy= initial_policy()while(policyhas not converged):trajectories = []forifrom1 tok:// evaluate policyby generating krolloutstrajectories.append(rollout(policy, environment))// improve policypolicy= policy.update(trajectories) // Trainingreturnpolicy\\nFigure 2: Typical RL pseudocode for learning a policy.\\na mapping from the state of the environment to a choice\\nof action. The precise deﬁnitions of environment, agent,\\nstate, action, and reward are application-speciﬁc.\\nTo learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='state, action, and reward are application-speciﬁc.\\nTo learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement.\\nTo evaluate the policy, the agent interacts with the envi-\\nronment (e.g., with a simulation of the environment) to\\ngenerate trajectories, where a trajectory consists of a se-\\nquence of (state, reward) tuples produced by the current\\npolicy. Then, the agent uses these trajectories to improve\\nthe policy; i.e., to update the policy in the direction of the\\ngradient that maximizes the reward. Figure 2 shows an\\nexample of the pseudocode used by an agent to learn a\\npolicy. This pseudocode evaluates the policy by invok-\\ning rollout(environment, policy) to generate trajectories.\\ntrain policy() then uses these trajectories to improve the\\ncurrent policy via policy.update(trajectories). This pro-\\ncess repeats until the policy converges.\\nThus, a framework for RL applications must provide'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='current policy via policy.update(trajectories). This pro-\\ncess repeats until the policy converges.\\nThus, a framework for RL applications must provide\\nefﬁcient support for training, serving, and simulation\\n(Figure 1). Next, we brieﬂy describe these workloads.\\nTraining typically involves running stochastic gradient\\ndescent (SGD), often in a distributed setting, to update the\\npolicy. Distributed SGD typically relies on an allreduce\\naggregation step or a parameter server [32].\\nServing uses the trained policy to render an action based\\non the current state of the environment. A serving system\\naims to minimize latency, and maximize the number of\\ndecisions per second. To scale, load is typically balanced\\nacross multiple nodes serving the policy.\\nFinally, most existing RL applications use simulations\\nto evaluate the policy—current RL algorithms are not\\nsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. These simula-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='to evaluate the policy—current RL algorithms are not\\nsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. These simula-\\ntions vary widely in complexity. They might take a few ms\\n(e.g., simulate a move in a chess game) to minutes (e.g.,\\nsimulate a realistic environment for a self-driving car).\\nIn contrast with supervised learning, in which train-\\ning and serving can be handled separately by different\\nsystems, in RL all three of these workloads are tightly\\ncoupled in a single application, with stringent latency re-\\nquirements between them. Currently, no framework sup-\\nports this coupling of workloads. In theory, multiple spe-\\ncialized frameworks could be stitched together to provide\\nthe overall capabilities, but in practice, the resulting data\\nmovement and latency between systems is prohibitive in\\nthe context of RL. As a result, researchers and practition-\\ners have been building their own one-off systems.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='movement and latency between systems is prohibitive in\\nthe context of RL. As a result, researchers and practition-\\ners have been building their own one-off systems.\\nThis state of affairs calls for the development of new\\ndistributed frameworks for RL that can efﬁciently support\\ntraining, serving, and simulation. In particular, such a\\nframework should satisfy the following requirements:\\nFine-grained, heterogeneous computations. The dura-\\ntion of a computation can range from milliseconds (e.g.,\\ntaking an action) to hours (e.g., training a complex pol-\\nicy). Additionally, training often requires heterogeneous\\nhardware (e.g., CPUs, GPUs, or TPUs).\\nFlexible computation model. RL applications require\\nboth stateless and stateful computations. Stateless compu-\\ntations can be executed on any node in the system, which\\nmakes it easy to achieve load balancing and movement\\nof computation to data, if needed. Thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='makes it easy to achieve load balancing and movement\\nof computation to data, if needed. Thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and\\ndata processing, such as extracting features from images\\nor videos. In contrast stateful computations are a good ﬁt\\nfor implementing parameter servers, performing repeated\\ncomputation on GPU-backed data, or running third-party\\nsimulators that do not expose their state.\\nDynamic execution. Several components of RL appli-\\ncations require dynamic execution, as the order in which\\ncomputations ﬁnish is not always known in advance (e.g.,\\nthe order in which simulations ﬁnish), and the results of a\\ncomputation can determine future computations (e.g., the\\nresults of a simulation will determine whether we need to\\nperform more simulations).\\nWe make two ﬁnal comments. First, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second.∗Second, such a framework'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='perform more simulations).\\nWe make two ﬁnal comments. First, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second.∗Second, such a framework\\nis not intended for implementing deep neural networks\\nor complex simulators from scratch. Instead, it should\\nenable seamless integration with existing simulators [13,\\n11, 59] and deep learning frameworks [7, 18, 46, 29].\\n∗Assume 5ms single-core tasks and a cluster of 200 32-core nodes.\\nThis cluster can run (1s/5ms) ×32 ×200 = 1.28M tasks/sec.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Name Description\\nfutures = f.remote(args) Execute function f remotely. f.remote() can take objects or futures as inputs\\nand returns one or more futures. This is non-blocking.\\nobjects = ray.get(futures) Return the values associated with one or more futures. This is blocking.\\nready futures = ray.wait(futures,k,timeout) Return the futures whose corresponding tasks have completed as soon as either\\nk have completed or the timeout expires.\\nactor = Class.remote(args) Instantiate class Class as a remote actor, and return a handle to it. Call a method\\nfutures = actor.method.remote(args) on the remote actor and return one or more futures. Both are non-blocking.\\nTable 1: Ray API\\n3 Programming and Computation Model\\nRay implements a dynamic task graph computation\\nmodel, i.e., it models an application as a graph of depen-\\ndent tasks that evolves during execution. On top of this\\nmodel, Ray provides both an actor and a task-parallel\\nprogramming abstraction. This uniﬁcation differentiates'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='dent tasks that evolves during execution. On top of this\\nmodel, Ray provides both an actor and a task-parallel\\nprogramming abstraction. This uniﬁcation differentiates\\nRay from related systems like CIEL, which only pro-\\nvides a task-parallel abstraction, and from Orleans [14] or\\nAkka [1], which primarily provide an actor abstraction.\\n3.1 Programming Model\\nTasks. A task represents the execution of a remote func-\\ntion on a stateless worker. When a remote function is\\ninvoked, a future representing the result of the task is\\nreturned immediately. Futures can be retrieved using\\nray.get() and passed as arguments into other remote func-\\ntions without waiting for their result. This allows the user\\nto express parallelism while capturing data dependencies.\\nTable 1 shows Ray’s API.\\nRemote functions operate on immutable objects and\\nare expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. This implies\\nidempotence, which simpliﬁes fault tolerance through'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='are expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. This implies\\nidempotence, which simpliﬁes fault tolerance through\\nfunction re-execution on failure.\\nActors. An actor represents a stateful computation. Each\\nactor exposes methods that can be invoked remotely and\\nare executed serially. A method execution is similar to a\\ntask, in that it executes remotely and returns a future, but\\ndiffers in that it executes on a stateful worker. A handle\\nto an actor can be passed to other actors or tasks, making\\nit possible for them to invoke methods on that actor.\\nTasks (stateless) Actors (stateful)\\nFine-grained load balancing Coarse-grained load balancing\\nSupport for object locality Poor locality support\\nHigh overhead for small updates Low overhead for small updates\\nEfﬁcient failure handling Overhead from checkpointing\\nTable 2: Tasks vs. actors tradeoffs.\\nTable 2 summarizes the properties of tasks and actors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Efﬁcient failure handling Overhead from checkpointing\\nTable 2: Tasks vs. actors tradeoffs.\\nTable 2 summarizes the properties of tasks and actors.\\nTasks enable ﬁne-grained load balancing through leverag-\\ning load-aware scheduling at task granularity, input data\\nlocality, as each task can be scheduled on the node stor-\\ning its inputs, and low recovery overhead, as there is no\\nneed to checkpoint and recover intermediate state. In con-\\ntrast, actors provide much more efﬁcient ﬁne-grained up-\\ndates, as these updates are performed on internal rather\\nthan external state, which typically requires serialization\\nand deserialization. For example, actors can be used to\\nimplement parameter servers [32] and GPU-based itera-\\ntive computations (e.g., training). In addition, actors can\\nbe used to wrap third-party simulators and other opaque\\nhandles that are hard to serialize.\\nTo satisfy the requirements for heterogeneity and ﬂex-\\nibility (Section 2), we augment the API in three ways.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='handles that are hard to serialize.\\nTo satisfy the requirements for heterogeneity and ﬂex-\\nibility (Section 2), we augment the API in three ways.\\nFirst, to handle concurrent tasks with heterogeneous du-\\nrations, we introduce ray.wait(), which waits for the\\nﬁrst k available results, instead of waiting for all results\\nlike ray.get(). Second, to handle resource-heterogeneous\\ntasks, we enable developers to specify resource require-\\nments so that the Ray scheduler can efﬁciently manage re-\\nsources. Third, to improve ﬂexibility, we enablenested re-\\nmote functions, meaning that remote functions can invoke\\nother remote functions. This is also critical for achiev-\\ning high scalability (Section 4), as it enables multiple pro-\\ncesses to invoke remote functions in a distributed fashion.\\n3.2 Computation Model\\nRay employs a dynamic task graph computation\\nmodel [21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='3.2 Computation Model\\nRay employs a dynamic task graph computation\\nmodel [21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the\\nsystem when their inputs become available. In this sec-\\ntion, we describe how the computation graph (Figure 4) is\\nconstructed from a user program (Figure 3). This program\\nuses the API in Table 1 to implement the pseudocode\\nfrom Figure 2.\\nIgnoring actors ﬁrst, there are two types of nodes in\\na computation graph: data objects and remote function\\ninvocations, or tasks. There are also two types of edges:\\ndata edges and control edges. Data edges capture the de-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='@ray.remote\\ndef create_policy():\\n# Initialize the policy randomly.\\nreturn policy\\n@ray.remote(num_gpus=1)\\nclass Simulator(object):\\ndef __init__(self):\\n# Initialize the environment.\\nself.env = Environment()\\ndef rollout(self, policy, num_steps):\\nobservations = []\\nobservation = self.env.current_state()\\nfor _ in range(num_steps):\\naction = policy(observation)\\nobservation = self.env.step(action)\\nobservations.append(observation)\\nreturn observations\\n@ray.remote(num_gpus=2)\\ndef update_policy(policy, *rollouts):\\n# Update the policy.\\nreturn policy\\n@ray.remote\\ndef train_policy():\\n# Create a policy.\\npolicy_id = create_policy.remote()\\n# Create 10 actors.\\nsimulators = [Simulator.remote() for _ in range(10)]\\n# Do 100 steps of training.\\nfor _ in range(100):\\n# Perform one rollout on each actor.\\nrollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# Update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='rollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# Update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)\\nFigure 3: Python code implementing the example in Figure 2\\nin Ray. Note that @ray.remote indicates remote functions and\\nactors. Invocations of remote functions and actor methods return\\nfutures, which can be passed to subsequent remote functions or\\nactor methods to encode task dependencies. Each actor has an\\nenvironment object self.env shared between all of its methods.\\npendencies between data objects and tasks. More pre-\\ncisely, if data object D is an output of task T , we add a\\ndata edge from T to D. Similarly, if D is an input to T ,\\nwe add a data edge from D to T . Control edges capture\\nthe computation dependencies that result from nested re-\\nmote functions (Section 3.1): if task T1 invokes task T2,\\nthen we add a control edge from T1 to T2.\\nActor method invocations are also represented as nodes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='mote functions (Section 3.1): if task T1 invokes task T2,\\nthen we add a control edge from T1 to T2.\\nActor method invocations are also represented as nodes\\nin the computation graph. They are identical to tasks\\nwith one key difference. To capture the state dependency\\nacross subsequent method invocations on the same actor,\\nwe add a third type of edge: a stateful edge. If method\\nMj is called right after method Mi on the same actor,\\nthen we add a stateful edge from Mi to Mj. Thus, all\\npolicy1\\nT1create_policy\\nT2update_policy\\nA11rollout\\nA12rollout policy2\\nT3update_policy\\nrollout11\\nrollout12\\nA21rollout\\nA22rolloutrollout22\\nA10Simulator A20Simulator\\n… ……data\\tedges statefuledgesobject task/methodcontrol\\tedges\\nrollout21\\nT0train_policy\\nFigure 4: The task graph corresponding to an invocation of\\ntrain policy.remote() in Figure 3. Remote function calls and the\\nactor method calls correspond to tasks in the task graph. The\\nﬁgure shows two actors. The method invocations for each actor'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='train policy.remote() in Figure 3. Remote function calls and the\\nactor method calls correspond to tasks in the task graph. The\\nﬁgure shows two actors. The method invocations for each actor\\n(the tasks labeled A1i and A2i) have stateful edges between them\\nindicating that they share the mutable actor state. There are con-\\ntrol edges from train policy to the tasks that it invokes. To train\\nmultiple policies in parallel, we could call train policy.remote()\\nmultiple times.\\nmethods invoked on the same actor object form a chain\\nthat is connected by stateful edges (Figure 4). This chain\\ncaptures the order in which these methods were invoked.\\nStateful edges help us embed actors in an otherwise\\nstateless task graph, as they capture the implicit data de-\\npendency between successive method invocations sharing\\nthe internal state of an actor. Stateful edges also enable\\nus to maintain lineage. As in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. By explic-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the internal state of an actor. Stateful edges also enable\\nus to maintain lineage. As in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. By explic-\\nitly including stateful edges in the lineage graph, we can\\neasily reconstruct lost data, whether produced by remote\\nfunctions or actor methods (Section 4.2.3).\\n4 Architecture\\nRay’s architecture comprises (1) an application layer im-\\nplementing the API, and (2) a system layer providing high\\nscalability and fault tolerance.\\n4.1 Application Layer\\nThe application layer consists of three types of processes:\\n•Driver: A process executing the user program.\\n•Worker: A stateless process that executes tasks\\n(remote functions) invoked by a driver or another'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Local Scheduler\\nActorDriver\\nObject Store\\nGlobal SchedulerGlobal Scheduler\\nObject TableTask TableFunction TableEvent Logs\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nDriverWorker\\nObject Store\\nNode\\nGlobal Scheduler\\nWeb UIDebugging ToolsProfiling Tools\\nError Diagnosis\\nLocal Scheduler\\nWorkerWorker\\nObject Store\\nNode Node\\nApp LayerSystem Layer (backend)\\nFigure 5: Ray’s architecture consists of two parts: anapplica-\\ntion layer and a system layer. The application layer implements\\nthe API and the computation model described in Section 3, the\\nsystem layer implements task scheduling and data management\\nto satisfy the performance and fault-tolerance requirements.\\nworker. Workers are started automatically and as-\\nsigned tasks by the system layer. When a remote\\nfunction is declared, the function is automatically\\npublished to all workers. A worker executes tasks\\nserially, with no local state maintained across tasks.\\n•Actor: A stateful process that executes, when in-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='published to all workers. A worker executes tasks\\nserially, with no local state maintained across tasks.\\n•Actor: A stateful process that executes, when in-\\nvoked, only the methods it exposes. Unlike a worker,\\nan actor is explicitly instantiated by a worker or a\\ndriver. Like workers, actors execute methods seri-\\nally, except that each method depends on the state\\nresulting from the previous method execution.\\n4.2 System Layer\\nThe system layer consists of three major components: a\\nglobal control store, a distributed scheduler, and a dis-\\ntributed object store. All components are horizontally\\nscalable and fault-tolerant.\\n4.2.1 Global Control Store (GCS)\\nThe global control store (GCS) maintains the entire con-\\ntrol state of the system, and it is a unique feature of our\\ndesign. At its core, GCS is a key-value store with pub-\\nsub functionality. We use sharding to achieve scale, and\\nper-shard chain replication [61] to provide fault tolerance.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='design. At its core, GCS is a key-value store with pub-\\nsub functionality. We use sharding to achieve scale, and\\nper-shard chain replication [61] to provide fault tolerance.\\nThe primary reason for the GCS and its design is to main-\\ntain fault tolerance and low latency for a system that can\\ndynamically spawn millions of tasks per second.\\nFault tolerance in case of node failure requires a solu-\\ntion to maintain lineage information. Existing lineage-\\nbased solutions [64, 63, 40, 28] focus on coarse-grained\\nparallelism and can therefore use a single node (e.g., mas-\\nter, driver) to store the lineage without impacting perfor-\\nmance. However, this design is not scalable for a ﬁne-\\ngrained and dynamic workload like simulation. Therefore,\\nwe decouple the durable lineage storage from the other\\nsystem components, allowing each to scale independently.\\nMaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='system components, allowing each to scale independently.\\nMaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where\\nto execute, and subsequently task dispatch, which in-\\nvolves retrieving remote inputs from other nodes. Many\\nexisting dataﬂow systems [ 64, 40, 48] couple these by\\nstoring object locations and sizes in a centralized sched-\\nuler, a natural design when the scheduler is not a bottle-\\nneck. However, the scale and granularity that Ray targets\\nrequires keeping the centralized scheduler off the critical\\npath. Involving the scheduler in each object transfer is pro-\\nhibitively expensive for primitives important to distributed\\ntraining like allreduce, which is both communication-\\nintensive and latency-sensitive. Therefore, we store the\\nobject metadata in the GCS rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nIn summary, the GCS signiﬁcantly simpliﬁes Ray’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='object metadata in the GCS rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nIn summary, the GCS signiﬁcantly simpliﬁes Ray’s\\noverall design, as it enables every component in the sys-\\ntem to be stateless. This not only simpliﬁes support for\\nfault tolerance (i.e., on failure, components simply restart\\nand read the lineage from the GCS), but also makes it\\neasy to scale the distributed object store and scheduler in-\\ndependently, as all components share the needed state via\\nthe GCS. An added beneﬁt is the easy development of de-\\nbugging, proﬁling, and visualization tools.\\n4.2.2 Bottom-Up Distributed Scheduler\\nAs discussed in Section 2, Ray needs to dynamically\\nschedule millions of tasks per second, tasks which may\\ntake as little as a few milliseconds. None of the clus-\\nter schedulers we are aware of meet these requirements.\\nMost cluster computing frameworks, such as Spark [64],\\nCIEL [40], and Dryad [28] implement a centralized sched-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ter schedulers we are aware of meet these requirements.\\nMost cluster computing frameworks, such as Spark [64],\\nCIEL [40], and Dryad [28] implement a centralized sched-\\nuler, which can provide locality but at latencies in the tens\\nof ms. Distributed schedulers such as work stealing [12],\\nSparrow [45] and Canary [47] can achieve high scale, but\\nthey either don’t consider data locality [12], or assume\\ntasks belong to independent jobs [45], or assume the com-\\nputation graph is known [47].\\nTo satisfy the above requirements, we design a two-\\nlevel hierarchical scheduler consisting of a global sched-\\nuler and per-node local schedulers. To avoid overloading\\nthe global scheduler, the tasks created at a node are sub-\\nmitted ﬁrst to the node’s local scheduler. A local sched-\\nuler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='uler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a\\nGPU). If a local scheduler decides not to schedule a task\\nlocally, it forwards it to the global scheduler. Since this\\nscheduler attempts to schedule tasks locally ﬁrst (i.e., at\\nthe leaves of the scheduling hierarchy), we call it abottom-\\nup scheduler.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Global Scheduler\\nLocal Scheduler\\nGlobal Scheduler\\nWorkerDriverWorker…\\nGlobal Control        State (GCS)\\nLocal Scheduler\\nWorkerWorkerWorker\\nSubmit tasksSchedule tasksLoadinfo\\nNode 1 Node N\\nFigure 6: Bottom-up distributed scheduler. Tasks are submitted\\nbottom-up, from drivers and workers to a local scheduler and\\nforwarded to the global scheduler only if needed (Section 4.2.2).\\nThe thickness of each arrow is proportional to its request rate.\\nThe global scheduler considers each node’s load and\\ntask’s constraints to make scheduling decisions. More pre-\\ncisely, the global scheduler identiﬁes the set of nodes that\\nhave enough resources of the type requested by the task,\\nand of these nodes selects the node which provides the\\nlowest estimated waiting time. At a given node, this time\\nis the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='is the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s\\nremote inputs (i.e., total size of remote inputs divided by\\naverage bandwidth). The global scheduler gets the queue\\nsize at each node and the node resource availability via\\nheartbeats, and the location of the task’s inputs and their\\nsizes from GCS. Furthermore, the global scheduler com-\\nputes the average task execution and the average transfer\\nbandwidth using simple exponential averaging. If the\\nglobal scheduler becomes a bottleneck, we can instantiate\\nmore replicas all sharing the same information via GCS.\\nThis makes our scheduler architecture highly scalable.\\n4.2.3 In-Memory Distributed Object Store\\nTo minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. On each node, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='To minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. On each node, we\\nimplement the object store via shared memory. This al-\\nlows zero-copy data sharing between tasks running on the\\nsame node. As a data format, we use Apache Arrow [2].\\nIf a task’s inputs are not local, the inputs are replicated\\nto the local object store before execution. Also, a task\\nwrites its outputs to the local object store. Replication\\neliminates the potential bottleneck due to hot data ob-\\njects and minimizes task execution time as a task only\\nreads/writes data from/to the local memory. This in-\\ncreases throughput for computation-bound workloads, a\\nproﬁle shared by many AI applications. For low latency,\\nwe keep objects entirely in memory and evict them as\\nneeded to disk using an LRU policy.\\nAs with existing cluster computing frameworks, such\\nas Spark [64], and Dryad [28], the object store is limited'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='we keep objects entirely in memory and evict them as\\nneeded to disk using an LRU policy.\\nAs with existing cluster computing frameworks, such\\nas Spark [64], and Dryad [28], the object store is limited\\nto immutable data. This obviates the need for complex\\nconsistency protocols (as objects are not updated), and\\nsimpliﬁes support for fault tolerance. In the case of node\\nfailure, Ray recovers any needed objects through lineage\\nre-execution. The lineage stored in the GCS tracks both\\nstateless tasks and stateful actors during initial execution;\\nwe use the former to reconstruct objects in the store.\\nFor simplicity, our object store does not support dis-\\ntributed objects, i.e., each object ﬁts on a single node. Dis-\\ntributed objects like large matrices or trees can be imple-\\nmented at the application level as collections of futures.\\n4.2.4 Implementation\\nRay is an active open source project†developed at the Uni-\\nversity of California, Berkeley. Ray fully integrates with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='mented at the application level as collections of futures.\\n4.2.4 Implementation\\nRay is an active open source project†developed at the Uni-\\nversity of California, Berkeley. Ray fully integrates with\\nthe Python environment and is easy to install by simply\\nrunning pip install ray. The implementation com-\\nprises ≈ 40K lines of code (LoC), 72% in C++ for the\\nsystem layer, 28% in Python for the application layer. The\\nGCS uses one Redis [50] key-value store per shard, with\\nentirely single-key operations. GCS tables are sharded\\nby object and task IDs to scale, and every shard is chain-\\nreplicated [61] for fault tolerance. We implement both\\nthe local and global schedulers as event-driven, single-\\nthreaded processes. Internally, local schedulers maintain\\ncached state for local object metadata, tasks waiting for\\ninputs, and tasks ready for dispatch to a worker. To trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple TCP connections.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='inputs, and tasks ready for dispatch to a worker. To trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple TCP connections.\\n4.3 Putting Everything Together\\nFigure 7 illustrates how Ray works end-to-end with a\\nsimple example that adds two objects a and b, which\\ncould be scalars or matrices, and returns result c. The\\nremote function add() is automatically registered with the\\nGCS upon initialization and distributed to every worker\\nin the system (step 0 in Figure 7a).\\nFigure 7a shows the step-by-step operations triggered\\nby a driver invoking add.remote(a,b), where a and b are\\nstored on nodes N1 and N2, respectively. The driver sub-\\nmits add(a, b) to the local scheduler (step 1), which for-\\nwards it to a global scheduler (step 2).‡Next, the global\\nscheduler looks up the locations of add(a, b)’s arguments\\nin the GCS (step 3) and decides to schedule the task on\\nnode N2, which stores argument b (step 4). The local'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='scheduler looks up the locations of add(a, b)’s arguments\\nin the GCS (step 3) and decides to schedule the task on\\nnode N2, which stores argument b (step 4). The local\\nscheduler at node N2 checks whether the local object\\nstore contains add(a, b)’s arguments (step 5). Since the\\n†https://github.com/ray-project/ray\\n‡Note that N1 could also decide to schedule the task locally.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Object store\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\n45\\n6\\nLocal Scheduler\\nObject store\\nidaa1\\n2\\n8\\nGlobal Scheduler\\n7\\n9\\nidaaidbb\\n0\\n3 Local Scheduler\\n(a) Executing a task remotely\\nLocal Scheduler\\nidbb\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nidaa1 idaaidcc idc N2, N14257 3\\nGlobal Scheduler\\nidcc6\\n(b) Returning the result of a remote task\\nFigure 7: An end-to-end example that adds a and b and returns\\nc. Solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) The function add() is registered\\nwith the GCS by node 1 ( N1), invoked on N1, and executed'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='c. Solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) The function add() is registered\\nwith the GCS by node 1 ( N1), invoked on N1, and executed\\non N2. (b) N1 gets add()’s result usingray.get(). The Object\\nTable entry for c is created in step 4 and updated in step 6 after\\nc is copied to N1.\\nlocal store doesn’t have objecta, it looks up a’s location\\nin the GCS (step 6). Learning that a is stored at N1, N2’s\\nobject store replicates it locally (step 7). As all arguments\\nof add() are now stored locally, the local scheduler in-\\nvokes add() at a local worker (step 8), which accesses the\\narguments via shared memory (step 9).\\nFigure 7b shows the step-by-step operations triggered\\nby the execution of ray.get() at N1, and of add() at N2,\\nrespectively. Upon ray.get(idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idc returned by add() (step 1). Since the local'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='respectively. Upon ray.get(idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idc returned by add() (step 1). Since the local\\nobject store doesn’t storec, it looks up its location in the\\nGCS. At this time, there is no entry for c, as c has not\\nbeen created yet. As a result, N1’s object store registers a\\ncallback with the Object Table to be triggered when c’s\\nentry has been created (step 2). Meanwhile, at N2, add()\\ncompletes its execution, stores the result c in the local\\nobject store (step 3), which in turn adds c’s entry to the\\nGCS (step 4). As a result, the GCS triggers a callback\\nto N1’s object store with c’s entry (step 5). Next, N1\\nreplicates c from N2 (step 6), and returns c to ray.get()\\n(step 7), which ﬁnally completes the task.\\nWhile this example involves a large number of RPCs,\\n100KB 1MB 10MB 100MB\\nObject size\\n10-5\\n10-4\\n10-3\\n10-2\\n10-1\\nMean task latency (s)\\nLocality Aware\\nUnaware\\n(a) Ray locality scheduling\\n10 20 30 40 50 60 100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='100KB 1MB 10MB 100MB\\nObject size\\n10-5\\n10-4\\n10-3\\n10-2\\n10-1\\nMean task latency (s)\\nLocality Aware\\nUnaware\\n(a) Ray locality scheduling\\n10 20 30 40 50 60 100\\nnumber of nodes\\n0.0\\n0.4\\n0.8\\n1.2\\n1.6Millions of tasks/s (b) Ray scalability\\nFigure 8: (a) Tasks leverage locality-aware placement. 1000\\ntasks with a random object dependency are scheduled onto one\\nof two nodes. With locality-aware policy, task latency remains\\nindependent of the size of task inputs instead of growing by 1-2\\norders of magnitude. (b) Near-linear scalability leveraging the\\nGCS and bottom-up distributed scheduler. Ray reaches 1 million\\ntasks per second throughput with 60 nodes. x ∈{70,80,90}\\nomitted due to cost.\\nin many cases this number is much smaller, as most tasks\\nare scheduled locally, and the GCS replies are cached by\\nthe global and local schedulers.\\n5 Evaluation\\nIn our evaluation, we study the following questions:\\n1. How well does Ray meet the latency, scalability,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the global and local schedulers.\\n5 Evaluation\\nIn our evaluation, we study the following questions:\\n1. How well does Ray meet the latency, scalability,\\nand fault tolerance requirements listed in Section 2?\\n(Section 5.1)\\n2. What overheads are imposed on distributed primi-\\ntives (e.g., allreduce) written using Ray’s API? (Sec-\\ntion 5.1)\\n3. In the context of RL workloads, how does Ray com-\\npare against specialized systems for training, serv-\\ning, and simulation? (Section 5.2)\\n4. What advantages does Ray provide for RL applica-\\ntions, compared to custom systems? (Section 5.3)\\nAll experiments were run on Amazon Web Services.\\nUnless otherwise stated, we use m4.16xlarge CPU in-\\nstances and p3.16xlarge GPU instances.\\n5.1 Microbenchmarks\\nLocality-aware task placement. Fine-grain load bal-\\nancing and locality-aware placement are primary beneﬁts\\nof tasks in Ray. Actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ancing and locality-aware placement are primary beneﬁts\\nof tasks in Ray. Actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.\\nIn Figure 8a, tasks placed without data locality awareness\\n(as is the case for actor methods), suffer 1-2 orders of\\nmagnitude latency increase at 10-100MB input data sizes.\\nRay uniﬁes tasks and actors through the shared object\\nstore, allowing developers to use tasks for e.g., expensive\\npostprocessing on output produced by simulation actors.\\nEnd-to-end scalability. One of the key beneﬁts of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='1KB 10KB100KB 1MB 10MB100MB 1GB\\nobject size\\n0\\n5000\\n10000\\n15000\\n20000IOPS\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\nthroughput (GB/s)\\nFigure 9: Object store write throughput and IOPS. From a\\nsingle client, throughput exceeds 15GB/s (red) for large objects\\nand 18K IOPS (cyan) for small objects on a 16 core instance\\n(m4.4xlarge). It uses 8 threads to copy objects larger than 0.5MB\\nand 1 thread for small objects. Bar plots report throughput with\\n1, 2, 4, 8, 16 threads. Results are averaged over 5 runs.\\nthe Global Control Store (GCS) and the bottom-up dis-\\ntributed scheduler is the ability to horizontally scale the\\nsystem to support a high throughput of ﬁne-grained tasks,\\nwhile maintaining fault tolerance and low-latency task\\nscheduling. In Figure 8b, we evaluate this ability on an\\nembarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. We observe near-perfect\\nlinearity in progressively increasing task throughput. Ray'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='embarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. We observe near-perfect\\nlinearity in progressively increasing task throughput. Ray\\nexceeds 1 million tasks per second throughput at 60 nodes\\nand continues to scale linearly beyond 1.8 million tasks\\nper second at 100 nodes. The rightmost datapoint shows\\nthat Ray can process 100 million tasks in less than a\\nminute (54s), with minimum variability. As expected, in-\\ncreasing task duration reduces throughput proportionally\\nto mean task duration, but the overall scalability remains\\nlinear. While many realistic workloads may exhibit more\\nlimited scalability due to object dependencies and inher-\\nent limits to application parallelism, this demonstrates the\\nscalability of our overall architecture under high load.\\nObject store performance. To evaluate the perfor-\\nmance of the object store (Section 4.2.3), we track two\\nmetrics: IOPS (for small objects) and write throughput'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Object store performance. To evaluate the perfor-\\nmance of the object store (Section 4.2.3), we track two\\nmetrics: IOPS (for small objects) and write throughput\\n(for large objects). In Figure 9, the write throughput from\\na single client exceeds 15GB/s as object size increases.\\nFor larger objects, memcpy dominates object creation\\ntime. For smaller objects, the main overheads are in seri-\\nalization and IPC between the client and object store.\\nGCS fault tolerance. To maintain low latency while\\nproviding strong consistency and fault tolerance, we build\\na lightweight chain replication [61] layer on top of Redis.\\nFigure 10a simulates recording Ray tasks to and reading\\ntasks from the GCS, where keys are 25 bytes and values\\nare 512 bytes. The client sends requests as fast as it can,\\nhaving at most one in-ﬂight request at a time. Failures are\\nreported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='reported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10\\nTime since start (s)\\n103 103\\n104 104\\nLatency (μs) write\\nread\\nnode dead\\n(a) A timeline for GCS read and write latencies as viewed from\\na client submitting tasks. The chain starts with 2 replicas. We\\nmanually trigger reconﬁguration as follows. At t ≈4.2s, a chain\\nmember is killed; immediately after, a new chain member joins,\\ninitiates state transfer, and restores the chain to 2-way replication.\\nThe maximum client-observed latency is under 30ms despite\\nreconﬁgurations.\\n0 10000 20000 30000 40000 50000 60000\\nElasped Time (seconds)\\n0\\n2000\\n4000\\n6000\\n8000GCS Used Memory (MB)\\n50 million no-op tasks\\nRay, no GCS flush\\nRay, GCS flush\\n(b) The Ray GCS maintains a constant memory footprint with\\nGCS ﬂushing. Without GCS ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Ray, GCS flush\\n(b) The Ray GCS maintains a constant memory footprint with\\nGCS ﬂushing. Without GCS ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete\\nwithin a predetermined duration (indicated by the red cross).\\nFigure 10: Ray GCS fault tolerance and ﬂushing.\\nfrom any server in the chain (having received explicit\\nerrors). Overall, reconﬁgurations caused a maximum\\nclient-observed delay of under 30ms (this includes both\\nfailure detection and recovery delays).\\nGCS ﬂushing. Ray is equipped to periodically ﬂush\\nthe contents of GCS to disk. In Figure 10b we submit 50\\nmillion empty tasks sequentially and monitor GCS mem-\\nory consumption. As expected, it grows linearly with the\\nnumber of tasks tracked and eventually reaches the mem-\\nory capacity of the system. At that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. With periodic GCS ﬂushing, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ory capacity of the system. At that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. With periodic GCS ﬂushing, we\\nachieve two goals. First, the memory footprint is capped\\nat a user-conﬁgurable level (in the microbenchmark we\\nemploy an aggressive strategy where consumed memory\\nis kept as low as possible). Second, the ﬂushing mecha-\\nnism provides a natural way to snapshot lineage to disk\\nfor long-running Ray applications.\\nRecovering from task failures. In Figure 11a, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='0 50 100 150 200\\nTime since start (s)\\n0\\n500\\n1000\\n1500\\n2000Throughput (tasks/s)\\n0\\n20\\n40\\n60\\nNumber of nodes\\nOriginal tasks\\nRe-executed tasks\\n(a) Task reconstruction\\n100 200 300 400 500 600\\nTime since start (s)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700Throughput (tasks/s)\\nOriginal tasks\\nRe-executed tasks\\nCheckpoint tasks\\n(b) Actor reconstruction\\nFigure 11: Ray fault-tolerance. (a) Ray reconstructs lost task\\ndependencies as nodes are removed (dotted line), and recovers\\nto original throughput when nodes are added back. Each task\\nis 100ms and depends on an object generated by a previously\\nsubmitted task. (b) Actors are reconstructed from their last\\ncheckpoint. At t = 200s, we kill 2 of the 10 nodes, causing 400\\nof the 2000 actors in the cluster to be recovered on the remaining\\nnodes (t = 200–270s).\\ndemonstrate Ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable GCS lineage storage. The workload, run on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='nodes (t = 200–270s).\\ndemonstrate Ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable GCS lineage storage. The workload, run on\\nm4.xlarge instances, consists of linear chains of 100ms\\ntasks submitted by the driver. As nodes are removed (at\\n25s, 50s, 100s), the local schedulers reconstruct previous\\nresults in the chain in order to continue execution. Over-\\nall per-node throughput remains stable throughout.\\nRecovering from actor failures. By encoding actor\\nmethod calls as stateful edges directly in the dependency\\ngraph, we can reuse the same object reconstruction mech-\\nanism as in Figure 11a to provide transparent fault tol-\\nerance for stateful computation. Ray additionally lever-\\nages user-deﬁned checkpoint functions to bound the re-\\nconstruction time for actors (Figure 11b). With minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='construction time for actors (Figure 11b). With minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-\\ning. In the future, we hope to further reduce actor recon-\\nstruction time, e.g., by allowing users to annotate meth-\\nods that do not mutate state.\\nAllreduce. Allreduce is a distributed communication\\n10MB 100MB 1GB\\nObject size\\n100\\n101\\n102\\n103\\n104\\nIteration time (milliseconds)\\nOpenMPI\\nRay*\\nRay\\n(a) Ray vs OpenMPI\\n+0 +1 +5 +10\\nAdded scheduler latency (ms)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700\\n800Iteration time (milliseconds)\\nRay ring reduce latency\\n(16 nodes, 100MB) (b) Ray scheduler ablation\\nFigure 12: (a) Mean execution time of allreduce on 16 m4.16xl\\nnodes. Each worker runs on a distinct node. Ray* restricts Ray\\nto 1 thread for sending and 1 thread for receiving. (b) Ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='to 1 thread for sending and 1 thread for receiving. (b) Ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.\\nHere, we evaluate whether Ray can natively support a\\nring allreduce [57] implementation with low enough over-\\nhead to match existing implementations [53]. We ﬁnd that\\nRay completes allreduce across 16 nodes on 100MB in\\n∼200ms and 1GB in ∼1200ms, surprisingly outperform-\\ning OpenMPI (v1.10), a popular MPI implementation,\\nby 1.5×and 2×respectively (Figure 12a). We attribute\\nRay’s performance to its use of multiple threads for net-\\nwork transfers, taking full advantage of the 25Gbps con-\\nnection between nodes on AWS, whereas OpenMPI se-\\nquentially sends and receives data on a single thread [22].\\nFor smaller objects, OpenMPI outperforms Ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nRay’s scheduler performance is critical to implement-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='For smaller objects, OpenMPI outperforms Ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nRay’s scheduler performance is critical to implement-\\ning primitives such as allreduce. In Figure 12b, we inject\\nartiﬁcial task execution delays and show that performance\\ndrops nearly 2×with just a few ms of extra latency. Sys-\\ntems with centralized schedulers like Spark and CIEL typ-\\nically have scheduler overheads in the tens of millisec-\\nonds [62, 38], making such workloads impractical. Sched-\\nuler throughput also becomes a bottleneck since the num-\\nber of tasks required by ring reduce scales quadratically\\nwith the number of participants.\\n5.2 Building blocks\\nEnd-to-end applications (e.g., AlphaGo [ 54]) require a\\ntight coupling of training, serving, and simulation. In this\\nsection, we isolate each of these workloads to a setting\\nthat illustrates a typical RL application’s requirements.\\nDue to a ﬂexible programming model targeted to RL, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='section, we isolate each of these workloads to a setting\\nthat illustrates a typical RL application’s requirements.\\nDue to a ﬂexible programming model targeted to RL, and\\na system designed to support this programming model,\\nRay matches and sometimes exceeds the performance of\\ndedicated systems for these individual workloads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='4 8 16 32 64\\nNum GPUs (V100)\\n0\\n1000\\n2000\\n3000\\n4000\\n5000\\n6000\\n7000Mean images / s\\nHorovod + TF\\nDistributed TF\\nRay + TF\\nFigure 13: Images per second reached when distributing the\\ntraining of a ResNet-101 TensorFlow model (from the ofﬁcial\\nTF benchmark). All experiments were run on p3.16xl instances\\nconnected by 25Gbps Ethernet, and workers allocated 4 GPUs\\nper node as done in Horovod [53]. We note some measurement\\ndeviations from previously reported, likely due to hardware\\ndifferences and recent TensorFlow performance improvements.\\nWe used OpenMPI 3.0, TF 1.8, and NCCL2 for all runs.\\n5.2.1 Distributed Training\\nWe implement data-parallel synchronous SGD leverag-\\ning the Ray actor abstraction to represent model replicas.\\nModel weights are synchronized via allreduce (5.1) or pa-\\nrameter server, both implemented on top of the Ray API.\\nIn Figure 13, we evaluate the performance of the\\nRay (synchronous) parameter-server SGD implementa-\\ntion against state-of-the-art implementations [ 53], us-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='In Figure 13, we evaluate the performance of the\\nRay (synchronous) parameter-server SGD implementa-\\ntion against state-of-the-art implementations [ 53], us-\\ning the same TensorFlow model and synthetic data gen-\\nerator for each experiment. We compare only against\\nTensorFlow-based systems to accurately measure the over-\\nhead imposed by Ray, rather than differences between the\\ndeep learning frameworks themselves. In each iteration,\\nmodel replica actors compute gradients in parallel, send\\nthe gradients to a sharded parameter server, then read the\\nsummed gradients from the parameter server for the next\\niteration.\\nFigure 13 shows that Ray matches the performance of\\nHorovod and is within 10% of distributed TensorFlow\\n(in distributed replicated mode). This is due to\\nthe ability to express the same application-level optimiza-\\ntions found in these specialized systems in Ray’s general-\\npurpose API. A key optimization is the pipelining of gra-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the ability to express the same application-level optimiza-\\ntions found in these specialized systems in Ray’s general-\\npurpose API. A key optimization is the pipelining of gra-\\ndient computation, transfer, and summation within a sin-\\ngle iteration. To overlap GPU computation with network\\ntransfer, we use a custom TensorFlow operator to write\\ntensors directly to Ray’s object store.\\n5.2.2 Serving\\nModel serving is an important component of end-to-end\\napplications. Ray focuses primarily on the embedded\\nserving of models to simulators running within the same\\ndynamic task graph (e.g., within an RL application on\\nRay). In contrast, systems like Clipper [ 19] focus on\\nserving predictions to external clients.\\nIn this setting, low latency is critical for achieving high\\nutilization. To show this, in Table 3 we compare the\\nSystem Small Input Larger Input\\nClipper 4400 ±15 states/sec 290 ±1.3 states/sec\\nRay 6200 ±21 states/sec 6900 ±150 states/sec'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='utilization. To show this, in Table 3 we compare the\\nSystem Small Input Larger Input\\nClipper 4400 ±15 states/sec 290 ±1.3 states/sec\\nRay 6200 ±21 states/sec 6900 ±150 states/sec\\nTable 3: Throughput comparisons for Clipper [19], a dedicated\\nserving system, and Ray for two embedded serving workloads.\\nWe use a residual network and a small fully connected network,\\ntaking 10ms and 5ms to evaluate, respectively. The server is\\nqueried by clients that each send states of size 4KB and 100KB\\nrespectively in batches of 64.\\nserver throughput achieved using a Ray actor to serve\\na policy versus using the open source Clipper system\\nover REST. Here, both client and server processes are co-\\nlocated on the same machine (a p3.8xlarge instance). This\\nis often the case for RL applications but not for the general\\nweb serving workloads addressed by systems like Clipper.\\nDue to its low-overhead serialization and shared memory\\nabstractions, Ray achieves an order of magnitude higher'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='web serving workloads addressed by systems like Clipper.\\nDue to its low-overhead serialization and shared memory\\nabstractions, Ray achieves an order of magnitude higher\\nthroughput for a small fully connected policy model that\\ntakes in a large input and is also faster on a more expensive\\nresidual network policy model, similar to one used in\\nAlphaGo Zero, that takes smaller input.\\n5.2.3 Simulation\\nSimulators used in RL produce results with variable\\nlengths (“timesteps”) that, due to the tight loop with train-\\ning, must be used as soon as they are available. The task\\nheterogeneity and timeliness requirements make simu-\\nlations hard to support efﬁciently in BSP-style systems.\\nTo demonstrate, we compare (1) an MPI implementation\\nthat submits 3n parallel simulation runs on n cores in 3\\nrounds, with a global barrier between rounds §, to (2) a\\nRay program that issues the same 3n tasks while concur-\\nrently gathering simulation results back to the driver. Ta-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='rounds, with a global barrier between rounds §, to (2) a\\nRay program that issues the same 3n tasks while concur-\\nrently gathering simulation results back to the driver. Ta-\\nble 4 shows that both systems scale well, yet Ray achieves\\nup to 1.8×throughput. This motivates a programming\\nmodel that can dynamically spawn and collect the results\\nof ﬁne-grained simulation tasks.\\nSystem, programming model 1 CPU 16 CPUs 256 CPUs\\nMPI, bulk synchronous 22.6K 208K 2.16M\\nRay, asynchronous tasks 22.3K 290K 4.03M\\nTable 4: Timesteps per second for the Pendulum-v0 simulator\\nin OpenAI Gym [ 13]. Ray allows for better utilization when\\nrunning heterogeneous simulations at scale.\\n§Note that experts can use MPI’s asynchronous primitives to get\\naround barriers—at the expense of increased program complexity —we\\nnonetheless chose such an implementation to simulate BSP.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='5.3 RL Applications\\nWithout a system that can tightly couple the training, sim-\\nulation, and serving steps, reinforcement learning algo-\\nrithms today are implemented as one-off solutions that\\nmake it difﬁcult to incorporate optimizations that, for ex-\\nample, require a different computation structure or that\\nutilize different architectures. Consequently, with imple-\\nmentations of two representative reinforcement learning\\napplications in Ray, we are able to match and even out-\\nperform custom systems built speciﬁcally for these algo-\\nrithms. The primary reason is the ﬂexibility of Ray’s pro-\\ngramming model, which can express application-level op-\\ntimizations that would require substantial engineering ef-\\nfort to port to custom-built systems, but are transparently\\nsupported by Ray’s dynamic task graph execution engine.\\n5.3.1 Evolution Strategies\\nTo evaluate Ray on large-scale RL workloads, we imple-\\nment the evolution strategies (ES) algorithm and com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='supported by Ray’s dynamic task graph execution engine.\\n5.3.1 Evolution Strategies\\nTo evaluate Ray on large-scale RL workloads, we imple-\\nment the evolution strategies (ES) algorithm and com-\\npare to the reference implementation [49]—a system spe-\\ncially built for this algorithm that relies on Redis for mes-\\nsaging and low-level multiprocessing libraries for data-\\nsharing. The algorithm periodically broadcasts a new pol-\\nicy to a pool of workers and aggregates the results of\\nroughly 10000 tasks (each performing 10 to 1000 simula-\\ntion steps).\\nAs shown in Figure 14a, an implementation on Ray\\nscales to 8192 cores. Doubling the cores available yields\\nan average completion time speedup of 1.6×. Conversely,\\nthe special-purpose system fails to complete at 2048 cores,\\nwhere the work in the system exceeds the processing\\ncapacity of the application driver. To avoid this issue, the\\nRay implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='capacity of the application driver. To avoid this issue, the\\nRay implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice\\nas fast as the best published result (10 minutes).\\nInitial parallelization of a serial implementation using\\nRay required modifying only 7 lines of code. Performance\\nimprovement through hierarchical aggregation was easy\\nto realize with Ray’s support for nested tasks and actors.\\nIn contrast, the reference implementation had several hun-\\ndred lines of code dedicated to a protocol for communi-\\ncating tasks and data between workers, and would require\\nfurther engineering to support optimizations like hierar-\\nchical aggregation.\\n5.3.2 Proximal Policy Optimization\\nWe implement Proximal Policy Optimization (PPO) [51]\\nin Ray and compare to a highly-optimized reference im-\\nplementation [5] that uses OpenMPI communication prim-\\nitives. The algorithm is an asynchronous scatter-gather,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='in Ray and compare to a highly-optimized reference im-\\nplementation [5] that uses OpenMPI communication prim-\\nitives. The algorithm is an asynchronous scatter-gather,\\nwhere new tasks are assigned to simulation actors as they\\n256 1024 8192\\nNumber of CPUs\\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\n90Mean time to solve (minutes)\\nx x x\\nReference ES\\nRay ES\\n(a) Evolution Strategies\\n8x1 64x8 512x64\\nCPUs x GPUs\\n0\\n100\\n200\\n300\\n400\\n500Mean time to solve (minutes)\\nMPI PPO\\nRay PPO (b) PPO\\nFigure 14: Time to reach a score of 6000 in the Humanoid-\\nv1 task [ 13]. (a) The Ray ES implementation scales well to\\n8192 cores and achieves a median time of 3.7 minutes, over\\ntwice as fast as the best published result. The special-purpose\\nsystem failed to run beyond 1024 cores. ES is faster than PPO\\non this benchmark, but shows greater runtime variance. (b)\\nThe Ray PPO implementation outperforms a specialized MPI\\nimplementation [5] with fewer GPUs, at a fraction of the cost.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='on this benchmark, but shows greater runtime variance. (b)\\nThe Ray PPO implementation outperforms a specialized MPI\\nimplementation [5] with fewer GPUs, at a fraction of the cost.\\nThe MPI implementation required 1 GPU for every 8 CPUs,\\nwhereas the Ray version required at most 8 GPUs (and never\\nmore than 1 GPU per 8 CPUs).\\nreturn rollouts to the driver. Tasks are submitted un-\\ntil 320000 simulation steps are collected (each task pro-\\nduces between 10 and 1000 steps). The policy update per-\\nforms 20 steps of SGD with a batch size of 32768. The\\nmodel parameters in this example are roughly 350KB.\\nThese experiments were run using p2.16xlarge (GPU) and\\nm4.16xlarge (high CPU) instances.\\nAs shown in Figure 14b, the Ray implementation out-\\nperforms the optimized MPI implementation in all exper-\\niments, while using a fraction of the GPUs. The reason\\nis that Ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='iments, while using a fraction of the GPUs. The reason\\nis that Ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource\\nrequirements at the granularity of a task or actor. The Ray\\nimplementation can then leverage TensorFlow’s single-\\nprocess multi-GPU support and can pin objects in GPU\\nmemory when possible. This optimization cannot be eas-\\nily ported to MPI due to the need to asynchronously gather\\nrollouts to a single GPU process. Indeed, [5] includes two\\ncustom implementations of PPO, one using MPI for large\\nclusters and one that is optimized for GPUs but that is re-\\nstricted to a single node. Ray allows for an implementa-\\ntion suitable for both scenarios.\\nRay’s ability to handle resource heterogeneity also de-\\ncreased PPO’s cost by a factor of 4.5 [4], since CPU-only\\ntasks can be scheduled on cheaper high-CPU instances.\\nIn contrast, MPI applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tasks can be scheduled on cheaper high-CPU instances.\\nIn contrast, MPI applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and\\nrequire identical resources, in this case preventing the\\nuse of CPU-only machines for scale-out. Furthermore,\\nthe MPI implementation requires on-demand instances\\nsince it does not transparently handle failure. Assum-\\ning 4×cheaper spot instances, Ray’s fault tolerance and\\nresource-aware scheduling together cut costs by 18×.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='6 Related Work\\nDynamic task graphs. Ray is closely related to\\nCIEL [40] and Dask [ 48]. All three support dynamic\\ntask graphs with nested tasks and implement the futures\\nabstraction. CIEL also provides lineage-based fault toler-\\nance, while Dask, like Ray, fully integrates with Python.\\nHowever, Ray differs in two aspects that have important\\nperformance consequences. First, Ray extends the task\\nmodel with an actor abstraction. This is necessary for\\nefﬁcient stateful computation in distributed training and\\nserving, to keep the model data collocated with the com-\\nputation. Second, Ray employs a fully distributed and de-\\ncoupled control plane and scheduler, instead of relying on\\na single master storing all metadata. This is critical for ef-\\nﬁciently supporting primitives like allreduce without sys-\\ntem modiﬁcation. At peak performance for 100MB on 16\\nnodes, allreduce on Ray (Section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. Meanwhile, Dask reports a maxi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tem modiﬁcation. At peak performance for 100MB on 16\\nnodes, allreduce on Ray (Section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. Meanwhile, Dask reports a maxi-\\nmum scheduler throughput of 3k tasks/s on 512 cores [3].\\nWith a centralized scheduler, each round of allreduce\\nwould then incur a minimum of ∼5ms of scheduling\\ndelay, translating to up to2×worse completion time (Fig-\\nure 12b). Even with a decentralized scheduler, coupling\\nthe control plane information with the scheduler leaves\\nthe latter on the critical path for data transfer, adding an\\nextra roundtrip to every round of allreduce.\\nDataﬂow systems. Popular dataﬂow systems, such\\nas MapReduce [ 20], Spark [ 65], and Dryad [ 28] have\\nwidespread adoption for analytics and ML workloads,\\nbut their computation model is too restrictive for a ﬁne-\\ngrained and dynamic simulation workload. Spark and\\nMapReduce implement the BSP execution model, which\\nassumes that tasks within the same stage perform the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='grained and dynamic simulation workload. Spark and\\nMapReduce implement the BSP execution model, which\\nassumes that tasks within the same stage perform the\\nsame computation and take roughly the same amount of\\ntime. Dryad relaxes this restriction but lacks support for\\ndynamic task graphs. Furthermore, none of these systems\\nprovide an actor abstraction, nor implement a distributed\\nscalable control plane and scheduler. Finally, Naiad [39]\\nis a dataﬂow system that provides improved scalability\\nfor some workloads, but only supports static task graphs.\\nMachine learning frameworks. TensorFlow [7] and\\nMXNet [ 18] target deep learning workloads and efﬁ-\\nciently leverage both CPUs and GPUs. While they\\nachieve great performance for training workloads consist-\\ning of static DAGs of linear algebra operations, they have\\nlimited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. TensorFlow Fold [33] provides some support for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='limited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. TensorFlow Fold [33] provides some support for\\ndynamic task graphs, as well as MXNet through its inter-\\nnal C++ APIs, but neither fully supports the ability to mod-\\nify the DAG during execution in response to task progress,\\ntask completion times, or faults. TensorFlow and MXNet\\nin principle achieve generality by allowing the program-\\nmer to simulate low-level message-passing and synchro-\\nnization primitives, but the pitfalls and user experience in\\nthis case are similar to those of MPI. OpenMPI [22] can\\nachieve high performance, but it is relatively hard to pro-\\ngram as it requires explicit coordination to handle hetero-\\ngeneous and dynamic task graphs. Furthermore, it forces\\nthe programmer to explicitly handle fault tolerance.\\nActor systems. Orleans [14] and Akka [1] are two ac-\\ntor frameworks well suited to developing highly available'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the programmer to explicitly handle fault tolerance.\\nActor systems. Orleans [14] and Akka [1] are two ac-\\ntor frameworks well suited to developing highly available\\nand concurrent distributed systems. However, compared\\nto Ray, they provide less support for recovery from data\\nloss. To recover stateful actors, the Orleans developer\\nmust explicitly checkpoint actor state and intermediate re-\\nsponses. Stateless actors in Orleans can be replicated for\\nscale-out, and could therefore act as tasks, but unlike in\\nRay, they have no lineage. Similarly, while Akka explic-\\nitly supports persisting actor state across failures, it does\\nnot provide efﬁcient fault tolerance for stateless computa-\\ntion (i.e., tasks). For message delivery, Orleans provides\\nat-least-once and Akka provides at-most-once semantics.\\nIn contrast, Ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe GCS and both arguments and results are immutable.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='In contrast, Ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe GCS and both arguments and results are immutable.\\nWe ﬁnd that in practice these limitations do not affect the\\nperformance of our applications. Erlang [10] and C++ Ac-\\ntor Framework [17], two other actor-based systems, have\\nsimilarly limited support for fault tolerance.\\nGlobal control store and scheduling. The concept\\nof logically centralizing the control plane has been pre-\\nviously proposed in software deﬁned networks (SDNs)\\n[16], distributed ﬁle systems (e.g., GFS [ 23]), resource\\nmanagement (e.g., Omega [52]), and distributed frame-\\nworks (e.g., MapReduce [ 20], BOOM [ 9]), to name a\\nfew. Ray draws inspiration from these pioneering efforts,\\nbut provides signiﬁcant improvements. In contrast with\\nSDNs, BOOM, and GFS, Ray decouples the storage of\\nthe control plane information (e.g., GCS) from the logic\\nimplementation (e.g., schedulers). This allows both stor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='SDNs, BOOM, and GFS, Ray decouples the storage of\\nthe control plane information (e.g., GCS) from the logic\\nimplementation (e.g., schedulers). This allows both stor-\\nage and computation layers to scale independently, which\\nis key to achieving our scalability targets. Omega uses\\na distributed architecture in which schedulers coordinate\\nvia globally shared state. To this architecture, Ray adds\\nglobal schedulers to balance load across local schedulers,\\nand targets ms-level, not second-level, task scheduling.\\nRay implements a unique distributed bottom-up sched-\\nuler that is horizontally scalable, and can handle dynami-\\ncally constructed task graphs. Unlike Ray, most existing\\ncluster computing systems [20, 64, 40] use a centralized\\nscheduler architecture. While Sparrow [45] is decentral-\\nized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. Mesos [ 26] im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. Mesos [ 26] im-\\nplements a two-level hierarchical scheduler, but its top-\\nlevel scheduler manages frameworks, not individual tasks.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Canary [47] achieves impressive performance by having\\neach scheduler instance handle a portion of the task graph,\\nbut does not handle dynamic computation graphs.\\nCilk [12] is a parallel programming language whose\\nwork-stealing scheduler achieves provably efﬁcient load-\\nbalancing for dynamic task graphs. However, with no cen-\\ntral coordinator like Ray’s global scheduler, this fully par-\\nallel design is also difﬁcult to extend to support data lo-\\ncality and resource heterogeneity in a distributed setting.\\n7 Discussion and Experiences\\nBuilding Ray has been a long journey. It started two years\\nago with a Spark library to perform distributed training\\nand simulations. However, the relative inﬂexibility of the\\nBSP model, the high per-task overhead, and the lack of an\\nactor abstraction led us to develop a new system. Since we\\nreleased Ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. Here we discuss our experience developing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='released Ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. Here we discuss our experience developing\\nand using Ray, and some early user feedback.\\nAPI. In designing the API, we have emphasized mini-\\nmalism. Initially we started with a basic task abstraction.\\nLater, we added the wait() primitive to accommodate roll-\\nouts with heterogeneous durations and the actor abstrac-\\ntion to accommodate third-party simulators and amortize\\nthe overhead of expensive initializations. While the re-\\nsulting API is relatively low-level, it has proven both pow-\\nerful and simple to use. We have already used this API to\\nimplement many state-of-the-art RL algorithms on top of\\nRay, including A3C [36], PPO [51], DQN [37], ES [49],\\nDDPG [55], and Ape-X [ 27]. In most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nRay. Based on early user feedback, we are considering'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='DDPG [55], and Ape-X [ 27]. In most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nRay. Based on early user feedback, we are considering\\nenhancing the API to include higher level primitives and\\nlibraries, which could also inform scheduling decisions.\\nLimitations. Given the workload generality, special-\\nized optimizations are hard. For example, we must make\\nscheduling decisions without full knowledge of the com-\\nputation graph. Scheduling optimizations in Ray might\\nrequire more complex runtime proﬁling. In addition, stor-\\ning lineage for each task requires the implementation of\\ngarbage collection policies to bound storage costs in the\\nGCS, a feature we are actively developing.\\nFault tolerance. We are often asked if fault tolerance\\nis really needed for AI applications. After all, due to the\\nstatistical nature of many AI algorithms, one could sim-\\nply ignore failed rollouts. Based on our experience, our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='is really needed for AI applications. After all, due to the\\nstatistical nature of many AI algorithms, one could sim-\\nply ignore failed rollouts. Based on our experience, our\\nanswer is “yes”. First, the ability to ignore failures makes\\napplications much easier to write and reason about. Sec-\\nond, our particular implementation of fault tolerance via\\ndeterministic replay dramatically simpliﬁes debugging as\\nit allows us to easily reproduce most errors. This is par-\\nticularly important since, due to their stochasticity, AI al-\\ngorithms are notoriously hard to debug. Third, fault toler-\\nance helps save money since it allows us to run on cheap\\nresources like spot instances on AWS. Of course, this\\ncomes at the price of some overhead. However, we found\\nthis overhead to be minimal for our target workloads.\\nGCS and Horizontal Scalability. The GCS dramati-\\ncally simpliﬁed Ray development and debugging. It en-\\nabled us to query the entire system state while debugging'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='GCS and Horizontal Scalability. The GCS dramati-\\ncally simpliﬁed Ray development and debugging. It en-\\nabled us to query the entire system state while debugging\\nRay itself, instead of having to manually expose internal\\ncomponent state. In addition, the GCS is also the backend\\nfor our timeline visualization tool, used for application-\\nlevel debugging.\\nThe GCS was also instrumental to Ray’s horizontal\\nscalability. In Section 5, we were able to scale by adding\\nmore shards whenever the GCS became a bottleneck. The\\nGCS also enabled the global scheduler to scale by sim-\\nply adding more replicas. Due to these advantages, we\\nbelieve that centralizing control state will be a key design\\ncomponent of future distributed systems.\\n8 Conclusion\\nNo general-purpose system today can efﬁciently support\\nthe tight loop of training, serving, and simulation. To ex-\\npress these core building blocks and meet the demands of\\nemerging AI applications, Ray uniﬁes task-parallel and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the tight loop of training, serving, and simulation. To ex-\\npress these core building blocks and meet the demands of\\nemerging AI applications, Ray uniﬁes task-parallel and\\nactor programming models in a single dynamic task graph\\nand employs a scalable architecture enabled by the global\\ncontrol store and a bottom-up distributed scheduler. The\\nprogramming ﬂexibility, high throughput, and low laten-\\ncies simultaneously achieved by this architecture is partic-\\nularly important for emerging artiﬁcial intelligence work-\\nloads, which produce tasks diverse in their resource re-\\nquirements, duration, and functionality. Our evaluation\\ndemonstrates linear scalability up to 1.8 million tasks per\\nsecond, transparent fault tolerance, and substantial perfor-\\nmance improvements on several contemporary RL work-\\nloads. Thus, Ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future AI applications.\\n9 Acknowledgments'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='loads. Thus, Ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future AI applications.\\n9 Acknowledgments\\nThis research is supported in part by NSF CISE Expedi-\\ntions Award CCF-1730628 and gifts from Alibaba, Ama-\\nzon Web Services, Ant Financial, Arm, CapitalOne, Eric-\\nsson, Facebook, Google, Huawei, Intel, Microsoft, Sco-\\ntiabank, Splunk and VMware as well as by NSF grant\\nDGE-1106400. We are grateful to our anonymous review-\\ners and our shepherd, Miguel Castro, for thoughtful feed-\\nback, which helped improve the quality of this paper.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Akka. https://akka.io/.\\n[2] Apache Arrow. https://arrow.apache.org/.\\n[3] Dask Benchmarks. http://matthewrocklin.com/blog/\\nwork/2017/07/03/scaling.\\n[4] EC2 Instance Pricing. https://aws.amazon.com/ec2/\\npricing/on-demand/.\\n[5] OpenAI Baselines: high-quality implementations of reinforce-\\nment learning algorithms. https://github.com/openai/\\nbaselines.\\n[6] TensorFlow Serving. https://www.tensorflow.org/\\nserving/.\\n[7] ABADI , M., B ARHAM , P., C HEN , J., C HEN , Z., D AVIS, A.,\\nDEAN , J., D EVIN , M., G HEMAWAT, S., I RVING , G., I SARD , M.,\\nET AL . TensorFlow: A system for large-scale machine learning.\\nIn Proceedings of the 12th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI). Savannah, Georgia,\\nUSA (2016).\\n[8] A GARWAL , A., B IRD , S., C OZOWICZ , M., H OANG , L., L ANG -\\nFORD , J., L EE, S., L I, J., M ELAMED , D., O SHRI , G., R IBAS ,\\nO., S EN, S., AND SLIVKINS , A. A multiworld testing decision\\nservice. arXiv preprint arXiv:1606.03966 (2016).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='FORD , J., L EE, S., L I, J., M ELAMED , D., O SHRI , G., R IBAS ,\\nO., S EN, S., AND SLIVKINS , A. A multiworld testing decision\\nservice. arXiv preprint arXiv:1606.03966 (2016).\\n[9] ALVARO, P., C ONDIE , T., C ONWAY, N., E LMELEEGY , K.,\\nHELLERSTEIN , J. M., AND SEARS , R. BOOM Analytics: ex-\\nploring data-centric, declarative programming for the cloud. In\\nProceedings of the 5th European conference on Computer systems\\n(2010), ACM, pp. 223–236.\\n[10] ARMSTRONG , J., V IRDING , R., W IKSTR ¨OM, C., AND\\nWILLIAMS , M. Concurrent programming in ERLANG.\\n[11] BEATTIE , C., L EIBO , J. Z., T EPLYASHIN , D., W ARD , T.,\\nWAINWRIGHT , M., K ¨UTTLER , H., L EFRANCQ , A., G REEN , S.,\\nVALD ´ES, V., SADIK , A., ET AL . DeepMind Lab. arXiv preprint\\narXiv:1612.03801 (2016).\\n[12] BLUMOFE , R. D., AND LEISERSON , C. E. Scheduling mul-\\ntithreaded computations by work stealing. J. ACM 46, 5 (Sept.\\n1999), 720–748.\\n[13] B ROCKMAN , G., C HEUNG , V., PETTERSSON , L., S CHNEIDER ,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tithreaded computations by work stealing. J. ACM 46, 5 (Sept.\\n1999), 720–748.\\n[13] B ROCKMAN , G., C HEUNG , V., PETTERSSON , L., S CHNEIDER ,\\nJ., S CHULMAN , J., T ANG , J., AND ZAREMBA , W. OpenAI gym.\\narXiv preprint arXiv:1606.01540 (2016).\\n[14] BYKOV, S., G ELLER , A., K LIOT , G., L ARUS , J. R., P ANDYA ,\\nR., AND THELIN , J. Orleans: Cloud computing for everyone. In\\nProceedings of the 2nd ACM Symposium on Cloud Computing\\n(2011), ACM, p. 16.\\n[15] CARBONE , P., E WEN , S., F ´ORA , G., H ARIDI , S., R ICHTER ,\\nS., AND TZOUMAS , K. State management in Apache Flink:\\nConsistent stateful distributed stream processing. Proc. VLDB\\nEndow. 10, 12 (Aug. 2017), 1718–1729.\\n[16] CASADO , M., F REEDMAN , M. J., P ETTIT , J., L UO, J., M CKE-\\nOWN , N., AND SHENKER , S. Ethane: Taking control of the enter-\\nprise. SIGCOMM Comput. Commun. Rev. 37, 4 (Aug. 2007), 1–12.\\n[17] CHAROUSSET , D., S CHMIDT , T. C., H IESGEN , R., AND\\nW ¨AHLISCH , M. Native actors: A scalable software platform for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='prise. SIGCOMM Comput. Commun. Rev. 37, 4 (Aug. 2007), 1–12.\\n[17] CHAROUSSET , D., S CHMIDT , T. C., H IESGEN , R., AND\\nW ¨AHLISCH , M. Native actors: A scalable software platform for\\ndistributed, heterogeneous environments. In Proceedings of the\\n2013 workshop on Programming based on actors, agents, and de-\\ncentralized control (2013), ACM, pp. 87–96.\\n[18] CHEN , T., L I, M., L I, Y., L IN, M., W ANG , N., W ANG , M.,\\nXIAO , T., X U, B., Z HANG , C., AND ZHANG , Z. MXNet: A\\nﬂexible and efﬁcient machine learning library for heterogeneous\\ndistributed systems. In NIPS Workshop on Machine Learning\\nSystems (LearningSys’16)(2016).\\n[19] CRANKSHAW , D., W ANG , X., Z HOU , G., F RANKLIN , M. J.,\\nGONZALEZ , J. E., AND STOICA , I. Clipper: A low-latency\\nonline prediction serving system. In 14th USENIX Symposium\\non Networked Systems Design and Implementation (NSDI 17)\\n(Boston, MA, 2017), USENIX Association, pp. 613–627.\\n[20] DEAN , J., AND GHEMAWAT, S. MapReduce: Simpliﬁed data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='on Networked Systems Design and Implementation (NSDI 17)\\n(Boston, MA, 2017), USENIX Association, pp. 613–627.\\n[20] DEAN , J., AND GHEMAWAT, S. MapReduce: Simpliﬁed data\\nprocessing on large clusters. Commun. ACM 51, 1 (Jan. 2008),\\n107–113.\\n[21] DENNIS , J. B., AND MISUNAS , D. P. A preliminary architecture\\nfor a basic data-ﬂow processor. In Proceedings of the 2Nd An-\\nnual Symposium on Computer Architecture (New York, NY , USA,\\n1975), ISCA ’75, ACM, pp. 126–132.\\n[22] GABRIEL , E., F AGG , G. E., B OSILCA , G., A NGSKUN , T., D ON-\\nGARRA , J. J., S QUYRES , J. M., S AHAY, V., K AMBADUR , P.,\\nBARRETT , B., L UMSDAINE , A., C ASTAIN , R. H., D ANIEL ,\\nD. J., G RAHAM , R. L., AND WOODALL , T. S. Open MPI: Goals,\\nconcept, and design of a next generation MPI implementation. In\\nProceedings, 11th European PVM/MPI Users’ Group Meeting\\n(Budapest, Hungary, September 2004), pp. 97–104.\\n[23] GHEMAWAT, S., G OBIOFF , H., AND LEUNG , S.-T. The Google\\nﬁle system. 29–43.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Proceedings, 11th European PVM/MPI Users’ Group Meeting\\n(Budapest, Hungary, September 2004), pp. 97–104.\\n[23] GHEMAWAT, S., G OBIOFF , H., AND LEUNG , S.-T. The Google\\nﬁle system. 29–43.\\n[24] GONZALEZ , J. E., X IN, R. S., D AVE, A., C RANKSHAW , D.,\\nFRANKLIN , M. J., AND STOICA , I. GraphX: Graph processing\\nin a distributed dataﬂow framework. In Proceedings of the 11th\\nUSENIX Conference on Operating Systems Design and Implemen-\\ntation (Berkeley, CA, USA, 2014), OSDI’14, USENIX Associa-\\ntion, pp. 599–613.\\n[25] GU*, S., H OLLY *, E., L ILLICRAP , T., AND LEVINE , S. Deep re-\\ninforcement learning for robotic manipulation with asynchronous\\noff-policy updates. In IEEE International Conference on Robotics\\nand Automation (ICRA 2017) (2017).\\n[26] HINDMAN , B., K ONWINSKI , A., Z AHARIA , M., G HODSI , A.,\\nJOSEPH , A. D., K ATZ, R., S HENKER , S., AND STOICA , I.\\nMesos: A platform for ﬁne-grained resource sharing in the data\\ncenter. In Proceedings of the 8th USENIX Conference on Net-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='JOSEPH , A. D., K ATZ, R., S HENKER , S., AND STOICA , I.\\nMesos: A platform for ﬁne-grained resource sharing in the data\\ncenter. In Proceedings of the 8th USENIX Conference on Net-\\nworked Systems Design and Implementation (Berkeley, CA, USA,\\n2011), NSDI’11, USENIX Association, pp. 295–308.\\n[27] HORGAN , D., Q UAN , J., B UDDEN , D., B ARTH -MARON , G.,\\nHESSEL , M., VAN HASSELT , H., AND SILVER , D. Distributed\\nprioritized experience replay. International Conference on Learn-\\ning Representations (2018).\\n[28] ISARD , M., B UDIU , M., Y U, Y., B IRRELL , A., AND FETTERLY ,\\nD. Dryad: Distributed data-parallel programs from sequential\\nbuilding blocks. In Proceedings of the 2nd ACM SIGOPS/EuroSys\\nEuropean Conference on Computer Systems 2007 (New York, NY ,\\nUSA, 2007), EuroSys ’07, ACM, pp. 59–72.\\n[29] JIA, Y., SHELHAMER , E., D ONAHUE , J., K ARAYEV, S., L ONG ,\\nJ., G IRSHICK , R., G UADARRAMA , S., AND DARRELL , T. Caffe:\\nConvolutional architecture for fast feature embedding. arXiv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[29] JIA, Y., SHELHAMER , E., D ONAHUE , J., K ARAYEV, S., L ONG ,\\nJ., G IRSHICK , R., G UADARRAMA , S., AND DARRELL , T. Caffe:\\nConvolutional architecture for fast feature embedding. arXiv\\npreprint arXiv:1408.5093 (2014).\\n[30] JORDAN , M. I., AND MITCHELL , T. M. Machine learning:\\nTrends, perspectives, and prospects. Science 349, 6245 (2015),\\n255–260.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[31] LEIBIUSKY , J., E ISBRUCH , G., AND SIMONASSI , D. Getting\\nStarted with Storm. O’Reilly Media, Inc., 2012.\\n[32] LI, M., A NDERSEN , D. G., P ARK , J. W., S MOLA , A. J.,\\nAHMED , A., J OSIFOVSKI , V., LONG , J., S HEKITA , E. J., AND\\nSU, B.-Y. Scaling distributed machine learning with the parame-\\nter server. In Proceedings of the 11th USENIX Conference on Op-\\nerating Systems Design and Implementation (Berkeley, CA, USA,\\n2014), OSDI’14, pp. 583–598.\\n[33] L OOKS , M., H ERRESHOFF , M., H UTCHINS , D., AND NORVIG ,\\nP. Deep learning with dynamic computation graphs.arXiv preprint\\narXiv:1702.02181 (2017).\\n[34] LOW, Y., G ONZALEZ , J., K YROLA , A., B ICKSON , D.,\\nGUESTRIN , C., AND HELLERSTEIN , J. GraphLab: A new frame-\\nwork for parallel machine learning. In Proceedings of the Twenty-\\nSixth Conference on Uncertainty in Artiﬁcial Intelligence (Arling-\\nton, Virginia, United States, 2010), UAI’10, pp. 340–349.\\n[35] MALEWICZ , G., A USTERN , M. H., B IK, A. J., D EHNERT , J. C.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Sixth Conference on Uncertainty in Artiﬁcial Intelligence (Arling-\\nton, Virginia, United States, 2010), UAI’10, pp. 340–349.\\n[35] MALEWICZ , G., A USTERN , M. H., B IK, A. J., D EHNERT , J. C.,\\nHORN , I., L EISER , N., AND CZAJKOWSKI , G. Pregel: A system\\nfor large-scale graph processing. In Proceedings of the 2010 ACM\\nSIGMOD International Conference on Management of Data(New\\nYork, NY , USA, 2010), SIGMOD ’10, ACM, pp. 135–146.\\n[36] MNIH , V., BADIA , A. P., M IRZA , M., G RAVES , A., L ILLICRAP ,\\nT. P., HARLEY , T., S ILVER , D., AND KAVUKCUOGLU , K. Asyn-\\nchronous methods for deep reinforcement learning. In Interna-\\ntional Conference on Machine Learning (2016).\\n[37] MNIH , V., K AVUKCUOGLU , K., S ILVER , D., R USU , A. A.,\\nVENESS , J., B ELLEMARE , M. G., G RAVES , A., R IEDMILLER ,\\nM., F IDJELAND , A. K., O STROVSKI , G., ET AL . Human-level\\ncontrol through deep reinforcement learning. Nature 518, 7540\\n(2015), 529–533.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='M., F IDJELAND , A. K., O STROVSKI , G., ET AL . Human-level\\ncontrol through deep reinforcement learning. Nature 518, 7540\\n(2015), 529–533.\\n[38] MURRAY, D. A Distributed Execution Engine Supporting Data-\\ndependent Control Flow. University of Cambridge, 2012.\\n[39] MURRAY, D. G., M CSHERRY, F., I SAACS , R., I SARD , M.,\\nBARHAM , P., AND ABADI , M. Naiad: A timely dataﬂow system.\\nIn Proceedings of the Twenty-Fourth ACM Symposium on Operat-\\ning Systems Principles (New York, NY , USA, 2013), SOSP ’13,\\nACM, pp. 439–455.\\n[40] MURRAY, D. G., S CHWARZKOPF , M., S MOWTON , C., S MITH ,\\nS., M ADHAVAPEDDY , A., AND HAND , S. CIEL: A universal exe-\\ncution engine for distributed data-ﬂow computing. In Proceedings\\nof the 8th USENIX Conference on Networked Systems Design and\\nImplementation (Berkeley, CA, USA, 2011), NSDI’11, USENIX\\nAssociation, pp. 113–126.\\n[41] NAIR , A., S RINIVASAN , P., B LACKWELL , S., A LCICEK , C.,\\nFEARON , R., M ARIA , A. D., P ANNEERSHELVAM , V., SULEY -'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Association, pp. 113–126.\\n[41] NAIR , A., S RINIVASAN , P., B LACKWELL , S., A LCICEK , C.,\\nFEARON , R., M ARIA , A. D., P ANNEERSHELVAM , V., SULEY -\\nMAN , M., B EATTIE , C., P ETERSEN , S., L EGG , S., M NIH , V.,\\nKAVUKCUOGLU , K., AND SILVER , D. Massively parallel meth-\\nods for deep reinforcement learning, 2015.\\n[42] NG, A., C OATES , A., D IEL , M., G ANAPATHI , V., S CHULTE , J.,\\nTSE, B., B ERGER , E., AND LIANG , E. Autonomous inverted he-\\nlicopter ﬂight via reinforcement learning. Experimental Robotics\\nIX (2006), 363–372.\\n[43] NISHIHARA , R., M ORITZ , P., WANG , S., T UMANOV , A., P AUL ,\\nW., SCHLEIER -SMITH , J., L IAW, R., N IKNAMI , M., J ORDAN ,\\nM. I., AND STOICA , I. Real-time machine learning: The missing\\npieces. In Workshop on Hot Topics in Operating Systems(2017).\\n[44] OPEN AI. OpenAI Dota 2 1v1 bot. https://openai.com/\\nthe-international/, 2017.\\n[45] OUSTERHOUT , K., W ENDELL , P., Z AHARIA , M., AND STOICA ,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[44] OPEN AI. OpenAI Dota 2 1v1 bot. https://openai.com/\\nthe-international/, 2017.\\n[45] OUSTERHOUT , K., W ENDELL , P., Z AHARIA , M., AND STOICA ,\\nI. Sparrow: Distributed, low latency scheduling. In Proceedings\\nof the Twenty-Fourth ACM Symposium on Operating Systems\\nPrinciples (New York, NY , USA, 2013), SOSP ’13, ACM, pp. 69–\\n84.\\n[46] PASZKE , A., G ROSS , S., C HINTALA , S., C HANAN , G., Y ANG ,\\nE., D EVITO , Z., L IN, Z., D ESMAISON , A., A NTIGA , L., AND\\nLERER , A. Automatic differentiation in PyTorch.\\n[47] QU, H., M ASHAYEKHI , O., T EREI , D., AND LEVIS , P. Canary:\\nA scheduling architecture for high performance cloud computing.\\narXiv preprint arXiv:1602.01412 (2016).\\n[48] ROCKLIN , M. Dask: Parallel computation with blocked algo-\\nrithms and task scheduling. In Proceedings of the 14th Python in\\nScience Conference (2015), K. Huff and J. Bergstra, Eds., pp. 130\\n– 136.\\n[49] S ALIMANS , T., H O, J., C HEN , X., AND SUTSKEVER , I. Evolu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Science Conference (2015), K. Huff and J. Bergstra, Eds., pp. 130\\n– 136.\\n[49] S ALIMANS , T., H O, J., C HEN , X., AND SUTSKEVER , I. Evolu-\\ntion strategies as a scalable alternative to reinforcement learning.\\narXiv preprint arXiv:1703.03864 (2017).\\n[50] SANFILIPPO , S. Redis: An open source, in-memory data structure\\nstore. https://redis.io/, 2009.\\n[51] SCHULMAN , J., W OLSKI , F., D HARIWAL , P., R ADFORD , A.,\\nAND KLIMOV, O. Proximal policy optimization algorithms. arXiv\\npreprint arXiv:1707.06347 (2017).\\n[52] SCHWARZKOPF , M., K ONWINSKI , A., A BD-EL-MALEK , M.,\\nAND WILKES , J. Omega: Flexible, scalable schedulers for large\\ncompute clusters. In Proceedings of the 8th ACM European Con-\\nference on Computer Systems (New York, NY , USA, 2013), Eu-\\nroSys ’13, ACM, pp. 351–364.\\n[53] SERGEEV , A., AND DEL BALSO , M. Horovod: fast and\\neasy distributed deep learning in tensorﬂow. arXiv preprint\\narXiv:1802.05799 (2018).\\n[54] SILVER , D., H UANG , A., M ADDISON , C. J., G UEZ , A.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='easy distributed deep learning in tensorﬂow. arXiv preprint\\narXiv:1802.05799 (2018).\\n[54] SILVER , D., H UANG , A., M ADDISON , C. J., G UEZ , A.,\\nSIFRE , L., V AN DEN DRIESSCHE , G., S CHRITTWIESER , J.,\\nANTONOGLOU , I., P ANNEERSHELVAM , V., L ANCTOT , M.,\\nET AL . Mastering the game of Go with deep neural networks and\\ntree search. Nature 529, 7587 (2016), 484–489.\\n[55] SILVER , D., L EVER , G., H EESS , N., D EGRIS , T., W IERSTRA ,\\nD., AND RIEDMILLER , M. Deterministic policy gradient algo-\\nrithms. In ICML (2014).\\n[56] SUTTON , R. S., AND BARTO , A. G. Reinforcement Learning:\\nAn Introduction. MIT press Cambridge, 1998.\\n[57] THAKUR , R., R ABENSEIFNER , R., AND GROPP, W. Optimiza-\\ntion of collective communication operations in MPICH. The Inter-\\nnational Journal of High Performance Computing Applications\\n19, 1 (2005), 49–66.\\n[58] TIAN , Y., GONG , Q., S HANG , W., W U, Y., AND ZITNICK , C. L.\\nELF: An extensive, lightweight and ﬂexible research platform'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='19, 1 (2005), 49–66.\\n[58] TIAN , Y., GONG , Q., S HANG , W., W U, Y., AND ZITNICK , C. L.\\nELF: An extensive, lightweight and ﬂexible research platform\\nfor real-time strategy games. Advances in Neural Information\\nProcessing Systems (NIPS) (2017).\\n[59] TODOROV , E., E REZ , T., AND TASSA , Y. Mujoco: A physics\\nengine for model-based control. In Intelligent Robots and Systems\\n(IROS), 2012 IEEE/RSJ International Conference on(2012), IEEE,\\npp. 5026–5033.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[60] VAN DEN BERG , J., M ILLER , S., D UCKWORTH , D., H U, H.,\\nWAN, A., F U, X.-Y., G OLDBERG , K., AND ABBEEL , P. Su-\\nperhuman performance of surgical tasks by robots using iterative\\nlearning from human-guided demonstrations. In Robotics and Au-\\ntomation (ICRA), 2010 IEEE International Conference on (2010),\\nIEEE, pp. 2074–2081.\\n[61] VAN RENESSE , R., AND SCHNEIDER , F. B. Chain replication for\\nsupporting high throughput and availability. In Proceedings of the\\n6th Conference on Symposium on Opearting Systems Design &\\nImplementation - Volume 6 (Berkeley, CA, USA, 2004), OSDI’04,\\nUSENIX Association.\\n[62] VENKATARAMAN , S., P ANDA , A., O USTERHOUT , K., G HODSI ,\\nA., A RMBRUST , M., R ECHT , B., F RANKLIN , M., AND STOICA ,\\nI. Drizzle: Fast and adaptable stream processing at scale. In\\nProceedings of the Twenty-Sixth ACM Symposium on Operating\\nSystems Principles (2017), SOSP ’17, ACM.\\n[63] WHITE , T. Hadoop: The Deﬁnitive Guide. O’Reilly Media, Inc.,\\n2012.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Proceedings of the Twenty-Sixth ACM Symposium on Operating\\nSystems Principles (2017), SOSP ’17, ACM.\\n[63] WHITE , T. Hadoop: The Deﬁnitive Guide. O’Reilly Media, Inc.,\\n2012.\\n[64] ZAHARIA , M., C HOWDHURY , M., D AS, T., D AVE, A., M A, J.,\\nMCCAULEY, M., F RANKLIN , M. J., S HENKER , S., AND STO-\\nICA , I. Resilient distributed datasets: A fault-tolerant abstrac-\\ntion for in-memory cluster computing. In Proceedings of the 9th\\nUSENIX conference on Networked Systems Design and Implemen-\\ntation (2012), USENIX Association, pp. 2–2.\\n[65] ZAHARIA , M., X IN, R. S., W ENDELL , P., DAS, T., A RMBRUST ,\\nM., D AVE, A., M ENG , X., R OSEN , J., V ENKATARAMAN , S.,\\nFRANKLIN , M. J., G HODSI , A., G ONZALEZ , J., S HENKER , S.,\\nAND STOICA , I. Apache Spark: A uniﬁed engine for big data\\nprocessing. Commun. ACM 59, 11 (Oct. 2016), 56–65.'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Scaling Transformer-Based Novel View Synthesis Models with\\nToken Disentanglement and Synthetic Data\\nNithin Gopalakrishnan Nair1∗ Srinivas Kaza2∗ Xuan Luo2 Vishal M. Patel1\\nStephen Lombardi2 Jungyeon Park2\\n1 Johns Hopkins University 2 Google\\n{ngopala2,vpatel36}@jhu.edu{srinivaskaza,xuluo,salombardi,jungyeonp}@google.com\\nhttps://scaling3dnvs.github.io\\nLVSM\\nOURS\\nLVSM\\nOURS\\nLVSM\\nOURS\\nFigure 1.Overview.Our method performs feed-forward novel-view synthesis from a series of input images, such as the pairs shown\\nabove. We demonstrate strong results in terms of quality and generalization capacity, performing well across a variety of common novel-\\nview synthesis datasets, including scenes that are out-of-distribution.\\nAbstract\\nLarge transformer-based models have made significant\\nprogress in generalizable novel view synthesis (NVS) from\\nsparse input views, generating novel viewpoints without the\\nneed for test-time optimization. However, these models'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='progress in generalizable novel view synthesis (NVS) from\\nsparse input views, generating novel viewpoints without the\\nneed for test-time optimization. However, these models\\nare constrained by the limited diversity of publicly avail-\\nable scene datasets, making most real-world (in-the-wild)\\nscenes out-of-distribution. To overcome this, we incorpo-\\nrate synthetic training data generated from diffusion mod-\\nels, which improves generalization across unseen domains.\\nWhile synthetic data offers scalability, we identify artifacts\\nintroduced during data generation as a key bottleneck af-\\nfecting reconstruction quality. To address this, we propose\\na token disentanglement process within the transformer ar-\\nchitecture, enhancing feature separation and ensuring more\\neffective learning. This refinement not only improves re-\\narXiv:2509.06950v1  [cs.GR]  8 Sep 2025'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='construction quality over standard transformers but also\\nenables scalable training with synthetic data. As a result,\\nour method outperforms existing models on both in-dataset\\nand cross-dataset evaluations, achieving state-of-the-art re-\\nsults across multiple benchmarks while significantly reduc-\\ning computational costs.\\n1. Introduction\\nNovel view synthesis (NVS) [20, 27] is a well-studied and\\nimportant problem in computer vision, where the task is to\\ngenerate unseen perspectives of a scene from a given set of\\nimages. Many approaches utilize volumetric [2, 5, 27, 28]\\nor differentiable rendering [20] to optimize for each scene\\nindividually, achieving high-quality NVS from arbitrary\\nviewpoints. More recently, advancements have enabled\\ntraining a single model that generalizes to novel scenes\\nwithout requiring per-scene optimization. Most existing\\nmethods address NVS by incorporating hand-crafted 3D\\npriors and architectural biases [4, 16, 39]. While these de-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='without requiring per-scene optimization. Most existing\\nmethods address NVS by incorporating hand-crafted 3D\\npriors and architectural biases [4, 16, 39]. While these de-\\nsign choices provide structure, they limit scalability with\\ndata and hinder generalization.\\nRecently, Large View Synthesis Model (LVSM) [19]\\nproposed a promising foundation for an NVS model scal-\\nable with large datasets. LVSM introduces an architec-\\nture that doesn’t require 3D inductive biases for scene re-\\nconstruction. It employs a decoder-only transformer ar-\\nchitecture that achieves state-of-the-art results by a sig-\\nnificant margin, with the performance improving with in-\\ncreased compute. However, we observed during our exper-\\niments that the decoder-only design causes an inherent fea-\\nture alignment problem which causes the target and source\\nfeatures to look similar at all layers. Thus, part of the trans-\\nformer’s computational capacity is spent modifying source'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ture alignment problem which causes the target and source\\nfeatures to look similar at all layers. Thus, part of the trans-\\nformer’s computational capacity is spent modifying source\\ntoken information that is ultimately discarded at the end\\nof the transformer block, reducing efficiency. This design\\nchoice also makes LVSM susceptible to unwanted noise\\nor compression artifacts that may be present in the source\\nviews. In addition, we noticed that LVSM presents limited\\ncross-domain performance when tested on datasets outside\\nthe training dataset domains.\\nMoreover, these issues are not unique to LVSM; many\\nNVS models face similar challenges due to data scarcity\\nin 3D vision. All existing multi-view 3D scene datasets\\n[24, 25, 49] combined contain fewer than 100,000 scenes,\\nseverely limiting the performance of NVS models on in-\\nthe-wild cases beyond the training distribution. One pos-\\nsible solution for alleviating this 3D data scarcity is using'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='severely limiting the performance of NVS models on in-\\nthe-wild cases beyond the training distribution. One pos-\\nsible solution for alleviating this 3D data scarcity is using\\nsynthetic data from generative models. Recent research has\\nexplored adapting pre-trained image [33, 34] and video dif-\\nfusion models [14, 15] for multi-view dataset generation\\n*Equal contribution. Nair designed the methodology, conducted pre-\\nrebuttal experiments, and drafted the initial manuscript. Kaza helped ad-\\nvise the project, led the rebuttal, and conducted camera-ready experiments.\\n[10, 26, 36, 44]. However, previous feed-forward mod-\\nels trained using synthetic data perform worse than those\\ntrained with real data. We hypothesize that the inability of\\nsynthetic data to improve reconstruction quality stems from\\ntwo types of degradation artifacts in scenes generated by\\ndiffusion models [15, 29, 38] (1) artifacts influenced by the\\ninitial noise of the diffusion process and (2) artifacts intro-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='two types of degradation artifacts in scenes generated by\\ndiffusion models [15, 29, 38] (1) artifacts influenced by the\\ninitial noise of the diffusion process and (2) artifacts intro-\\nduced during decoding, as most diffusion-based scene syn-\\nthesis models operate in latent space and rely on a diffusion\\nV AE [33]. We address both issues, leading to improved per-\\nformance when using synthetic data. We provide a detailed\\nexplanation of our data pipeline in Section 4.2.\\nIn this work, we tackle a key challenge in developing\\na feed-forward NVS model that performs well on out-of-\\ndistribution data – the need for a scalable and efficient\\ntransformer-based NVS architecture. We introduce the To-\\nken Distentangled (Tok-D) transformer block, which ap-\\nplies layer-wise modulation of source and target tokens, ex-\\nplicitly distinguishing the two at each layer. These model\\nmodifications improve out-of-distribution training, which\\nintroduces the possibility of training on synthetic data. We'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='plicitly distinguishing the two at each layer. These model\\nmodifications improve out-of-distribution training, which\\nintroduces the possibility of training on synthetic data. We\\nuse the CAT3D model to generate a large dataset of syn-\\nthetic multi-view samples. We then employ a novel data\\ngeneration strategy that significantly improves the quality\\nof these synthetic samples. We show that the Tok-D trans-\\nformer block can be trained with synthetic data augmenta-\\ntion, unlike the baseline LVSM method which suffers from\\nthe inclusion of synthetic data.\\n• We enhance the scalability of transformer architectures\\nfor NVS, enabling more efficient modeling.\\n• We introduce a new training scheme that is less suscepti-\\nble to artifacts from synthetic data.\\n• We improve the training efficiency of transformer for\\nNVS by introducing a new transformer block.\\n• Our approach achieves state-of-the-art results across mul-\\ntiple benchmarks for scene level NVS.\\n2. Related Works'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='NVS by introducing a new transformer block.\\n• Our approach achieves state-of-the-art results across mul-\\ntiple benchmarks for scene level NVS.\\n2. Related Works\\n2.1. Offline Novel View Synthesis\\nThe advent of neural rendering in recent years has substan-\\ntially improved the quality of NVS. Early neural scene rep-\\nresentations focused on the 4D plenoptic function [11, 23]\\nthat represents the lightfield of a scene [1, 37, 39]. Other\\nmethods modeled the geometry of the scene (e.g. as a\\nsigned distance function) separately from material proper-\\nties [40, 45]. Either way, a differentiable rendering process\\nwas used to render these neural representations into 2D im-\\nages [27]. Most of these methods focused on fitting neu-\\nral fields to sparse observations of a scene at test time—\\nwe refer to this as test-time or offline optimization. There\\nis a substantial amount of heterogeneity in these methods,\\nboth in terms of the rendering method and the scene repre-\\n2'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Tok-D Transformer Blocks\\nSource Patchify Patchify\\nSource tokens\\nTarget tokens\\nMulti-View Diﬀusion Model\\n   Input View\\n                           Generated Views\\nSynthetic Data Generation NVS Model Training\\nUnPatchify\\nFigure 2.An illustration of the architecture.We use CAT3D, a multi-view diffusion model, to generate synthetic views conditioned on\\nrandom spline camera trajectories and a random image. From the two random views form the generated views as the source views and\\nthe input conditioning view to be the target of our large reconstruction network. Our large reconstruction model uses a special transformer\\nblock which we name Tok-D Transformer. When real data is available, we just use the reconstruction transformer.\\nsentation used. Multi-layer perceptrons (MLPs) [27], vox-\\nels [9, 26], hashing-based representations [3, 28], triplanes\\n[5], and, most recently, Gaussian splats [17, 20, 21, 31]\\nhave been used as scene representations. These meth-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='els [9, 26], hashing-based representations [3, 28], triplanes\\n[5], and, most recently, Gaussian splats [17, 20, 21, 31]\\nhave been used as scene representations. These meth-\\nods have trade-offs between reconstruction quality, training\\ntime, inference time, memory/space requirements, capacity\\nto model view-dependent effects, etc. Some of these offline\\nmethods can even fit dynamic scenes. These test-time opti-\\nmization methods demonstrate compelling results given the\\nsparsity of the observations provided. However, they often\\nstruggle to incorporate priors learned from larger datasets.\\n2.2. Online Novel View Synthesis\\nSometimes referred to as “feed-forward” or “generaliz-\\nable” NVS models, these methods attempt to directly pro-\\nduce 3D representations from input images. Early efforts\\ninclude the image-based rendering-inspired IBRNet [41],\\nwhich directly produces 2D images based on epipolar cor-\\nrespondences on the viewing ray. The Large Reconstruc-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='include the image-based rendering-inspired IBRNet [41],\\nwhich directly produces 2D images based on epipolar cor-\\nrespondences on the viewing ray. The Large Reconstruc-\\ntion Model (LRM) [16] family of methods attempt to pro-\\nduce a triplane that represents an object, in some cases with\\nnear-real time performance. PixelSplat [4], MVSplat [4],\\nand GS-LRM [47] attempt to predict 3DGS [20] representa-\\ntions, which exploit the sparse Gaussian splat representation\\nand fast rasterization to achieve quasi-interactive inference.\\nThese methods are trained on large datasets of real-world\\nscenes, which helps them outperform even test-time opti-\\nmization methods. Quark [8] couples an easily-rasterizable\\nlayered depth map representation with a render-and-refine\\nstrategy to achieve state-of-the-art quality at a much higher\\nresolution. Other efforts in this space include GPNR [39]\\nand SRT [35], which are parameterized in a similar fash-\\nion to IBRNet [41] and attempt to scale up the image and'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='resolution. Other efforts in this space include GPNR [39]\\nand SRT [35], which are parameterized in a similar fash-\\nion to IBRNet [41] and attempt to scale up the image and\\nray transformers. LRF [22] attempts to perform 3D recon-\\nstruction in the latent space of a V AE, bypassing learning\\n3D representation altogether [48]. Finally, the LVSM [19]\\nremoves all 3D priors by simply using one transformer to\\nperform NVS. LVSM performs favorably compared to both\\ngeometry-free and geometry-based feed-forward models.\\n2.3. Synthetic Data\\nRecent efforts have leveraged synthetic data to train exist-\\ning feed-forward NVS methods and investigate its efficacy\\nas a training dataset. However, it is important to note that\\nthe synthetic data in many of these efforts are generated\\nprocedurally from systems like Blender, whereas ours are\\ngenerated from a multi-view diffusion model. Two recent\\nworks LRM-Zero [43] and MegaSynth [18] are examples\\nof models trained either entirely or mostly on procedurally'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='generated from a multi-view diffusion model. Two recent\\nworks LRM-Zero [43] and MegaSynth [18] are examples\\nof models trained either entirely or mostly on procedurally\\ngenerated synthetic data. In LRM-Zero, they demonstrate\\nthat the LRM model can be trained entirely on synthetic\\ndata. However, the synthetic-data-only model shows a sub-\\nstantial decrease in reconstruction quality compared to the\\nreal-world-data equivalent. Improving training data diver-\\nsity using synthetic data for 4D generation has also been\\nexplored in CAT4D [42].\\n3. Background\\nLVSM is a feed-forward NVS method that has no 3D in-\\nductive bias. Since our model builds upon its architecture,\\n3'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Feedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\nEmbedding \\nLayer\\n𝐑d\\n𝐑k\\nPre-Modulate\\nLinear Layer\\n𝐑6d\\nStyle \\nembed\\nPost-Modulate\\nPre-Modulate\\nPost-Modulate\\n 0\\n 1\\nStyle Tokens\\nFeedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\n 0\\n 1\\nEmbedding \\nLayer\\n 𝐑d\\n𝐑k\\nModulate\\nLinear Layer\\n𝐑2d\\nStyle Tokens\\nStyle \\nembed\\nFigure 3.An illustration of the Tok-D transformer block.Our transformer blocks that differentiates between source and target tokens.\\nTok-D transformer modulates the input to all transformer blocks. Tok-D plus transformer modulates the attention and MLP layers.\\nwe outline the details here for clarity. Whereidenotes the\\nimage index andjdenotes the token index, source images\\npatches are written asIs\\nij ∈R p×p×3, source Pl¨ucker coordi-\\nnates patchesP s\\nij ∈R p×p×6, and target Pl¨ucker coordinates\\nPt\\nj ∈R p×p×6. The source images and pl ¨ucker embeddings\\nare tokenized together using a linear layer embedder.\\nSij =Linear([I s\\nij, Ps\\nij]) (1)'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ij ∈R p×p×6, and target Pl¨ucker coordinates\\nPt\\nj ∈R p×p×6. The source images and pl ¨ucker embeddings\\nare tokenized together using a linear layer embedder.\\nSij =Linear([I s\\nij, Ps\\nij]) (1)\\nThe target Pl ¨ucker coordinates are also embedded using a\\nlinear layer.\\nTij =Linear(P t\\nij) (2)\\nFinally, the transformer network is trained to reconstruct the\\ntarget output tokensOt\\nj from the Pl¨ucker patch embeddings.\\nOt\\nj =M(T j|Sij) (3)\\nThe target output tokens are detokenized using a linear\\nlayer which is converted to target image embeddingsT j ∈\\nRp×p×3\\nTj =Linear([O t\\nj]) (4)\\nThe target patches are unpatchified to get the target image\\nT∈R H×W×3 (see Figure 2). The training is supervised\\nusing MSE loss and perceptual loss designed to reconstruct.\\nTransformer BlockConsider a transformer block at\\nlayerl, which includes aMulti-head Self Attentionlayer\\n(SelfAttnl), a Feed-forward network (FFN l), and a Layer\\nNorm operation (LNl). For an input[x s\\nl ,x t\\nl], wherex s\\nl and\\nxt'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='layerl, which includes aMulti-head Self Attentionlayer\\n(SelfAttnl), a Feed-forward network (FFN l), and a Layer\\nNorm operation (LNl). For an input[x s\\nl ,x t\\nl], wherex s\\nl and\\nxt\\nl represent the source and target tokens, the data flow as\\nfollows:\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +SelfAttnl([xs\\nl ,x t\\nl])(5)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +FFNl(LNl([xs\\nl ,x t\\nl])).\\nGiven the basic self attention based transformer blocks in\\nLVSM. At the end of the optimization process there arises a\\nneed for all token outputs of a particular layer to be aligned\\nsince they are processed by the same set of weights. Hence,\\nLVSM inherently has a chance to infuse noise or atifacts\\nthat maybe present in the source images to the target. More-\\nover this alignment also causes some part of the computa-\\ntional power of the model being used to model source token\\ninformation although those tokens are discarded at the last\\nlayer. Hence, we call for a need to distinguish between the'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tional power of the model being used to model source token\\ninformation although those tokens are discarded at the last\\nlayer. Hence, we call for a need to distinguish between the\\nsource and target tokens of the transformer network.\\n4. Method\\nOur proposed method consists of two major contributions.\\nFirst, ourToken-Disentangled (Tok-D)transformer block\\nis specialized for NVS and distinguishes information from\\nthe source and target views, leading to more efficient allo-\\ncation of representation capacity. Second, to address the\\nscarcity of multi-view data, we generate synthetic data us-\\ning CAT3D [10] and propose a model training scheme that\\nis robust to artifacts in this synthetic data. In this section,\\nwe describe each component in detail.\\n4.1. Token-Disentangled Transformer\\nIn LVSM, the transformer blocks process source and target\\ntokens in the same manner, even though the source consists\\nof images and Pl ¨ucker rays, while the target includes only'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='In LVSM, the transformer blocks process source and target\\ntokens in the same manner, even though the source consists\\nof images and Pl ¨ucker rays, while the target includes only\\nPl¨ucker rays. Additionally, source and target image quality\\ncan differ when training with synthetic data. To address this,\\nwe introduce theToken-Disentangled (Tok-D) Transformer\\nblock (see Figure 3), which enables differentiated process-\\ning of source and target tokens through modulation. The\\nTok-D Transformer uses an indicator variable (δ), where\\nδ= 1for target tokens andδ= 0for source tokens, to\\nmodulate tokens based on their origin. This mechanism ex-\\ntracts distinct style vectors and computes specific scale and\\nbias parameters for each layer and token type, allowing for\\nprecise and adaptive token modulation.\\nstyle=Linear(Embed(δ))(6)\\nModl(x) = (1 +σl)x+µ l,where[σ l, µl] =Linearl(style)\\n[xs\\nl ,x t\\nl] =Mods,t\\nl ([xs\\nl ,x t\\nl]) = [Mods\\nl (xs\\nl ),Mod t\\nl(xt\\nl)]'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='precise and adaptive token modulation.\\nstyle=Linear(Embed(δ))(6)\\nModl(x) = (1 +σl)x+µ l,where[σ l, µl] =Linearl(style)\\n[xs\\nl ,x t\\nl] =Mods,t\\nl ([xs\\nl ,x t\\nl]) = [Mods\\nl (xs\\nl ),Mod t\\nl(xt\\nl)]\\nModulating the input of each transformer block improves\\nperforamnce. Drawing inspiration from DiT [30], we\\n4'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='extend this modulation to the Attention and MLP lay-\\ners, achieving further improvements. This modulation is\\ntermedpre-modulationif applied before a layer andpost-\\nmodulationif after. Pre-modulation includes both scaling\\nand shifting, and post-modulation involves only scaling.\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl1 ([xs\\nl ,x t\\nl])(7)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl1, σt\\nl1]⊙SelfAttn([ ˆxs\\nl , ˆxt\\nl])\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl2 ([xs\\nl ,x t\\nl])\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl2, σt\\nl2]⊙FFN l(LNl([ˆxs\\nl , ˆxt\\nl]))\\nwhere⊙denotes element-wise multiplication which scales\\nthe corresponding source and target tokens.\\nOur Tok-D transformer block enhances the distinction\\nbetween source and target tokens, as reflected in their dis-\\ntinct feature representations (Figure 6, Section 5.4). This\\nspecialization highlights the superior representational ca-\\npacity of our model. Furthermore, when trained on syn-\\nthetic data (Section 4.2), out-of-distribution artifacts can'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='specialization highlights the superior representational ca-\\npacity of our model. Furthermore, when trained on syn-\\nthetic data (Section 4.2), out-of-distribution artifacts can\\nintroduce quality disparities between source and target to-\\nkens. By leveraging its token-aware architecture, our model\\ndemonstrates greater robustness to these artifacts, resulting\\nin improved performance, as shown in Section 5.3.\\n4.2. Synthetic Data Generation & Training Scheme\\nTraining a naive transformer model with synthetic data can\\nlead to degraded performance rather than improvement due\\nto two key factors: (1) The model struggles to distinguish\\nbetween tokens from source images and target images, al-\\nlowing artifacts from one to propagate into the other dur-\\ning alignment. (2) The model is trained to generate novel\\nviews from sparse input views, and if the target is a syn-\\nthetic image with artifacts, it may learn a distribution bi-\\nased toward unrealistic images. While these issues might'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='views from sparse input views, and if the target is a syn-\\nthetic image with artifacts, it may learn a distribution bi-\\nased toward unrealistic images. While these issues might\\nnot arise with perfect synthetic data, in-practice synthetic\\ndatasets often contain noise, making the model vulnerable\\nto errors through either mechanism. However, for image-to-\\nmultiview synthesis models like CAT3D, we propose a sim-\\nple yet effective solution: assigning the conditioned image\\nas the target view and the generated views as input views.\\nFormally letI c, Cc denote the input image and camera\\nconditioning used for the multiview diffusion model. We\\nsample additional random spline camera trajectory poses\\nCtgt relative to this particular view, and use the state-of-\\nthe-art multi-view diffusion model CAT3D to generate the\\ntarget viewsI src conditioned on the input conditioning and\\ntarget poses\\nIgen ∼DM(I gen|Cgen, Cc, Ic) (8)\\nHere DM represents inferencing through the state of the art'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='target viewsI src conditioned on the input conditioning and\\ntarget poses\\nIgen ∼DM(I gen|Cgen, Cc, Ic) (8)\\nHere DM represents inferencing through the state of the art\\ndiffusion model, After obtaining the generated views, we\\nsample 2 generated viewsI src\\nIsrc, Csrc ∼I gen, Cgen (9)\\nand their camera poses as the source imagesI src, Csrc\\nand utilize the conditioned image and its camera as the tar-\\ngetI c, Cc. Sampling the source and target images this way\\nforces the transformer to always generate a realistic image,\\nmaking our model robust to artifacts from synthetic data.\\n5. Experiments\\n5.1. Implementation Details\\nTraining detailsWe perform all experiments on 8 H100\\nGPUs. We use the AdamW optimizer withβparameters\\n0.9and0.95, and we use weight decay with a rate of0.05\\nfor all layers except the normalization layers. Moreover, we\\nuse a linear learning rate scheduler with with a peak learn-\\ning rate of2e −4, and a warmup of 2500 iterations. In total,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='for all layers except the normalization layers. Moreover, we\\nuse a linear learning rate scheduler with with a peak learn-\\ning rate of2e −4, and a warmup of 2500 iterations. In total,\\nall experiments have100ktraining iterations. In addition,\\nwe use exponential moving averaging (EMA) with a rate of\\n0.99for stabilizing the training process. Although previous\\nworks required gradient clipping for a stable training pro-\\ncess, our training processes were smooth without a need for\\nan explicit gradient clipping.\\nTraining and Evaluation DatasetsFor scene-level synthe-\\nsis model training, we use Re10K [49], ACID [25] and\\nDL3DV [24] with their originally released train and test\\nsplits. We also perform an experiment where the model\\nis trained together with a mix of all of these datasets. For\\nscene-level synthesis, we follow LVSM and train using 2\\ninput views and test using 6 target views fed one at a time.\\nFor DL3DV dataset evaluation, we choose the farthest cam-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='scene-level synthesis, we follow LVSM and train using 2\\ninput views and test using 6 target views fed one at a time.\\nFor DL3DV dataset evaluation, we choose the farthest cam-\\nera from a randomly selected target view as the input view.\\nThe training and evaluation of DL3DV dataset for in dis-\\ntribution metrics is done using 2 input views and 2 target\\nviews. For cross dataset testing, we use 2 input views and 6\\ntarget views for DL3DV dataset. We use a batch size of 64\\nfor our experiments.\\nSynthetic DataFor generating the synthetic data we use the\\nstate-of-the-art 3D generation model CAT3D. CAT3D was\\ntrained using a single scene dataset Re10K and three object-\\nbased datasets: Objaverse [7], MVImgNet [46] and Co3D\\n[32]. To create synthetic data, we use two variants: one with\\n1 conditioning view and 7 generated views, and another\\nwith 3 conditioning views and 5 generated views. We match\\nthe focal lengths of Re10K and DL3DV during generation.'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='1 conditioning view and 7 generated views, and another\\nwith 3 conditioning views and 5 generated views. We match\\nthe focal lengths of Re10K and DL3DV during generation.\\nFor the camera trajectory, we sample a random spline tra-\\njectory with a random position rotation matrix, converting it\\ninto ray maps before passing it into the network. As CAT3D\\nis originally trained with a resolution of 512, we convert the\\nimages and camera parameters to a resolution of256before\\npassing them through our network.\\n5'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Input Views LVSM Ours GT\\nFigure 4.Qualitative results on in-distribution datasets.We illustrate the cases Tok-D transformer works better than LVSM. We notice\\nthat we obtain substantial improvement in cases where the novel views needs to reconstruct regions present only in one of the views as\\nshown in the highlighted regions in the images. The results presented here are taken from our in-distribution trained model. We present\\ntwo diffrent views to show that this problem is persistent across views.\\nTable 1.Quantitative comparisons for in-distribution scene synthesis at 256 resolution.LVSM and our method are trained with a\\nbatch size of 64. LVSM results are taken from the original paper rather than our re-implementation. Our method outperforms the previous\\nSOTA method across all exisiting datasets. ( , , ) denotes the first, second and third best results.\\nMethod Venue RealEstate10k [49] ACID [25] DL3DV [24]\\nPSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Method Venue RealEstate10k [49] ACID [25] DL3DV [24]\\nPSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nGPNR [39] CVPR’23 24.11 0.793 0.255 25.28 0.764 0.332 - - -\\nPixelSplat [4] CVPR’24 25.89 0.858 0.142 28.14 0.839 0.533 - - -\\nMVSplat [6] ECCV’25 26.39 0.869 0.128 28.25 0.843 0.144 17.54 0.529 0.402\\nDepthSplat [44] CVPR’25 27.44 0.887 0.119 - - - 19.05 0.610 0.313\\nLVSM [19] ICLR’25 28.89 0.894 0.108 29.19 0.836 0.095 19.91 0.600 0.273\\nOurs 30.02 0.919 0.058 29.47 0.846 0.086 21.55 0.643 0.208\\n5.2. Scene Synthesis\\nWe evaluate our method qualitatively and quantitatively\\nfor scene synthesis using very recent feed-forward meth-\\nods GPNR, PixelSplat, MVSplat, DepthSplat and LVSM.\\nThese methods were chosen because they outperform con-\\nventional approaches in 2-view reconstruction. Quantita-\\ntive results are shown in Table 1. We observe that Tok-D-\\nPlus outperforms LVSM by 1.2 dB on the Re10K evaluation\\nbenchmark when both models are trained with 8 GPUs. Fur-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tive results are shown in Table 1. We observe that Tok-D-\\nPlus outperforms LVSM by 1.2 dB on the Re10K evaluation\\nbenchmark when both models are trained with 8 GPUs. Fur-\\nthermore, despite using only 8 GPUs, our method still sur-\\npasses LVSM trained with 64 GPUs by a margin of 0.2 dB.\\nMoreover we obtain an improvement of 1.6dB over LVSM\\nin a more diverse scene-level dataset, DL3DV [24] dataset\\nas well. We also observe that our performance improvement\\nis0.2in ACID dataset. We emphasize that this happens be-\\ncause ACID has a relatively smaller training and testing set\\nand the dataset is generally clean and easier to reconstruct.\\nWe also provide the corresponding qualitative comparisons\\non Re10K and DL3DV dataset in Figure 4 . Comparing the\\nmain results we find that our method usually outperforms\\nLVSM when the generated content is only visible in one of\\nthe source views. When the camera is far from both views\\nand the information is present only in one of the views, our'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='LVSM when the generated content is only visible in one of\\nthe source views. When the camera is far from both views\\nand the information is present only in one of the views, our\\nmethod is still able to extract the relevant content from the\\ncorresponding input image. As can be seen from rows 1\\nand 2, the reconstruction form LVSM fails to reconstruct\\nobjects present in only one of the views, whereas Tok-D\\ntransformer can effectively reconstruct these regions.\\n5.3. Cross-Dataset Scene Synthesis\\nTo analyze the generalization capacity of our method, we\\nevaluate our method trained with Re10K dataset on two dif-\\nferent datasets: ACID and DL3DV [24]. ACID is a dataset\\nwith aerial views similar to Re10K. DL3DV [24] is a di-\\nverse dataset comprising natural scenes and various indoor\\nand outdoor settings. The scene geometry and appearance\\nof DL3DV [24] is very different from Re10k. We test the\\nRe10K and ACID datasets at a resolution of 256×265. For'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='and outdoor settings. The scene geometry and appearance\\nof DL3DV [24] is very different from Re10k. We test the\\nRe10K and ACID datasets at a resolution of 256×265. For\\ntesting on DL3DV [24], we choose a resolution of 256×448\\nto maintain the original aspect ratio in the DL3DV [24]\\ndataset and well as maintain consistent evaluation settings\\nwith DepthSplat. We choose 2 source views and 6 tar-\\nget views for all of these datasets. Looking closely at the\\nquantitative results on Table 1 and Table 2, we find that the\\nmodel trained on Re10K underperformed the in-distribution\\ntrained model by a small margin. The drop is higher in the\\ncase of DL3DV due to resolution and diversity differences\\nin the datasets. Next we add a small portion of synthetic\\n6'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='LVSM Ours GTInput\\nFigure 5.Out-of-distribution Evaluation:We evaluate our the version of our method fine-tuned on synthetic data and LVSM on DL3DV\\nand ACID (i.e. out-of-distribution datasets). We also evaluate the model with resolutions that were not used during training. We notice that\\nLVSM’s visual quality degrades when substantial camera motion reveals previously-occluded regions.\\nTable 2.Quantitative comparisons for scaling up with synthetic data.We evaluate LVSM and our method, which are both trained with\\na batch size of 64. A mixture of synthesized DL3DV and Re10K data is used for the synthetic tab. For MVSplat and DepthSplat we include\\nthe numbers reported in their papers\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K[49] Synthetic PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nMVSplat [6] ✓ 26.39 0.869 0.128 28.15 0.147 0.841 17.72 0.534 0.371\\nDepthsplat [44] ✓ 27.44 0.887 0.119 - - - 18.90 0.640 0.317'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='MVSplat [6] ✓ 26.39 0.869 0.128 28.15 0.147 0.841 17.72 0.534 0.371\\nDepthsplat [44] ✓ 27.44 0.887 0.119 - - - 18.90 0.640 0.317\\nLVSM [19] ✓ 28.89 0.894 0.108 28.29 0.809 0.104 20.52 0.621 0.223\\nLVSM [19] ✓ ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nOurs ✓ 30.02 0.910 0.058 29.31 0.838 0.091 21.18 0.652 0.205\\nOurs ✓ ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\ndata comprising about half the size of Re10K dataset and\\nperform training with the new framework. We also retrain\\nLVSM for the same setting. We find thatLVSM’s perfor-\\nmance drops rather than improving when synthetic data is\\nadded. We emphasize that this arises due to the introduc-\\ntion of artifacts during feature alignment. In contrast, we\\nobserve an improvement in quality on our method when a\\nsmall amount of synthetic data is added.\\n5.4. Analysis and Discussion\\nVisualization of source and target features.To visually\\nillustrate the representation alignment problem mentioned'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='small amount of synthetic data is added.\\n5.4. Analysis and Discussion\\nVisualization of source and target features.To visually\\nillustrate the representation alignment problem mentioned\\nin the previous sections, we visualize the 3 channel PCA\\nof each transformer block output after unpatchifying for all\\n24 layers of LVSM and our method in Figure 6. The first\\nrow shows the first 6 layer outputs, second row shows layer\\n6-12, and so on. We can see that for a particular scene the\\nsource and target layer tokens are aligned at all layers even\\nthough the training objective is to reconstruct the target.\\nThis causes inefficient usage of the transformer parameters\\nto maintain the source information throughout the layers.\\nMoreover this also makes the model prone tonoise in the\\nsource data. However, with our Tok-D transformer there is\\nno alignment and the source information is infused much\\nearlier, leaving more room for the transformer blocks to re-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='source data. However, with our Tok-D transformer there is\\nno alignment and the source information is infused much\\nearlier, leaving more room for the transformer blocks to re-\\nconstruct the target. Another important observation is that\\nalthough both source image and Pl¨ucker coordinates are fed\\nas input to the source, the source tokens look similar to the\\nPl¨ucker coordinates. Whereas in our case the image compo-\\nnents in the source PCA components leading to much more\\neffective information extraction from each source token.\\nImpact of additional real data.Incorporating synthetic\\ndata into the training process facilitates the introduction of\\ndiverse scenes and camera motion, enhancing model gener-\\nalizability. While the proposed Tok-D transformer demon-\\n7'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='(a)\\nTarget\\n (b)\\nSource\\n (c) LVSM Target PCA\\n (d) LVSM Source PCA\\n (e) Ours Source PCA\\n (f) Ours Target PCA\\nFigure 6.A visualization of the principal components of transformer layer outputs for source and target of LVSM. The 24 images\\nin each subfigure show the layer output of each layer of the transformer. LVSM features for source and target images looks similar even\\nthough the source is conditioned with image and Pl ¨ucker coordinates and target is conditioned with Pl ¨ucker coordinates alone. This leads\\nto inefficient transformer usage requiring explicit alignment of source and target features across different layers\\nTable 3.Ablation studies on scaling up with more real data.Although including synthetic data in training is helpful for improving\\nquality, including additional real data significantly improves reconstruction quality.\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K [49]+Synthetic DL3DV [24]PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Method Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K [49]+Synthetic DL3DV [24]PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nLVSM [19] ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nLVSM [19] ✓ ✓ 28.10 0.892 0.073 28.79 0.826 0.096 21.37 0.665 0.196\\nOurs ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\nOurs ✓ ✓ 29.78 0.917 0.0604 30.13 0.857 0.082 23.14 0.726 0.156\\nTable 4.Ablation analysisWe analyze the performance improve-\\nment of our design choices.PreandPostdemonstrate the effects\\nof including or not including pre/post-modulation.\\nPre Post Whole Attn MLP PSNR↑ SSIM↑ LPIPS↓\\n28.50 0.893 0.070\\n✓ ✓ 29.69 0.911 0.063\\n✓ ✓ ✓ 28.51 0.894 0.070\\n✓ ✓ ✓ ✓ 30.02 0.918 0.058\\nstrates reduced sensitivity to synthetic data artifacts and in-\\ncreased generative diversity, its photorealistic reconstruc-\\ntion performance remains comparable to the baseline model\\ntrained solely on real data. To investigate the impact of'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='creased generative diversity, its photorealistic reconstruc-\\ntion performance remains comparable to the baseline model\\ntrained solely on real data. To investigate the impact of\\naugmenting the training dataset with additional real data,\\nwe integrated the DL3DV dataset into the existing exper-\\nimental setup. This modification resulted in a significant\\nimprovement in photorealistic reconstruction, as evidenced\\nby a substantial increase in PSNR on the ACID dataset. Fur-\\nthermore, the relative performance gains observed with our\\nmodel, compared to LVSM, were considerably greater, sug-\\ngesting a reduced susceptibility to noise.\\n5.5. Ablation Studies\\nWe analyze the impact of various design choices in the net-\\nwork. Specifically, we examine three aspects: (1) The effect\\nof modulation in different parts of the network, (2) The role\\nof EMA in performance, (3) Number of input views.\\nImpact of modulation at different locations of Tok-D\\ntransformer.We examine the effect of modulating differ-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='of EMA in performance, (3) Number of input views.\\nImpact of modulation at different locations of Tok-D\\ntransformer.We examine the effect of modulating differ-\\nent parts of the network. For this, we consider four differ-\\nent cases. We present the corresponding results in Table 4.\\nHaving a common modulation premodulation worked better\\nthan separate premodulation for both layers.\\nImpact of EMA.We also observe that performing Expo-\\nnential moving average (EMA) [13] during training results\\nin a performance boost for the base model. For the sake of\\nTable 5.Effect of EMA on runtime performance and quality.\\nComparison performed on Re10k.\\nMethod TrainRenderGFLOPs No EMA With EMA(ms) (ms) PSNR SSIM LPIPSPSNR SSIM LPIPS\\nLVSM-1024706.1171.6 2896.8827.68 0.88 0.07728.65 0.90 0.070Ours 734.6174.4 2900.7828.75 0.90 0.06430.02 0.92 0.058\\nTable 6.Effect of adding more source views. Our method works\\nwell as additional source views are introduced.\\nMethod 2 views 4 views 8 views'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Table 6.Effect of adding more source views. Our method works\\nwell as additional source views are introduced.\\nMethod 2 views 4 views 8 views\\nPSNR SSIM LPIPSPSNR SSIM LPIPSPSNR SSIM LPIPS\\nOurs 30.02 0.92 0.058 31.51 0.94 0.048 33.09 0.94 0.042\\nconsistency, we show the results of our model and our re-\\nimplementation of LVSM with 1024 channels trained with\\nand without EMA in Table 5.\\nImpact of number of source frames.Our model scales\\nwith the number of input views and results in better re-\\nconstruction quality when more input views are fed to the\\nmodel to the model as presented in Table 6.\\n6. Conclusion\\nIn this paper, we introduce a new approach to scaling up\\nNVS by addressing two key limitations in existing mod-\\nels: efficiency and diversity. To enhance the efficiency\\nof transformer-based NVS models, we propose the Token-\\nDisentangled (Tok-D) Transformer, which reduces redun-\\ndancies and improves data efficiency, enabling higher re-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='of transformer-based NVS models, we propose the Token-\\nDisentangled (Tok-D) Transformer, which reduces redun-\\ndancies and improves data efficiency, enabling higher re-\\nconstruction quality with less compute. Additionally, the\\nTok-D Transformer mitigates training artifacts through its\\ndisentangling property, allowing for effective scaling us-\\ning synthetic data. Incorporating synthetic data into train-\\ning significantly improves cross-dataset performance com-\\npared to existing models. By integrating the Tok-D Trans-\\nformer and synthetic data, we achieve state-of-the-art re-\\nsults across three large-scale NVS benchmarks, surpassing\\nprevious methods with lower computational cost and by a\\nsubstantial margin.\\n8'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Benjamin Attal, Jia-Bin Huang, Michael Zollh ¨ofer, Johannes\\nKopf, and Changil Kim. Learning neural light fields with\\nray-space embedding. InProceedings of the IEEE/CVF Con-\\nference on Computer Vision and Pattern Recognition, pages\\n19819–19829, 2022. 2\\n[2] Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased\\ngrid-based neural radiance fields. InProceedings of the\\nIEEE/CVF International Conference on Computer Vision,\\npages 19697–19705, 2023. 2\\n[3] Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P.\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased grid-\\nbased neural radiance fields.ICCV, 2023. 3\\n[4] David Charatan, Sizhe Lester Li, Andrea Tagliasacchi, and\\nVincent Sitzmann. pixelsplat: 3d gaussian splats from image\\npairs for scalable generalizable 3d reconstruction. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 19457–19467, 2024. 2, 3, 6'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='pairs for scalable generalizable 3d reconstruction. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 19457–19467, 2024. 2, 3, 6\\n[5] Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and\\nHao Su. Tensorf: Tensorial radiance fields. InEuropean\\nConference on Computer Vision (ECCV), 2022. 2, 3\\n[6] Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang,\\nMarc Pollefeys, Andreas Geiger, Tat-Jen Cham, and Jianfei\\nCai. Mvsplat: Efficient 3d gaussian splatting from sparse\\nmulti-view images. InEuropean Conference on Computer\\nVision, pages 370–386. Springer, 2024. 6, 7\\n[7] Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs,\\nOscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana\\nEhsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse:\\nA universe of annotated 3d objects. InProceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 13142–13153, 2023. 5\\n[8] John Flynn, Michael Broxton, Lukas Murmann, Lucy Chai,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 13142–13153, 2023. 5\\n[8] John Flynn, Michael Broxton, Lukas Murmann, Lucy Chai,\\nMatthew DuVall, Cl ´ement Godard, Kathryn Heal, Srinivas\\nKaza, Stephen Lombardi, Xuan Luo, et al. Quark: Real-time,\\nhigh-resolution, and general neural view synthesis.ACM\\nTransactions on Graphics (TOG), 43(6):1–20, 2024. 3\\n[9] Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong\\nChen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels:\\nRadiance fields without neural networks. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 5501–5510, 2022. 3\\n[10] Ruiqi Gao, Aleksander Holynski, Philipp Henzler, Arthur\\nBrussee, Ricardo Martin Brualla, Pratul Srinivasan, Jonathan\\nBarron, and Ben Poole. Cat3d: Create anything in 3d with\\nmulti-view diffusion models.Advances in Neural Informa-\\ntion Processing Systems, 37:75468–75494, 2024. 2, 4\\n[11] Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='multi-view diffusion models.Advances in Neural Informa-\\ntion Processing Systems, 37:75468–75494, 2024. 2, 4\\n[11] Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and\\nMichael F. Cohen. The lumigraph. InProceedings of the\\n23rd Annual Conference on Computer Graphics and Inter-\\nactive Techniques, page 43–54, New York, NY , USA, 1996.\\nAssociation for Computing Machinery. 2\\n[12] Albert Gu and Tri Dao. Mamba: Linear-time sequence mod-\\neling with selective state spaces, 2024. 12\\n[13] David Haynes, Steven Corns, and Ganesh Kumar Venayag-\\namoorthy. An exponential moving average algorithm. In\\n2012 IEEE Congress on Evolutionary Computation, pages\\n1–8. IEEE, 2012. 8\\n[14] Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and\\nQifeng Chen. Latent video diffusion models for high-fidelity\\nlong video generation.arXiv preprint arXiv:2211.13221,\\n2022. 2\\n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-\\nfusion probabilistic models.Advances in neural information'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='long video generation.arXiv preprint arXiv:2211.13221,\\n2022. 2\\n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-\\nfusion probabilistic models.Advances in neural information\\nprocessing systems, 33:6840–6851, 2020. 2\\n[16] Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou,\\nDifan Liu, Feng Liu, Kalyan Sunkavalli, Trung Bui, and Hao\\nTan. LRM: Large reconstruction model for single image to\\n3d. InThe Twelfth International Conference on Learning\\nRepresentations, 2024. 2, 3\\n[17] Binbin Huang, Zehao Yu, Anpei Chen, Andreas Geiger, and\\nShenghua Gao. 2d gaussian splatting for geometrically accu-\\nrate radiance fields. InSpecial Interest Group on Computer\\nGraphics and Interactive Techniques Conference Conference\\nPapers, page 1–11. ACM, 2024. 3\\n[18] Hanwen Jiang, Zexiang Xu, Desai Xie, Ziwen Chen, Haian\\nJin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Ji-\\nuxiang Gu, Qixing Huang, Georgios Pavlakos, and Hao Tan.\\nMegasynth: Scaling up 3d scene reconstruction with syn-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Jin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Ji-\\nuxiang Gu, Qixing Huang, Georgios Pavlakos, and Hao Tan.\\nMegasynth: Scaling up 3d scene reconstruction with syn-\\nthesized data. InProceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition (CVPR), pages\\n16441–16452, 2025. 3\\n[19] Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi,\\nTianyuan Zhang, Fujun Luan, Noah Snavely, and Zexiang\\nXu. LVSM: A large view synthesis model with minimal 3d\\ninductive bias. InThe Thirteenth International Conference\\non Learning Representations, 2025. 2, 3, 6, 7, 8\\n[20] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk ¨uhler,\\nand George Drettakis. 3d gaussian splatting for real-time\\nradiance field rendering.ACM Trans. Graph., 42(4):139–1,\\n2023. 2, 3\\n[21] Shakiba Kheradmand, Delio Vicini, George Kopanas,\\nDmitry Lagun, Kwang Moo Yi, Mark Matthews, and An-\\ndrea Tagliasacchi. Stochasticsplats: Stochastic rasterization\\nfor sorting-free 3d gaussian splatting, 2025. 3'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Dmitry Lagun, Kwang Moo Yi, Mark Matthews, and An-\\ndrea Tagliasacchi. Stochasticsplats: Stochastic rasterization\\nfor sorting-free 3d gaussian splatting, 2025. 3\\n[22] Diederik P Kingma, Max Welling, et al. Auto-encoding vari-\\national bayes, 2013. 3\\n[23] Marc Levoy and Pat Hanrahan. Light field rendering. In\\nProceedings of the 23rd Annual Conference on Computer\\nGraphics and Interactive Techniques, page 31–42, New\\nYork, NY , USA, 1996. Association for Computing Machin-\\nery. 2\\n[24] Lu Ling, Yichen Sheng, Zhi Tu, Wentian Zhao, Cheng Xin,\\nKun Wan, Lantao Yu, Qianyu Guo, Zixun Yu, Yawen Lu,\\net al. Dl3dv-10k: A large-scale scene dataset for deep\\nlearning-based 3d vision. InProceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition,\\npages 22160–22169, 2024. 2, 5, 6, 7, 8\\n[25] Andrew Liu, Richard Tucker, Varun Jampani, Ameesh\\nMakadia, Noah Snavely, and Angjoo Kanazawa. Infinite na-\\nture: Perpetual view generation of natural scenes from a sin-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[25] Andrew Liu, Richard Tucker, Varun Jampani, Ameesh\\nMakadia, Noah Snavely, and Angjoo Kanazawa. Infinite na-\\nture: Perpetual view generation of natural scenes from a sin-\\ngle image. InProceedings of the IEEE/CVF International\\nConference on Computer Vision, pages 14458–14467, 2021.\\n2, 5, 6, 7, 8\\n9'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[26] Lingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, and\\nChristian Theobalt. Neural sparse voxel fields.Advances\\nin Neural Information Processing Systems, 33:15651–15663,\\n2020. 2, 3\\n[27] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,\\nJonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:\\nRepresenting scenes as neural radiance fields for view syn-\\nthesis. InEuropean conference on computer vision, 2020. 2,\\n3\\n[28] Thomas M ¨uller, Alex Evans, Christoph Schied, and Alexan-\\nder Keller. Instant neural graphics primitives with a mul-\\ntiresolution hash encoding.ACM transactions on graphics\\n(TOG), 41(4):1–15, 2022. 2, 3\\n[29] Alexander Quinn Nichol and Prafulla Dhariwal. Improved\\ndenoising diffusion probabilistic models. InInternational\\nconference on machine learning, pages 8162–8171. PMLR,\\n2021. 2\\n[30] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. InProceedings of the IEEE/CVF inter-\\nnational conference on computer vision, pages 4195–4205,\\n2023. 4'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='2021. 2\\n[30] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. InProceedings of the IEEE/CVF inter-\\nnational conference on computer vision, pages 4195–4205,\\n2023. 4\\n[31] Lukas Radl, Michael Steiner, Mathias Parger, Alexan-\\nder Weinrauch, Bernhard Kerbl, and Markus Steinberger.\\nStopThePop: Sorted Gaussian Splatting for View-Consistent\\nReal-time Rendering.ACM Transactions on Graphics, 4\\n(43), 2024. 3\\n[32] Jeremy Reizenstein, Roman Shapovalov, Philipp Henzler,\\nLuca Sbordone, Patrick Labatut, and David Novotny. Com-\\nmon objects in 3d: Large-scale learning and evaluation\\nof real-life 3d category reconstruction. InProceedings of\\nthe IEEE/CVF international conference on computer vision,\\npages 10901–10911, 2021. 5\\n[33] Robin Rombach, Andreas Blattmann, Dominik Lorenz,\\nPatrick Esser, and Bj ¨orn Ommer. High-resolution image\\nsynthesis with latent diffusion models. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Patrick Esser, and Bj ¨orn Ommer. High-resolution image\\nsynthesis with latent diffusion models. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 10684–10695, 2022. 2\\n[34] Chitwan Saharia, William Chan, Saurabh Saxena, Lala\\nLi, Jay Whang, Emily L Denton, Kamyar Ghasemipour,\\nRaphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans,\\net al. Photorealistic text-to-image diffusion models with deep\\nlanguage understanding.Advances in neural information\\nprocessing systems, 35:36479–36494, 2022. 2\\n[35] Mehdi SM Sajjadi, Henning Meyer, Etienne Pot, Urs\\nBergmann, Klaus Greff, Noha Radwan, Suhani V ora, Mario\\nLuˇci´c, Daniel Duckworth, Alexey Dosovitskiy, et al. Scene\\nrepresentation transformer: Geometry-free novel view syn-\\nthesis through set-latent scene representations. InProceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 6229–6238, 2022. 3\\n[36] Yichun Shi, Peng Wang, Jianglong Ye, Long Mai, Kejie Li,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 6229–6238, 2022. 3\\n[36] Yichun Shi, Peng Wang, Jianglong Ye, Long Mai, Kejie Li,\\nand Xiao Yang. MVDream: Multi-view diffusion for 3d gen-\\neration. InThe Twelfth International Conference on Learn-\\ning Representations, 2024. 2\\n[37] Vincent Sitzmann, Semon Rezchikov, Bill Freeman, Josh\\nTenenbaum, and Fredo Durand. Light field networks: Neu-\\nral scene representations with single-evaluation rendering.\\nAdvances in Neural Information Processing Systems, 34:\\n19313–19325, 2021. 2\\n[38] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-\\nhishek Kumar, Stefano Ermon, and Ben Poole. Score-based\\ngenerative modeling through stochastic differential equa-\\ntions. InInternational Conference on Learning Represen-\\ntations, 2021. 2\\n[39] Mohammed Suhail, Carlos Esteves, Leonid Sigal, and\\nAmeesh Makadia. Generalizable patch-based neural render-\\ning. InEuropean Conference on Computer Vision, pages'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tations, 2021. 2\\n[39] Mohammed Suhail, Carlos Esteves, Leonid Sigal, and\\nAmeesh Makadia. Generalizable patch-based neural render-\\ning. InEuropean Conference on Computer Vision, pages\\n156–174. Springer, 2022. 2, 3, 6\\n[40] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku\\nKomura, and Wenping Wang. Neus: Learning neural im-\\nplicit surfaces by volume rendering for multi-view recon-\\nstruction.Advances in Neural Information Processing Sys-\\ntems, 34:27171–27183, 2021. 2\\n[41] Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P\\nSrinivasan, Howard Zhou, Jonathan T Barron, Ricardo\\nMartin-Brualla, Noah Snavely, and Thomas Funkhouser. Ibr-\\nnet: Learning multi-view image-based rendering. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 4690–4699, 2021. 3\\n[42] Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi\\nZheng, Jonathan T Barron, and Aleksander Holynski. Cat4d:\\nCreate anything in 4d with multi-view video diffusion mod-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[42] Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi\\nZheng, Jonathan T Barron, and Aleksander Holynski. Cat4d:\\nCreate anything in 4d with multi-view video diffusion mod-\\nels. InProceedings of the Computer Vision and Pattern\\nRecognition Conference, pages 26057–26068, 2025. 3\\n[43] Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, Zexiang Xu, Yi\\nZhou, Soren Pirk, Arie Kaufman, Xin Sun, and Hao Tan.\\nLRM-zero: Training large reconstruction models with syn-\\nthesized data. InThe Thirty-eighth Annual Conference on\\nNeural Information Processing Systems, 2024. 3\\n[44] Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann\\nBlum, Daniel Barath, Andreas Geiger, and Marc Pollefeys.\\nDepthsplat: Connecting gaussian splatting and depth. InPro-\\nceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR), pages 16453–16463, 2025.\\n2, 6, 7\\n[45] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V ol-\\nume rendering of neural implicit surfaces, 2021. 2'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='and Pattern Recognition (CVPR), pages 16453–16463, 2025.\\n2, 6, 7\\n[45] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V ol-\\nume rendering of neural implicit surfaces, 2021. 2\\n[46] Xianggang Yu, Mutian Xu, Yidan Zhang, Haolin Liu,\\nChongjie Ye, Yushuang Wu, Zizheng Yan, Chenming Zhu,\\nZhangyang Xiong, Tianyou Liang, et al. Mvimgnet: A\\nlarge-scale dataset of multi-view images. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 9150–9161, 2023. 5\\n[47] Kai Zhang, Sai Bi, Hao Tan, Yuanbo Xiangli, Nanxuan Zhao,\\nKalyan Sunkavalli, and Zexiang Xu. Gs-lrm: Large recon-\\nstruction model for 3d gaussian splatting.European Confer-\\nence on Computer Vision, 2024. 3\\n[48] Chaoyi Zhou, Xi Liu, Feng Luo, and Siyu Huang. Latent\\nradiance fields with 3d-aware 2d representations. InThe\\nThirteenth International Conference on Learning Represen-\\ntations, 2025. 3\\n[49] Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='radiance fields with 3d-aware 2d representations. InThe\\nThirteenth International Conference on Learning Represen-\\ntations, 2025. 3\\n[49] Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe,\\nand Noah Snavely. Stereo magnification: learning view syn-\\nthesis using multiplane images.ACM Trans. Graph., 37(4),\\n2018. 2, 5, 6, 7, 8\\n10'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[50] Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang,\\nWenyu Liu, and Xinggang Wang. Vision mamba: Efficient\\nvisual representation learning with bidirectional state space\\nmodel, 2024. 12\\n7. Design choices\\nWe provide further details of the exact transformer model\\nused here.Transformer blocksWe find the claims regard-\\ning the naive transformer architecture to be unstable for im-\\nage generative tasks to be true. We use QK-Norm to stabi-\\nlize the transformer block. We use24transformer blocks\\nwith an embedding dimension of1024. In addition to this,\\ndifferent from LVSM, we use attention biases at all layers\\nand include the bias for the last transformer block, as we\\nfind this design choice particularly stable with linear learn-\\ning rate decay. We use a patch size of 8 for all experiments.\\n7.1. Enhancing 3D generative models for 3D consis-\\ntent generation\\nThe use of diffusion models has been widely explored for\\ngenerating 3D scenes. Multiple works in the literature'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='7.1. Enhancing 3D generative models for 3D consis-\\ntent generation\\nThe use of diffusion models has been widely explored for\\ngenerating 3D scenes. Multiple works in the literature\\nadapt pretrained text-to-image and image-to-video models\\nfor 3D-consistent scene generation. Most of these works\\ncondition the diffusion model on camera parameters and\\nlearn the conditional distribution of multiple views given the\\ncamera poses. Given the ability to cherry-pick and sample\\nthrough the diffusion model multiple times, these models\\nproduce high-quality results. However, existing 3D scene\\ngeneration models cannot mass-produce synthetic data for\\nfine-tuning substream models for high-fidelity generation.\\nUntil now, no generalizable models with high-fidelity re-\\nsults have been proposed that can directly utilize the data\\ngenerated by diffusion models. We argue that this draw-\\nback is caused by a lack of analysis of the inference-time\\ngeneration process of diffusion models. Although extensive'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='generated by diffusion models. We argue that this draw-\\nback is caused by a lack of analysis of the inference-time\\ngeneration process of diffusion models. Although extensive\\nstudies have been performed on different training strategies\\nfor 3D-consistent generation using diffusion models, much\\nless effort has been put into improving inference-time gen-\\neration quality.\\nMost 3D generative models generateNviews of a scene,\\neach of dimension(H×W×C), in parallel to preserve\\n3D consistency. The generation process starts with random\\nisotropic Gaussian noise of dimensionN×H×W×C,\\nwhich undergoes a diffusion process ofTsteps. This either\\nconverts it into a latent representation, which is then de-\\ncoded by a V AE decoder to produce multiview images, or\\ngenerates images directly. These multiview images are fur-\\nther used to train a NeRF or a Gaussian Splat model to gen-\\nerate novel views of the scene. When the diffusion model\\ngenerates high-quality, 3D-consistent images, this frame-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ther used to train a NeRF or a Gaussian Splat model to gen-\\nerate novel views of the scene. When the diffusion model\\ngenerates high-quality, 3D-consistent images, this frame-\\nwork works perfectly. However, in reality, diffusion models\\nare sensitive to input noise. Even for the simple case of\\nimage generation, different noise inputs produce different\\nquality results. Recent works have shed light on inference-\\ntime scaling laws for generation, claiming that the quality of\\ndiffusion model outputs can be controlled by selecting the\\ncorrect input noise via rejection sampling. Similar claims\\nhave been made for video generation models, where per-\\nformance improves significantly by refining the input noise\\nschedule.\\nTo understand this, consider a toy example: Suppose we\\nwant to generate an image (I 1) using the diffusion model\\nconditioned on a text prompt. Starting with Gaussian noise\\nN1, if we want to generate another image (I2) close to (I1),'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='want to generate an image (I 1) using the diffusion model\\nconditioned on a text prompt. Starting with Gaussian noise\\nN1, if we want to generate another image (I2) close to (I1),\\nthe desired noise is most likely closer toN1. Previous works\\nhave demonstrated enhanced video generation results by se-\\nlecting starting noises that are close across different frames.\\nIn our case, we use the image-to-multiview variant of\\nCAT3D as the base model for generating multiview images.\\nFor choosing the initial noise, we follow a specific heuris-\\ntic. Specifically, we ensure that the noise across different\\nviews remains 3D-consistent. CAT3D is a multiview diffu-\\nsion model that generates eight views simultaneously, con-\\nditioned on the camera poses. CAT3D allows conditioning\\non a particular view to generate the remaining views. Given\\nthe view to be conditioned, we select a random noise for\\nthis view, denoted asV 1, with its noise represented asN 1'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='on a particular view to generate the remaining views. Given\\nthe view to be conditioned, we select a random noise for\\nthis view, denoted asV 1, with its noise represented asN 1\\nand the corresponding rotation-translation matrices denoted\\nasR 1, t1. To estimate the starting noise for other views, we\\nperform a warping operation onN 1, denoted by:\\nNi =warp(N 1, inv([Ri, ti])[R1, t1]) (10)\\nwhere the warp operation transforms the coordinates of\\nN1 toN i. However, we noticed that such a warping op-\\neration fails in regions outside the scene. To handle these\\ncases while enhancing consistency, we marginally modify\\nthe noise. Specifically, for these cases, we assign the noise\\nas:\\nN2 =αN 1 + (1−α)N(0, I) (11)\\nThus, our effective starting noise is defined as:\\nNfinal =\\n(\\nN1,overlapping regions\\nN2,non overlapping regions\\nWe perform the effective noising operation parallely with\\nrespect to the reference view. First we take view 1, warp to\\nview 2. then add noise, then we Although we use CAT3D,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='We perform the effective noising operation parallely with\\nrespect to the reference view. First we take view 1, warp to\\nview 2. then add noise, then we Although we use CAT3D,\\nour method is generalizable across any 3D scene generation\\nmodel.\\nUnderstanding the value that synthetic data from gen-\\nerative models can bring, we propose a method to en-\\nhance diffusion-based 3D generative models to produce\\nhigh-quality, 3D-consistent results.\\n11'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='7.2. Loss functions\\nSimilar to LVSM, we utilize Mean Square Error (MSE) loss\\nfor training our network. Instead of using Perceptual Loss,\\nwe utilize LPIPS loss for training. Given the ground-truth\\ntarget view of dimension ˆI∈R H×W×C and the recon-\\nstructed target viewI, the effective objective function used\\nfor optimization is defined as:\\nL=MSE(I, ˆI) +λ·LP IP S(I,ˆI) (12)\\nwhereλis a scaling factor set to0.5for all experiments.\\n7.3. Emergent Properties\\nOne surprisingemergent propertyof our newly proposed\\ntransformer block is its ability to disentangle the source\\nand target tokens, which allows it to scale better for syn-\\nthetic data compared to a naive transformer block. We\\npresent these results in Figure X, where we observe sig-\\nnificant improvements. We hypothesize that this emergent\\nproperty arises because synthetic data is generally prone to\\nartifacts and out-of-distribution noise. When transformer\\nblocks cannot distinguish between source and target tokens,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='property arises because synthetic data is generally prone to\\nartifacts and out-of-distribution noise. When transformer\\nblocks cannot distinguish between source and target tokens,\\nthe model learns using both real and synthetic data, leading\\nto reconstructions that inherit these artifacts. However, in\\nour case, only the relevant information from clean images\\nis used for backpropagation, allowing the model to utilize\\nuseful context from synthetic data while discarding artifacts\\nduring token fusion for target view generation.\\n8. Limitations\\nOur model struggles when regions occluded in the source\\nimages become visible in the target view. As shown in Fig-\\nure 17, when a new object enters the scene, the model hallu-\\ncinates the affected region. We argue that this phenomenon\\nis inherently ill-posed and lacks a definitive solution. Ad-\\nditionally, the model uses a token size of 8 for all blocks,\\nresulting in 1024 tokens per source image, which demands'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='is inherently ill-posed and lacks a definitive solution. Ad-\\nditionally, the model uses a token size of 8 for all blocks,\\nresulting in 1024 tokens per source image, which demands\\nsignificant memory. We leave further architectural opti-\\nmizations, such as hierarchical transformers and more ef-\\nficient networks like linear attention and state-space models\\n(e.g., Mamba [12], [50]), for future work.\\n9. Failure cases of our method\\nWe notice that our method contains two main failure modes\\n(1) when an new object comes into the view in between the\\nconditioned frames. (2) When too many shiny artifacts are\\npresent in the image\\n12'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 7.Figure illustrating results from DL3DV dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n13'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 8.Figure illustrating results from Re10k dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n14'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 9.Figure illustrating results from ACID dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n15'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 10.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 11.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n16'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 12.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 13.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n17'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 14.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 15.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and\\n18'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 16.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 17.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n19'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 18.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 19.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n20'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 20.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 21.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene moreover, our method also fails to reconstruct properly when there are some shiny obejcts in the scene. Figure ordering is OURS,\\nGT, DIFF\\n21')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=split_documents(all_pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1e5685",
   "metadata": {},
   "source": [
    "### embeddings and vectorStoreDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed0d133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Machine Learning\\LLM\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630fe3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the embedding model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Enbedding Dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x195fe45fe00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handles Document Embedding generation using SentenceTransformers\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): HuggingFace model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "\n",
    "    def _load_model(self):\n",
    "        \"\"\"\"Load the SentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading the embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Enbedding Dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Generate embeddings for a list of texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings with shape (len(texts), embedding_dim)\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded.\")\n",
    "        \n",
    "        print(f\"Generating embedding for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generate embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    \n",
    "    # def get_embedding_dimension(self) -> int:\n",
    "    #     \"\"\"Get the embedding dimension of the model\"\"\"\n",
    "    #     if not self.model:\n",
    "    #         raise ValueError(\"Model not loaded.\")\n",
    "    #     return self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "\n",
    "## initialize embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1271621",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ddf024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing document in collection: 1134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1959e48fe00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embedding in ChromaDB vector store\"\"\"\n",
    "\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection_name: Name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize ChromDB client and collection\"\"\"\n",
    "        try:\n",
    "            # Create persistant ChromaDB client\n",
    "            os.makedirs(self.persist_directory,exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embedding for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing document in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add document and their emebedding to vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of LangChain Documents\n",
    "            embeddings: Corresponding embeddings for the document\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents to vector store...\")\n",
    "\n",
    "        # Prepare data for ChromaDB\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique ID\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            # Prepare Metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        # Add to collection\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to the vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore = VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9312530d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗ †\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗ ‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='mechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='best models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='1 Introduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='sequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='In this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Here, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks\\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder: The decoder is also composed of a stack of N = 6identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 2, 'page_label': '3', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Scaled Dot-Product Attention\\n Multi-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1 Scaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='into a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V) = softmax(QKT\\n√dk\\n)V (1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof 1√dk\\n. Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 3, 'page_label': '4', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='dot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1√dk\\n.\\n3.2.2 Multi-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V) = Concat(head1, ...,headh)WO\\nwhere headi = Attention(QWQ\\ni , KWK\\ni , V WV\\ni )\\nWhere the projections are parameter matricesWQ\\ni ∈ Rdmodel×dk , WK\\ni ∈ Rdmodel×dk , WV\\ni ∈ Rdmodel×dv\\nand WO ∈ Rhdv×dmodel .\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='The Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='encoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3 Position-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 4, 'page_label': '5', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='FFN(x) = max(0, xW1 + b1)W2 + b2 (2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4 Embeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type Complexity per Layer Sequential Maximum Path Length\\nOperations\\nSelf-Attention O(n2 · d) O(1) O(1)\\nRecurrent O(n · d2) O(n) O(n)\\nConvolutional O(k · n · d2) O(1) O(logk(n))\\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\\n3.5 Positional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nP E(pos,2i) = sin(pos/100002i/dmodel )\\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\\nP Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='P Epos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4 Why Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='One is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 5, 'page_label': '6', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='length n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < ndoes not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='or O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [ 6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='and semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2 Hardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 6, 'page_label': '7', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3 Optimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4 Regularization\\nWe employ three types of regularization during training:\\n7'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU Training Cost (FLOPs)\\nEN-DE EN-FR EN-DE EN-FR\\nByteNet [18] 23.75\\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\\nTransformer (base model) 27.3 38.1 3.3 · 1018\\nTransformer (big) 28.4 41.8 2.3 · 1019\\nResidual Dropout We apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6 Results\\n6.1 Machine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='the competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 7, 'page_label': '8', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='inference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2 Model Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN d model dff h d k dv Pdrop ϵls\\ntrain PPL BLEU params\\nsteps (dev) (dev) ×106\\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\\n(A)\\n1 512 512 5.29 24.9\\n4 128 128 5.00 25.5\\n16 32 32 4.91 25.8\\n32 16 16 5.01 25.4\\n(B) 16 5.16 25.1 58\\n32 5.01 25.4 60\\n(C)\\n2 6.11 23.7 36\\n4 5.19 25.3 50\\n8 4.88 25.5 80\\n256 32 32 5.75 24.5 28\\n1024 128 128 4.66 26.0 168\\n1024 5.12 25.4 53\\n4096 4.75 26.2 90\\n(D)\\n0.0 5.77 24.6\\n0.2 4.95 25.5\\n0.0 4.67 25.3\\n0.2 5.47 25.7\\n(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='(E) positional embedding instead of sinusoids 4.92 25.7\\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3 English Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 8, 'page_label': '9', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Table 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser Training WSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\\nTransformer (4 layers) WSJ only, discriminative 91.3\\nZhu et al. (2013) [40] semi-supervised 91.3\\nHuang & Harper (2009) [14] semi-supervised 91.3\\nMcClosky et al. (2006) [26] semi-supervised 92.1\\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\\nTransformer (4 layers) semi-supervised 92.7\\nLuong et al. (2015) [23] multi-task 93.0\\nDyer et al. (2016) [8] generative 93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='for both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7 Conclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 9, 'page_label': '10', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='comments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V . Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='across languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time.arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 10, 'page_label': '11', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='and interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='nov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 11, 'page_label': '12', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 12, 'page_label': '13', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf', 'total_pages': 15, 'page': 14, 'page_label': '15', 'source_file': 'attention-is-all-you-need.pdf', 'file_type': 'pdf'}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Ray: A Distributed Framework for Emerging AI Applications\\nPhilipp Moritz∗, Robert Nishihara ∗, Stephanie Wang, Alexey Tumanov, Richard Liaw,\\nEric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, Ion Stoica\\nUniversity of California, Berkeley\\nAbstract\\nThe next generation of AI applications will continuously\\ninteract with the environment and learn from these inter-\\nactions. These applications impose new and demanding\\nsystems requirements, both in terms of performance and\\nﬂexibility. In this paper, we consider these requirements\\nand present Ray—a distributed system to address them.\\nRay implements a uniﬁed interface that can express both\\ntask-parallel and actor-based computations, supported by\\na single dynamic execution engine. To meet the perfor-\\nmance requirements, Ray employs a distributed scheduler\\nand a distributed and fault-tolerant store to manage the\\nsystem’s control state. In our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='and a distributed and fault-tolerant store to manage the\\nsystem’s control state. In our experiments, we demon-\\nstrate scaling beyond 1.8 million tasks per second and\\nbetter performance than existing specialized systems for\\nseveral challenging reinforcement learning applications.\\n1 Introduction\\nOver the past two decades, many organizations have been\\ncollecting—and aiming to exploit—ever-growing quanti-\\nties of data. This has led to the development of a plethora\\nof frameworks for distributed data analysis, including\\nbatch [20, 64, 28], streaming [15, 39, 31], and graph [34,\\n35, 24] processing systems. The success of these frame-\\nworks has made it possible for organizations to analyze\\nlarge data sets as a core part of their business or scientiﬁc\\nstrategy, and has ushered in the age of “Big Data. ”\\nMore recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (AI) or machine learning (ML) techniques [30].'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='More recently, the scope of data-focused applications\\nhas expanded to encompass more complex artiﬁcial intel-\\nligence (AI) or machine learning (ML) techniques [30].\\nThe paradigm case is that of supervised learning, where\\ndata points are accompanied by labels, and where the\\nworkhorse technology for mapping data points to labels\\nis provided by deep neural networks. The complexity of\\nthese deep networks has led to another ﬂurry of frame-\\nworks that focus on the training of deep neural networks\\n∗equal contribution\\nand their use in prediction. These frameworks often lever-\\nage specialized hardware (e.g., GPUs and TPUs), with the\\ngoal of reducing training time in a batch setting. Examples\\ninclude TensorFlow [7], MXNet [18], and PyTorch [46].\\nThe promise of AI is, however, far broader than classi-\\ncal supervised learning. Emerging AI applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='cal supervised learning. Emerging AI applications must\\nincreasingly operate in dynamic environments, react to\\nchanges in the environment, and take sequences of ac-\\ntions to accomplish long-term goals [8, 43]. They must\\naim not only to exploit the data gathered, but also to ex-\\nplore the space of possible actions. These broader require-\\nments are naturally framed within the paradigm of rein-\\nforcement learning (RL). RL deals with learning to oper-\\nate continuously within an uncertain environment based\\non delayed and limited feedback [56]. RL-based systems\\nhave already yielded remarkable results, such as Google’s\\nAlphaGo beating a human world champion [54], and are\\nbeginning to ﬁnd their way into dialogue systems, UA Vs\\n[42], and robotic manipulation [25, 60].\\nThe central goal of an RL application is to learn a\\npolicy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. Finding ef-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='policy—a mapping from the state of the environment to a\\nchoice of action—that yields effective performance over\\ntime, e.g., winning a game or piloting a drone. Finding ef-\\nfective policies in large-scale applications requires three\\nmain capabilities. First, RL methods often rely on simula-\\ntion to evaluate policies. Simulations make it possible to\\nexplore many different choices of action sequences and to\\nlearn about the long-term consequences of those choices.\\nSecond, like their supervised learning counterparts, RL al-\\ngorithms need to perform distributed training to improve\\nthe policy based on data generated through simulations or\\ninteractions with the physical environment. Third, poli-\\ncies are intended to provide solutions to control problems,\\nand thus it is necessary to serve the policy in interactive\\nclosed-loop and open-loop control scenarios.\\nThese characteristics drive new systems requirements:\\na system for RL must support ﬁne-grained computations'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='closed-loop and open-loop control scenarios.\\nThese characteristics drive new systems requirements:\\na system for RL must support ﬁne-grained computations\\n(e.g., rendering actions in milliseconds when interacting\\nwith the real world, and performing vast numbers of sim-\\narXiv:1712.05889v2  [cs.DC]  30 Sep 2018'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ulations), must support heterogeneity both in time (e.g.,\\na simulation may take milliseconds or hours) and in re-\\nsource usage (e.g., GPUs for training and CPUs for simu-\\nlations), and must support dynamic execution, as results\\nof simulations or interactions with the environment can\\nchange future computations. Thus, we need a dynamic\\ncomputation framework that handles millions of hetero-\\ngeneous tasks per second at millisecond-level latencies.\\nExisting frameworks that have been developed for\\nBig Data workloads or for supervised learning work-\\nloads fall short of satisfying these new requirements for\\nRL. Bulk-synchronous parallel systems such as Map-\\nReduce [20], Apache Spark [64], and Dryad [28] do not\\nsupport ﬁne-grained simulation or policy serving. Task-\\nparallel systems such as CIEL [40] and Dask [48] provide\\nlittle support for distributed training and serving. The\\nsame is true for streaming systems such as Naiad [ 39]\\nand Storm [31]. Distributed deep-learning frameworks'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='little support for distributed training and serving. The\\nsame is true for streaming systems such as Naiad [ 39]\\nand Storm [31]. Distributed deep-learning frameworks\\nsuch as TensorFlow [7] and MXNet [18] do not naturally\\nsupport simulation and serving. Finally, model-serving\\nsystems such as TensorFlow Serving [6] and Clipper [19]\\nsupport neither training nor simulation.\\nWhile in principle one could develop an end-to-end so-\\nlution by stitching together several existing systems (e.g.,\\nHorovod [53] for distributed training, Clipper [ 19] for\\nserving, and CIEL [40] for simulation), in practice this ap-\\nproach is untenable due to thetight coupling of these com-\\nponents within applications. As a result, researchers and\\npractitioners today build one-off systems for specialized\\nRL applications [58, 41, 54, 44, 49, 5]. This approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='RL applications [58, 41, 54, 44, 49, 5]. This approach im-\\nposes a massive systems engineering burden on the devel-\\nopment of distributed applications by essentially pushing\\nstandard systems challenges like scheduling, fault toler-\\nance, and data movement onto each application.\\nIn this paper, we propose Ray, a general-purpose\\ncluster-computing framework that enables simulation,\\ntraining, and serving for RL applications. The require-\\nments of these workloads range from lightweight and\\nstateless computations, such as for simulation, to long-\\nrunning and stateful computations, such as for training.\\nTo satisfy these requirements, Ray implements a uniﬁed\\ninterface that can express both task-parallel and actor-\\nbased computations. Tasks enable Ray to efﬁciently and\\ndynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. In contrast, actors enable Ray to efﬁciently'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='dynamically load balance simulations, process large in-\\nputs and state spaces (e.g., images, video), and recover\\nfrom failures. In contrast, actors enable Ray to efﬁciently\\nsupport stateful computations, such as model training, and\\nexpose shared mutable state to clients, (e.g., a parameter\\nserver). Ray implements the actor and the task abstrac-\\ntions on top of a single dynamic execution engine that is\\nhighly scalable and fault tolerant.\\nTo meet the performance requirements, Ray distributes\\ntwo components that are typically centralized in existing\\nframeworks [64, 28, 40]: (1) the task scheduler and (2) a\\nstate (si+1) \\n(observation)\\nreward (ri+1)\\naction (ai)\\nPolicy \\nimprovement\\n(e.g., SGD)\\ntrajectory: s0, (s1, r1), … , (sn, rn)\\npolicy\\nTraining Serving Simulation\\nPolicy\\nevaluation \\nEnvironment\\nAgent\\nFigure 1: Example of an RL system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. This allows Ray to sched-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Policy\\nevaluation \\nEnvironment\\nAgent\\nFigure 1: Example of an RL system.\\nmetadata store which maintains the computation lineage\\nand a directory for data objects. This allows Ray to sched-\\nule millions of tasks per second with millisecond-level\\nlatencies. Furthermore, Ray provides lineage-based fault\\ntolerance for tasks and actors, and replication-based fault\\ntolerance for the metadata store.\\nWhile Ray supports serving, training, and simulation\\nin the context of RL applications, this does not mean that\\nit should be viewed as a replacement for systems that pro-\\nvide solutions for these workloads in other contexts. In\\nparticular, Ray does not aim to substitute for serving sys-\\ntems like Clipper [ 19] and TensorFlow Serving [ 6], as\\nthese systems address a broader set of challenges in de-\\nploying models, including model management, testing,\\nand model composition. Similarly, despite its ﬂexibility,\\nRay is not a substitute for generic data-parallel frame-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ploying models, including model management, testing,\\nand model composition. Similarly, despite its ﬂexibility,\\nRay is not a substitute for generic data-parallel frame-\\nworks, such as Spark [64], as it currently lacks the rich\\nfunctionality and APIs (e.g., straggler mitigation, query\\noptimization) that these frameworks provide.\\nWe make the following contributions:\\n•We design and build the ﬁrst distributed frame-\\nwork that uniﬁes training, simulation, and serving—\\nnecessary components of emerging RL applications.\\n•To support these workloads, we unify the actor and\\ntask-parallel abstractions on top of a dynamic task\\nexecution engine.\\n•To achieve scalability and fault tolerance, we pro-\\npose a system design principle in which control state\\nis stored in a sharded metadata store and all other\\nsystem components are stateless.\\n•To achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 Motivation and Requirements\\nWe begin by considering the basic components of an RL'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='system components are stateless.\\n•To achieve scalability, we propose a bottom-up dis-\\ntributed scheduling strategy.\\n2 Motivation and Requirements\\nWe begin by considering the basic components of an RL\\nsystem and ﬂeshing out the key requirements for Ray. As\\nshown in Figure 1, in an RL setting, an agent interacts\\nrepeatedly with the environment. The goal of the agent\\nis to learn a policy that maximizes a reward. A policy is'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='// evaluate policyby interacting with env. (e.g., simulator)rollout(policy, environment):trajectory=[]state= environment.initial_state()while(notenvironment.has_terminated()):action= policy.compute(state) // Servingstate,reward= environment.step(action) // Simulationtrajectory.append(state,reward)returntrajectory// improve policy iteratively until it convergestrain_policy(environment):policy= initial_policy()while(policyhas not converged):trajectories = []forifrom1 tok:// evaluate policyby generating krolloutstrajectories.append(rollout(policy, environment))// improve policypolicy= policy.update(trajectories) // Trainingreturnpolicy\\nFigure 2: Typical RL pseudocode for learning a policy.\\na mapping from the state of the environment to a choice\\nof action. The precise deﬁnitions of environment, agent,\\nstate, action, and reward are application-speciﬁc.\\nTo learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='state, action, and reward are application-speciﬁc.\\nTo learn a policy, an agent typically employs a two-step\\nprocess: (1) policy evaluation and (2) policy improvement.\\nTo evaluate the policy, the agent interacts with the envi-\\nronment (e.g., with a simulation of the environment) to\\ngenerate trajectories, where a trajectory consists of a se-\\nquence of (state, reward) tuples produced by the current\\npolicy. Then, the agent uses these trajectories to improve\\nthe policy; i.e., to update the policy in the direction of the\\ngradient that maximizes the reward. Figure 2 shows an\\nexample of the pseudocode used by an agent to learn a\\npolicy. This pseudocode evaluates the policy by invok-\\ning rollout(environment, policy) to generate trajectories.\\ntrain policy() then uses these trajectories to improve the\\ncurrent policy via policy.update(trajectories). This pro-\\ncess repeats until the policy converges.\\nThus, a framework for RL applications must provide'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='current policy via policy.update(trajectories). This pro-\\ncess repeats until the policy converges.\\nThus, a framework for RL applications must provide\\nefﬁcient support for training, serving, and simulation\\n(Figure 1). Next, we brieﬂy describe these workloads.\\nTraining typically involves running stochastic gradient\\ndescent (SGD), often in a distributed setting, to update the\\npolicy. Distributed SGD typically relies on an allreduce\\naggregation step or a parameter server [32].\\nServing uses the trained policy to render an action based\\non the current state of the environment. A serving system\\naims to minimize latency, and maximize the number of\\ndecisions per second. To scale, load is typically balanced\\nacross multiple nodes serving the policy.\\nFinally, most existing RL applications use simulations\\nto evaluate the policy—current RL algorithms are not\\nsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. These simula-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='to evaluate the policy—current RL algorithms are not\\nsample-efﬁcient enough to rely solely on data obtained\\nfrom interactions with the physical world. These simula-\\ntions vary widely in complexity. They might take a few ms\\n(e.g., simulate a move in a chess game) to minutes (e.g.,\\nsimulate a realistic environment for a self-driving car).\\nIn contrast with supervised learning, in which train-\\ning and serving can be handled separately by different\\nsystems, in RL all three of these workloads are tightly\\ncoupled in a single application, with stringent latency re-\\nquirements between them. Currently, no framework sup-\\nports this coupling of workloads. In theory, multiple spe-\\ncialized frameworks could be stitched together to provide\\nthe overall capabilities, but in practice, the resulting data\\nmovement and latency between systems is prohibitive in\\nthe context of RL. As a result, researchers and practition-\\ners have been building their own one-off systems.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='movement and latency between systems is prohibitive in\\nthe context of RL. As a result, researchers and practition-\\ners have been building their own one-off systems.\\nThis state of affairs calls for the development of new\\ndistributed frameworks for RL that can efﬁciently support\\ntraining, serving, and simulation. In particular, such a\\nframework should satisfy the following requirements:\\nFine-grained, heterogeneous computations. The dura-\\ntion of a computation can range from milliseconds (e.g.,\\ntaking an action) to hours (e.g., training a complex pol-\\nicy). Additionally, training often requires heterogeneous\\nhardware (e.g., CPUs, GPUs, or TPUs).\\nFlexible computation model. RL applications require\\nboth stateless and stateful computations. Stateless compu-\\ntations can be executed on any node in the system, which\\nmakes it easy to achieve load balancing and movement\\nof computation to data, if needed. Thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='makes it easy to achieve load balancing and movement\\nof computation to data, if needed. Thus stateless com-\\nputations are a good ﬁt for ﬁne-grained simulation and\\ndata processing, such as extracting features from images\\nor videos. In contrast stateful computations are a good ﬁt\\nfor implementing parameter servers, performing repeated\\ncomputation on GPU-backed data, or running third-party\\nsimulators that do not expose their state.\\nDynamic execution. Several components of RL appli-\\ncations require dynamic execution, as the order in which\\ncomputations ﬁnish is not always known in advance (e.g.,\\nthe order in which simulations ﬁnish), and the results of a\\ncomputation can determine future computations (e.g., the\\nresults of a simulation will determine whether we need to\\nperform more simulations).\\nWe make two ﬁnal comments. First, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second.∗Second, such a framework'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='perform more simulations).\\nWe make two ﬁnal comments. First, to achieve high\\nutilization in large clusters, such a framework must handle\\nmillions of tasks per second.∗Second, such a framework\\nis not intended for implementing deep neural networks\\nor complex simulators from scratch. Instead, it should\\nenable seamless integration with existing simulators [13,\\n11, 59] and deep learning frameworks [7, 18, 46, 29].\\n∗Assume 5ms single-core tasks and a cluster of 200 32-core nodes.\\nThis cluster can run (1s/5ms) ×32 ×200 = 1.28M tasks/sec.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Name Description\\nfutures = f.remote(args) Execute function f remotely. f.remote() can take objects or futures as inputs\\nand returns one or more futures. This is non-blocking.\\nobjects = ray.get(futures) Return the values associated with one or more futures. This is blocking.\\nready futures = ray.wait(futures,k,timeout) Return the futures whose corresponding tasks have completed as soon as either\\nk have completed or the timeout expires.\\nactor = Class.remote(args) Instantiate class Class as a remote actor, and return a handle to it. Call a method\\nfutures = actor.method.remote(args) on the remote actor and return one or more futures. Both are non-blocking.\\nTable 1: Ray API\\n3 Programming and Computation Model\\nRay implements a dynamic task graph computation\\nmodel, i.e., it models an application as a graph of depen-\\ndent tasks that evolves during execution. On top of this\\nmodel, Ray provides both an actor and a task-parallel\\nprogramming abstraction. This uniﬁcation differentiates'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='dent tasks that evolves during execution. On top of this\\nmodel, Ray provides both an actor and a task-parallel\\nprogramming abstraction. This uniﬁcation differentiates\\nRay from related systems like CIEL, which only pro-\\nvides a task-parallel abstraction, and from Orleans [14] or\\nAkka [1], which primarily provide an actor abstraction.\\n3.1 Programming Model\\nTasks. A task represents the execution of a remote func-\\ntion on a stateless worker. When a remote function is\\ninvoked, a future representing the result of the task is\\nreturned immediately. Futures can be retrieved using\\nray.get() and passed as arguments into other remote func-\\ntions without waiting for their result. This allows the user\\nto express parallelism while capturing data dependencies.\\nTable 1 shows Ray’s API.\\nRemote functions operate on immutable objects and\\nare expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. This implies\\nidempotence, which simpliﬁes fault tolerance through'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='are expected to be stateless and side-effect free: their\\noutputs are determined solely by their inputs. This implies\\nidempotence, which simpliﬁes fault tolerance through\\nfunction re-execution on failure.\\nActors. An actor represents a stateful computation. Each\\nactor exposes methods that can be invoked remotely and\\nare executed serially. A method execution is similar to a\\ntask, in that it executes remotely and returns a future, but\\ndiffers in that it executes on a stateful worker. A handle\\nto an actor can be passed to other actors or tasks, making\\nit possible for them to invoke methods on that actor.\\nTasks (stateless) Actors (stateful)\\nFine-grained load balancing Coarse-grained load balancing\\nSupport for object locality Poor locality support\\nHigh overhead for small updates Low overhead for small updates\\nEfﬁcient failure handling Overhead from checkpointing\\nTable 2: Tasks vs. actors tradeoffs.\\nTable 2 summarizes the properties of tasks and actors.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Efﬁcient failure handling Overhead from checkpointing\\nTable 2: Tasks vs. actors tradeoffs.\\nTable 2 summarizes the properties of tasks and actors.\\nTasks enable ﬁne-grained load balancing through leverag-\\ning load-aware scheduling at task granularity, input data\\nlocality, as each task can be scheduled on the node stor-\\ning its inputs, and low recovery overhead, as there is no\\nneed to checkpoint and recover intermediate state. In con-\\ntrast, actors provide much more efﬁcient ﬁne-grained up-\\ndates, as these updates are performed on internal rather\\nthan external state, which typically requires serialization\\nand deserialization. For example, actors can be used to\\nimplement parameter servers [32] and GPU-based itera-\\ntive computations (e.g., training). In addition, actors can\\nbe used to wrap third-party simulators and other opaque\\nhandles that are hard to serialize.\\nTo satisfy the requirements for heterogeneity and ﬂex-\\nibility (Section 2), we augment the API in three ways.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='handles that are hard to serialize.\\nTo satisfy the requirements for heterogeneity and ﬂex-\\nibility (Section 2), we augment the API in three ways.\\nFirst, to handle concurrent tasks with heterogeneous du-\\nrations, we introduce ray.wait(), which waits for the\\nﬁrst k available results, instead of waiting for all results\\nlike ray.get(). Second, to handle resource-heterogeneous\\ntasks, we enable developers to specify resource require-\\nments so that the Ray scheduler can efﬁciently manage re-\\nsources. Third, to improve ﬂexibility, we enablenested re-\\nmote functions, meaning that remote functions can invoke\\nother remote functions. This is also critical for achiev-\\ning high scalability (Section 4), as it enables multiple pro-\\ncesses to invoke remote functions in a distributed fashion.\\n3.2 Computation Model\\nRay employs a dynamic task graph computation\\nmodel [21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='3.2 Computation Model\\nRay employs a dynamic task graph computation\\nmodel [21], in which the execution of both remote func-\\ntions and actor methods is automatically triggered by the\\nsystem when their inputs become available. In this sec-\\ntion, we describe how the computation graph (Figure 4) is\\nconstructed from a user program (Figure 3). This program\\nuses the API in Table 1 to implement the pseudocode\\nfrom Figure 2.\\nIgnoring actors ﬁrst, there are two types of nodes in\\na computation graph: data objects and remote function\\ninvocations, or tasks. There are also two types of edges:\\ndata edges and control edges. Data edges capture the de-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='@ray.remote\\ndef create_policy():\\n# Initialize the policy randomly.\\nreturn policy\\n@ray.remote(num_gpus=1)\\nclass Simulator(object):\\ndef __init__(self):\\n# Initialize the environment.\\nself.env = Environment()\\ndef rollout(self, policy, num_steps):\\nobservations = []\\nobservation = self.env.current_state()\\nfor _ in range(num_steps):\\naction = policy(observation)\\nobservation = self.env.step(action)\\nobservations.append(observation)\\nreturn observations\\n@ray.remote(num_gpus=2)\\ndef update_policy(policy, *rollouts):\\n# Update the policy.\\nreturn policy\\n@ray.remote\\ndef train_policy():\\n# Create a policy.\\npolicy_id = create_policy.remote()\\n# Create 10 actors.\\nsimulators = [Simulator.remote() for _ in range(10)]\\n# Do 100 steps of training.\\nfor _ in range(100):\\n# Perform one rollout on each actor.\\nrollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# Update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='rollout_ids = [s.rollout.remote(policy_id)\\nfor s in simulators]\\n# Update the policy with the rollouts.\\npolicy_id =\\nupdate_policy.remote(policy_id, *rollout_ids)\\nreturn ray.get(policy_id)\\nFigure 3: Python code implementing the example in Figure 2\\nin Ray. Note that @ray.remote indicates remote functions and\\nactors. Invocations of remote functions and actor methods return\\nfutures, which can be passed to subsequent remote functions or\\nactor methods to encode task dependencies. Each actor has an\\nenvironment object self.env shared between all of its methods.\\npendencies between data objects and tasks. More pre-\\ncisely, if data object D is an output of task T , we add a\\ndata edge from T to D. Similarly, if D is an input to T ,\\nwe add a data edge from D to T . Control edges capture\\nthe computation dependencies that result from nested re-\\nmote functions (Section 3.1): if task T1 invokes task T2,\\nthen we add a control edge from T1 to T2.\\nActor method invocations are also represented as nodes'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='mote functions (Section 3.1): if task T1 invokes task T2,\\nthen we add a control edge from T1 to T2.\\nActor method invocations are also represented as nodes\\nin the computation graph. They are identical to tasks\\nwith one key difference. To capture the state dependency\\nacross subsequent method invocations on the same actor,\\nwe add a third type of edge: a stateful edge. If method\\nMj is called right after method Mi on the same actor,\\nthen we add a stateful edge from Mi to Mj. Thus, all\\npolicy1\\nT1create_policy\\nT2update_policy\\nA11rollout\\nA12rollout policy2\\nT3update_policy\\nrollout11\\nrollout12\\nA21rollout\\nA22rolloutrollout22\\nA10Simulator A20Simulator\\n… ……data\\tedges statefuledgesobject task/methodcontrol\\tedges\\nrollout21\\nT0train_policy\\nFigure 4: The task graph corresponding to an invocation of\\ntrain policy.remote() in Figure 3. Remote function calls and the\\nactor method calls correspond to tasks in the task graph. The\\nﬁgure shows two actors. The method invocations for each actor'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='train policy.remote() in Figure 3. Remote function calls and the\\nactor method calls correspond to tasks in the task graph. The\\nﬁgure shows two actors. The method invocations for each actor\\n(the tasks labeled A1i and A2i) have stateful edges between them\\nindicating that they share the mutable actor state. There are con-\\ntrol edges from train policy to the tasks that it invokes. To train\\nmultiple policies in parallel, we could call train policy.remote()\\nmultiple times.\\nmethods invoked on the same actor object form a chain\\nthat is connected by stateful edges (Figure 4). This chain\\ncaptures the order in which these methods were invoked.\\nStateful edges help us embed actors in an otherwise\\nstateless task graph, as they capture the implicit data de-\\npendency between successive method invocations sharing\\nthe internal state of an actor. Stateful edges also enable\\nus to maintain lineage. As in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. By explic-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the internal state of an actor. Stateful edges also enable\\nus to maintain lineage. As in other dataﬂow systems [ 64],\\nwe track data lineage to enable reconstruction. By explic-\\nitly including stateful edges in the lineage graph, we can\\neasily reconstruct lost data, whether produced by remote\\nfunctions or actor methods (Section 4.2.3).\\n4 Architecture\\nRay’s architecture comprises (1) an application layer im-\\nplementing the API, and (2) a system layer providing high\\nscalability and fault tolerance.\\n4.1 Application Layer\\nThe application layer consists of three types of processes:\\n•Driver: A process executing the user program.\\n•Worker: A stateless process that executes tasks\\n(remote functions) invoked by a driver or another'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Local Scheduler\\nActorDriver\\nObject Store\\nGlobal SchedulerGlobal Scheduler\\nObject TableTask TableFunction TableEvent Logs\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nDriverWorker\\nObject Store\\nNode\\nGlobal Scheduler\\nWeb UIDebugging ToolsProfiling Tools\\nError Diagnosis\\nLocal Scheduler\\nWorkerWorker\\nObject Store\\nNode Node\\nApp LayerSystem Layer (backend)\\nFigure 5: Ray’s architecture consists of two parts: anapplica-\\ntion layer and a system layer. The application layer implements\\nthe API and the computation model described in Section 3, the\\nsystem layer implements task scheduling and data management\\nto satisfy the performance and fault-tolerance requirements.\\nworker. Workers are started automatically and as-\\nsigned tasks by the system layer. When a remote\\nfunction is declared, the function is automatically\\npublished to all workers. A worker executes tasks\\nserially, with no local state maintained across tasks.\\n•Actor: A stateful process that executes, when in-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='published to all workers. A worker executes tasks\\nserially, with no local state maintained across tasks.\\n•Actor: A stateful process that executes, when in-\\nvoked, only the methods it exposes. Unlike a worker,\\nan actor is explicitly instantiated by a worker or a\\ndriver. Like workers, actors execute methods seri-\\nally, except that each method depends on the state\\nresulting from the previous method execution.\\n4.2 System Layer\\nThe system layer consists of three major components: a\\nglobal control store, a distributed scheduler, and a dis-\\ntributed object store. All components are horizontally\\nscalable and fault-tolerant.\\n4.2.1 Global Control Store (GCS)\\nThe global control store (GCS) maintains the entire con-\\ntrol state of the system, and it is a unique feature of our\\ndesign. At its core, GCS is a key-value store with pub-\\nsub functionality. We use sharding to achieve scale, and\\nper-shard chain replication [61] to provide fault tolerance.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='design. At its core, GCS is a key-value store with pub-\\nsub functionality. We use sharding to achieve scale, and\\nper-shard chain replication [61] to provide fault tolerance.\\nThe primary reason for the GCS and its design is to main-\\ntain fault tolerance and low latency for a system that can\\ndynamically spawn millions of tasks per second.\\nFault tolerance in case of node failure requires a solu-\\ntion to maintain lineage information. Existing lineage-\\nbased solutions [64, 63, 40, 28] focus on coarse-grained\\nparallelism and can therefore use a single node (e.g., mas-\\nter, driver) to store the lineage without impacting perfor-\\nmance. However, this design is not scalable for a ﬁne-\\ngrained and dynamic workload like simulation. Therefore,\\nwe decouple the durable lineage storage from the other\\nsystem components, allowing each to scale independently.\\nMaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='system components, allowing each to scale independently.\\nMaintaining low latency requires minimizing over-\\nheads in task scheduling, which involves choosing where\\nto execute, and subsequently task dispatch, which in-\\nvolves retrieving remote inputs from other nodes. Many\\nexisting dataﬂow systems [ 64, 40, 48] couple these by\\nstoring object locations and sizes in a centralized sched-\\nuler, a natural design when the scheduler is not a bottle-\\nneck. However, the scale and granularity that Ray targets\\nrequires keeping the centralized scheduler off the critical\\npath. Involving the scheduler in each object transfer is pro-\\nhibitively expensive for primitives important to distributed\\ntraining like allreduce, which is both communication-\\nintensive and latency-sensitive. Therefore, we store the\\nobject metadata in the GCS rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nIn summary, the GCS signiﬁcantly simpliﬁes Ray’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='object metadata in the GCS rather than in the scheduler,\\nfully decoupling task dispatch from task scheduling.\\nIn summary, the GCS signiﬁcantly simpliﬁes Ray’s\\noverall design, as it enables every component in the sys-\\ntem to be stateless. This not only simpliﬁes support for\\nfault tolerance (i.e., on failure, components simply restart\\nand read the lineage from the GCS), but also makes it\\neasy to scale the distributed object store and scheduler in-\\ndependently, as all components share the needed state via\\nthe GCS. An added beneﬁt is the easy development of de-\\nbugging, proﬁling, and visualization tools.\\n4.2.2 Bottom-Up Distributed Scheduler\\nAs discussed in Section 2, Ray needs to dynamically\\nschedule millions of tasks per second, tasks which may\\ntake as little as a few milliseconds. None of the clus-\\nter schedulers we are aware of meet these requirements.\\nMost cluster computing frameworks, such as Spark [64],\\nCIEL [40], and Dryad [28] implement a centralized sched-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ter schedulers we are aware of meet these requirements.\\nMost cluster computing frameworks, such as Spark [64],\\nCIEL [40], and Dryad [28] implement a centralized sched-\\nuler, which can provide locality but at latencies in the tens\\nof ms. Distributed schedulers such as work stealing [12],\\nSparrow [45] and Canary [47] can achieve high scale, but\\nthey either don’t consider data locality [12], or assume\\ntasks belong to independent jobs [45], or assume the com-\\nputation graph is known [47].\\nTo satisfy the above requirements, we design a two-\\nlevel hierarchical scheduler consisting of a global sched-\\nuler and per-node local schedulers. To avoid overloading\\nthe global scheduler, the tasks created at a node are sub-\\nmitted ﬁrst to the node’s local scheduler. A local sched-\\nuler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='uler schedules tasks locally unless the node is overloaded\\n(i.e., its local task queue exceeds a predeﬁned threshold),\\nor it cannot satisfy a task’s requirements (e.g., lacks a\\nGPU). If a local scheduler decides not to schedule a task\\nlocally, it forwards it to the global scheduler. Since this\\nscheduler attempts to schedule tasks locally ﬁrst (i.e., at\\nthe leaves of the scheduling hierarchy), we call it abottom-\\nup scheduler.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Global Scheduler\\nLocal Scheduler\\nGlobal Scheduler\\nWorkerDriverWorker…\\nGlobal Control        State (GCS)\\nLocal Scheduler\\nWorkerWorkerWorker\\nSubmit tasksSchedule tasksLoadinfo\\nNode 1 Node N\\nFigure 6: Bottom-up distributed scheduler. Tasks are submitted\\nbottom-up, from drivers and workers to a local scheduler and\\nforwarded to the global scheduler only if needed (Section 4.2.2).\\nThe thickness of each arrow is proportional to its request rate.\\nThe global scheduler considers each node’s load and\\ntask’s constraints to make scheduling decisions. More pre-\\ncisely, the global scheduler identiﬁes the set of nodes that\\nhave enough resources of the type requested by the task,\\nand of these nodes selects the node which provides the\\nlowest estimated waiting time. At a given node, this time\\nis the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='is the sum of (i) the estimated time the task will be queued\\nat that node (i.e., task queue size times average task ex-\\necution), and (ii) the estimated transfer time of task’s\\nremote inputs (i.e., total size of remote inputs divided by\\naverage bandwidth). The global scheduler gets the queue\\nsize at each node and the node resource availability via\\nheartbeats, and the location of the task’s inputs and their\\nsizes from GCS. Furthermore, the global scheduler com-\\nputes the average task execution and the average transfer\\nbandwidth using simple exponential averaging. If the\\nglobal scheduler becomes a bottleneck, we can instantiate\\nmore replicas all sharing the same information via GCS.\\nThis makes our scheduler architecture highly scalable.\\n4.2.3 In-Memory Distributed Object Store\\nTo minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. On each node, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='To minimize task latency, we implement an in-memory\\ndistributed storage system to store the inputs and outputs\\nof every task, or stateless computation. On each node, we\\nimplement the object store via shared memory. This al-\\nlows zero-copy data sharing between tasks running on the\\nsame node. As a data format, we use Apache Arrow [2].\\nIf a task’s inputs are not local, the inputs are replicated\\nto the local object store before execution. Also, a task\\nwrites its outputs to the local object store. Replication\\neliminates the potential bottleneck due to hot data ob-\\njects and minimizes task execution time as a task only\\nreads/writes data from/to the local memory. This in-\\ncreases throughput for computation-bound workloads, a\\nproﬁle shared by many AI applications. For low latency,\\nwe keep objects entirely in memory and evict them as\\nneeded to disk using an LRU policy.\\nAs with existing cluster computing frameworks, such\\nas Spark [64], and Dryad [28], the object store is limited'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='we keep objects entirely in memory and evict them as\\nneeded to disk using an LRU policy.\\nAs with existing cluster computing frameworks, such\\nas Spark [64], and Dryad [28], the object store is limited\\nto immutable data. This obviates the need for complex\\nconsistency protocols (as objects are not updated), and\\nsimpliﬁes support for fault tolerance. In the case of node\\nfailure, Ray recovers any needed objects through lineage\\nre-execution. The lineage stored in the GCS tracks both\\nstateless tasks and stateful actors during initial execution;\\nwe use the former to reconstruct objects in the store.\\nFor simplicity, our object store does not support dis-\\ntributed objects, i.e., each object ﬁts on a single node. Dis-\\ntributed objects like large matrices or trees can be imple-\\nmented at the application level as collections of futures.\\n4.2.4 Implementation\\nRay is an active open source project†developed at the Uni-\\nversity of California, Berkeley. Ray fully integrates with'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='mented at the application level as collections of futures.\\n4.2.4 Implementation\\nRay is an active open source project†developed at the Uni-\\nversity of California, Berkeley. Ray fully integrates with\\nthe Python environment and is easy to install by simply\\nrunning pip install ray. The implementation com-\\nprises ≈ 40K lines of code (LoC), 72% in C++ for the\\nsystem layer, 28% in Python for the application layer. The\\nGCS uses one Redis [50] key-value store per shard, with\\nentirely single-key operations. GCS tables are sharded\\nby object and task IDs to scale, and every shard is chain-\\nreplicated [61] for fault tolerance. We implement both\\nthe local and global schedulers as event-driven, single-\\nthreaded processes. Internally, local schedulers maintain\\ncached state for local object metadata, tasks waiting for\\ninputs, and tasks ready for dispatch to a worker. To trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple TCP connections.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='inputs, and tasks ready for dispatch to a worker. To trans-\\nfer large objects between different object stores, we stripe\\nthe object across multiple TCP connections.\\n4.3 Putting Everything Together\\nFigure 7 illustrates how Ray works end-to-end with a\\nsimple example that adds two objects a and b, which\\ncould be scalars or matrices, and returns result c. The\\nremote function add() is automatically registered with the\\nGCS upon initialization and distributed to every worker\\nin the system (step 0 in Figure 7a).\\nFigure 7a shows the step-by-step operations triggered\\nby a driver invoking add.remote(a,b), where a and b are\\nstored on nodes N1 and N2, respectively. The driver sub-\\nmits add(a, b) to the local scheduler (step 1), which for-\\nwards it to a global scheduler (step 2).‡Next, the global\\nscheduler looks up the locations of add(a, b)’s arguments\\nin the GCS (step 3) and decides to schedule the task on\\nnode N2, which stores argument b (step 4). The local'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='scheduler looks up the locations of add(a, b)’s arguments\\nin the GCS (step 3) and decides to schedule the task on\\nnode N2, which stores argument b (step 4). The local\\nscheduler at node N2 checks whether the local object\\nstore contains add(a, b)’s arguments (step 5). Since the\\n†https://github.com/ray-project/ray\\n‡Note that N1 could also decide to schedule the task locally.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Object store\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\n45\\n6\\nLocal Scheduler\\nObject store\\nidaa1\\n2\\n8\\nGlobal Scheduler\\n7\\n9\\nidaaidbb\\n0\\n3 Local Scheduler\\n(a) Executing a task remotely\\nLocal Scheduler\\nidbb\\n@ray.remotedefadd(a, b):return a + b@ray.remotedefadd(a, b):return a + bidc= add.remote(a, b)c = ray.get(idc)\\nN1Driver \\nObject Table\\nFunction Table@ray.remotedefadd(a, b):return a + b\\nN2Worker \\nida N1idb N2\\nGlobal Control Store (GCS)\\nLocal Scheduler\\nidaa1 idaaidcc idc N2, N14257 3\\nGlobal Scheduler\\nidcc6\\n(b) Returning the result of a remote task\\nFigure 7: An end-to-end example that adds a and b and returns\\nc. Solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) The function add() is registered\\nwith the GCS by node 1 ( N1), invoked on N1, and executed'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='c. Solid lines are data plane operations and dotted lines are\\ncontrol plane operations. (a) The function add() is registered\\nwith the GCS by node 1 ( N1), invoked on N1, and executed\\non N2. (b) N1 gets add()’s result usingray.get(). The Object\\nTable entry for c is created in step 4 and updated in step 6 after\\nc is copied to N1.\\nlocal store doesn’t have objecta, it looks up a’s location\\nin the GCS (step 6). Learning that a is stored at N1, N2’s\\nobject store replicates it locally (step 7). As all arguments\\nof add() are now stored locally, the local scheduler in-\\nvokes add() at a local worker (step 8), which accesses the\\narguments via shared memory (step 9).\\nFigure 7b shows the step-by-step operations triggered\\nby the execution of ray.get() at N1, and of add() at N2,\\nrespectively. Upon ray.get(idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idc returned by add() (step 1). Since the local'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='respectively. Upon ray.get(idc)’s invocation, the driver\\nchecks the local object store for the value c, using the\\nfuture idc returned by add() (step 1). Since the local\\nobject store doesn’t storec, it looks up its location in the\\nGCS. At this time, there is no entry for c, as c has not\\nbeen created yet. As a result, N1’s object store registers a\\ncallback with the Object Table to be triggered when c’s\\nentry has been created (step 2). Meanwhile, at N2, add()\\ncompletes its execution, stores the result c in the local\\nobject store (step 3), which in turn adds c’s entry to the\\nGCS (step 4). As a result, the GCS triggers a callback\\nto N1’s object store with c’s entry (step 5). Next, N1\\nreplicates c from N2 (step 6), and returns c to ray.get()\\n(step 7), which ﬁnally completes the task.\\nWhile this example involves a large number of RPCs,\\n100KB 1MB 10MB 100MB\\nObject size\\n10-5\\n10-4\\n10-3\\n10-2\\n10-1\\nMean task latency (s)\\nLocality Aware\\nUnaware\\n(a) Ray locality scheduling\\n10 20 30 40 50 60 100'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='100KB 1MB 10MB 100MB\\nObject size\\n10-5\\n10-4\\n10-3\\n10-2\\n10-1\\nMean task latency (s)\\nLocality Aware\\nUnaware\\n(a) Ray locality scheduling\\n10 20 30 40 50 60 100\\nnumber of nodes\\n0.0\\n0.4\\n0.8\\n1.2\\n1.6Millions of tasks/s (b) Ray scalability\\nFigure 8: (a) Tasks leverage locality-aware placement. 1000\\ntasks with a random object dependency are scheduled onto one\\nof two nodes. With locality-aware policy, task latency remains\\nindependent of the size of task inputs instead of growing by 1-2\\norders of magnitude. (b) Near-linear scalability leveraging the\\nGCS and bottom-up distributed scheduler. Ray reaches 1 million\\ntasks per second throughput with 60 nodes. x ∈{70,80,90}\\nomitted due to cost.\\nin many cases this number is much smaller, as most tasks\\nare scheduled locally, and the GCS replies are cached by\\nthe global and local schedulers.\\n5 Evaluation\\nIn our evaluation, we study the following questions:\\n1. How well does Ray meet the latency, scalability,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the global and local schedulers.\\n5 Evaluation\\nIn our evaluation, we study the following questions:\\n1. How well does Ray meet the latency, scalability,\\nand fault tolerance requirements listed in Section 2?\\n(Section 5.1)\\n2. What overheads are imposed on distributed primi-\\ntives (e.g., allreduce) written using Ray’s API? (Sec-\\ntion 5.1)\\n3. In the context of RL workloads, how does Ray com-\\npare against specialized systems for training, serv-\\ning, and simulation? (Section 5.2)\\n4. What advantages does Ray provide for RL applica-\\ntions, compared to custom systems? (Section 5.3)\\nAll experiments were run on Amazon Web Services.\\nUnless otherwise stated, we use m4.16xlarge CPU in-\\nstances and p3.16xlarge GPU instances.\\n5.1 Microbenchmarks\\nLocality-aware task placement. Fine-grain load bal-\\nancing and locality-aware placement are primary beneﬁts\\nof tasks in Ray. Actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ancing and locality-aware placement are primary beneﬁts\\nof tasks in Ray. Actors, once placed, are unable to move\\ntheir computation to large remote objects, while tasks can.\\nIn Figure 8a, tasks placed without data locality awareness\\n(as is the case for actor methods), suffer 1-2 orders of\\nmagnitude latency increase at 10-100MB input data sizes.\\nRay uniﬁes tasks and actors through the shared object\\nstore, allowing developers to use tasks for e.g., expensive\\npostprocessing on output produced by simulation actors.\\nEnd-to-end scalability. One of the key beneﬁts of'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='1KB 10KB100KB 1MB 10MB100MB 1GB\\nobject size\\n0\\n5000\\n10000\\n15000\\n20000IOPS\\n0\\n2\\n4\\n6\\n8\\n10\\n12\\n14\\n16\\nthroughput (GB/s)\\nFigure 9: Object store write throughput and IOPS. From a\\nsingle client, throughput exceeds 15GB/s (red) for large objects\\nand 18K IOPS (cyan) for small objects on a 16 core instance\\n(m4.4xlarge). It uses 8 threads to copy objects larger than 0.5MB\\nand 1 thread for small objects. Bar plots report throughput with\\n1, 2, 4, 8, 16 threads. Results are averaged over 5 runs.\\nthe Global Control Store (GCS) and the bottom-up dis-\\ntributed scheduler is the ability to horizontally scale the\\nsystem to support a high throughput of ﬁne-grained tasks,\\nwhile maintaining fault tolerance and low-latency task\\nscheduling. In Figure 8b, we evaluate this ability on an\\nembarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. We observe near-perfect\\nlinearity in progressively increasing task throughput. Ray'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='embarrassingly parallel workload of empty tasks, increas-\\ning the cluster size on the x-axis. We observe near-perfect\\nlinearity in progressively increasing task throughput. Ray\\nexceeds 1 million tasks per second throughput at 60 nodes\\nand continues to scale linearly beyond 1.8 million tasks\\nper second at 100 nodes. The rightmost datapoint shows\\nthat Ray can process 100 million tasks in less than a\\nminute (54s), with minimum variability. As expected, in-\\ncreasing task duration reduces throughput proportionally\\nto mean task duration, but the overall scalability remains\\nlinear. While many realistic workloads may exhibit more\\nlimited scalability due to object dependencies and inher-\\nent limits to application parallelism, this demonstrates the\\nscalability of our overall architecture under high load.\\nObject store performance. To evaluate the perfor-\\nmance of the object store (Section 4.2.3), we track two\\nmetrics: IOPS (for small objects) and write throughput'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Object store performance. To evaluate the perfor-\\nmance of the object store (Section 4.2.3), we track two\\nmetrics: IOPS (for small objects) and write throughput\\n(for large objects). In Figure 9, the write throughput from\\na single client exceeds 15GB/s as object size increases.\\nFor larger objects, memcpy dominates object creation\\ntime. For smaller objects, the main overheads are in seri-\\nalization and IPC between the client and object store.\\nGCS fault tolerance. To maintain low latency while\\nproviding strong consistency and fault tolerance, we build\\na lightweight chain replication [61] layer on top of Redis.\\nFigure 10a simulates recording Ray tasks to and reading\\ntasks from the GCS, where keys are 25 bytes and values\\nare 512 bytes. The client sends requests as fast as it can,\\nhaving at most one in-ﬂight request at a time. Failures are\\nreported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='reported to the chain master either from the client (having\\nreceived explicit errors, or timeouts despite retries) or\\n0 1 2 3 4 5 6 7 8 9 10\\nTime since start (s)\\n103 103\\n104 104\\nLatency (μs) write\\nread\\nnode dead\\n(a) A timeline for GCS read and write latencies as viewed from\\na client submitting tasks. The chain starts with 2 replicas. We\\nmanually trigger reconﬁguration as follows. At t ≈4.2s, a chain\\nmember is killed; immediately after, a new chain member joins,\\ninitiates state transfer, and restores the chain to 2-way replication.\\nThe maximum client-observed latency is under 30ms despite\\nreconﬁgurations.\\n0 10000 20000 30000 40000 50000 60000\\nElasped Time (seconds)\\n0\\n2000\\n4000\\n6000\\n8000GCS Used Memory (MB)\\n50 million no-op tasks\\nRay, no GCS flush\\nRay, GCS flush\\n(b) The Ray GCS maintains a constant memory footprint with\\nGCS ﬂushing. Without GCS ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Ray, GCS flush\\n(b) The Ray GCS maintains a constant memory footprint with\\nGCS ﬂushing. Without GCS ﬂushing, the memory footprint\\nreaches a maximum capacity and the workload fails to complete\\nwithin a predetermined duration (indicated by the red cross).\\nFigure 10: Ray GCS fault tolerance and ﬂushing.\\nfrom any server in the chain (having received explicit\\nerrors). Overall, reconﬁgurations caused a maximum\\nclient-observed delay of under 30ms (this includes both\\nfailure detection and recovery delays).\\nGCS ﬂushing. Ray is equipped to periodically ﬂush\\nthe contents of GCS to disk. In Figure 10b we submit 50\\nmillion empty tasks sequentially and monitor GCS mem-\\nory consumption. As expected, it grows linearly with the\\nnumber of tasks tracked and eventually reaches the mem-\\nory capacity of the system. At that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. With periodic GCS ﬂushing, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ory capacity of the system. At that point, the system be-\\ncomes stalled and the workload fails to ﬁnish within a rea-\\nsonable amount of time. With periodic GCS ﬂushing, we\\nachieve two goals. First, the memory footprint is capped\\nat a user-conﬁgurable level (in the microbenchmark we\\nemploy an aggressive strategy where consumed memory\\nis kept as low as possible). Second, the ﬂushing mecha-\\nnism provides a natural way to snapshot lineage to disk\\nfor long-running Ray applications.\\nRecovering from task failures. In Figure 11a, we'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='0 50 100 150 200\\nTime since start (s)\\n0\\n500\\n1000\\n1500\\n2000Throughput (tasks/s)\\n0\\n20\\n40\\n60\\nNumber of nodes\\nOriginal tasks\\nRe-executed tasks\\n(a) Task reconstruction\\n100 200 300 400 500 600\\nTime since start (s)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700Throughput (tasks/s)\\nOriginal tasks\\nRe-executed tasks\\nCheckpoint tasks\\n(b) Actor reconstruction\\nFigure 11: Ray fault-tolerance. (a) Ray reconstructs lost task\\ndependencies as nodes are removed (dotted line), and recovers\\nto original throughput when nodes are added back. Each task\\nis 100ms and depends on an object generated by a previously\\nsubmitted task. (b) Actors are reconstructed from their last\\ncheckpoint. At t = 200s, we kill 2 of the 10 nodes, causing 400\\nof the 2000 actors in the cluster to be recovered on the remaining\\nnodes (t = 200–270s).\\ndemonstrate Ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable GCS lineage storage. The workload, run on'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='nodes (t = 200–270s).\\ndemonstrate Ray’s ability to transparently recover from\\nworker node failures and elastically scale, using the\\ndurable GCS lineage storage. The workload, run on\\nm4.xlarge instances, consists of linear chains of 100ms\\ntasks submitted by the driver. As nodes are removed (at\\n25s, 50s, 100s), the local schedulers reconstruct previous\\nresults in the chain in order to continue execution. Over-\\nall per-node throughput remains stable throughout.\\nRecovering from actor failures. By encoding actor\\nmethod calls as stateful edges directly in the dependency\\ngraph, we can reuse the same object reconstruction mech-\\nanism as in Figure 11a to provide transparent fault tol-\\nerance for stateful computation. Ray additionally lever-\\nages user-deﬁned checkpoint functions to bound the re-\\nconstruction time for actors (Figure 11b). With minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='construction time for actors (Figure 11b). With minimal\\noverhead, checkpointing enables only 500 methods to be\\nre-executed, versus 10k re-executions without checkpoint-\\ning. In the future, we hope to further reduce actor recon-\\nstruction time, e.g., by allowing users to annotate meth-\\nods that do not mutate state.\\nAllreduce. Allreduce is a distributed communication\\n10MB 100MB 1GB\\nObject size\\n100\\n101\\n102\\n103\\n104\\nIteration time (milliseconds)\\nOpenMPI\\nRay*\\nRay\\n(a) Ray vs OpenMPI\\n+0 +1 +5 +10\\nAdded scheduler latency (ms)\\n0\\n100\\n200\\n300\\n400\\n500\\n600\\n700\\n800Iteration time (milliseconds)\\nRay ring reduce latency\\n(16 nodes, 100MB) (b) Ray scheduler ablation\\nFigure 12: (a) Mean execution time of allreduce on 16 m4.16xl\\nnodes. Each worker runs on a distinct node. Ray* restricts Ray\\nto 1 thread for sending and 1 thread for receiving. (b) Ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='to 1 thread for sending and 1 thread for receiving. (b) Ray’s low-\\nlatency scheduling is critical for allreduce.\\nprimitive important to many machine learning workloads.\\nHere, we evaluate whether Ray can natively support a\\nring allreduce [57] implementation with low enough over-\\nhead to match existing implementations [53]. We ﬁnd that\\nRay completes allreduce across 16 nodes on 100MB in\\n∼200ms and 1GB in ∼1200ms, surprisingly outperform-\\ning OpenMPI (v1.10), a popular MPI implementation,\\nby 1.5×and 2×respectively (Figure 12a). We attribute\\nRay’s performance to its use of multiple threads for net-\\nwork transfers, taking full advantage of the 25Gbps con-\\nnection between nodes on AWS, whereas OpenMPI se-\\nquentially sends and receives data on a single thread [22].\\nFor smaller objects, OpenMPI outperforms Ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nRay’s scheduler performance is critical to implement-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='For smaller objects, OpenMPI outperforms Ray by switch-\\ning to a lower overhead algorithm, an optimization we\\nplan to implement in the future.\\nRay’s scheduler performance is critical to implement-\\ning primitives such as allreduce. In Figure 12b, we inject\\nartiﬁcial task execution delays and show that performance\\ndrops nearly 2×with just a few ms of extra latency. Sys-\\ntems with centralized schedulers like Spark and CIEL typ-\\nically have scheduler overheads in the tens of millisec-\\nonds [62, 38], making such workloads impractical. Sched-\\nuler throughput also becomes a bottleneck since the num-\\nber of tasks required by ring reduce scales quadratically\\nwith the number of participants.\\n5.2 Building blocks\\nEnd-to-end applications (e.g., AlphaGo [ 54]) require a\\ntight coupling of training, serving, and simulation. In this\\nsection, we isolate each of these workloads to a setting\\nthat illustrates a typical RL application’s requirements.\\nDue to a ﬂexible programming model targeted to RL, and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='section, we isolate each of these workloads to a setting\\nthat illustrates a typical RL application’s requirements.\\nDue to a ﬂexible programming model targeted to RL, and\\na system designed to support this programming model,\\nRay matches and sometimes exceeds the performance of\\ndedicated systems for these individual workloads.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='4 8 16 32 64\\nNum GPUs (V100)\\n0\\n1000\\n2000\\n3000\\n4000\\n5000\\n6000\\n7000Mean images / s\\nHorovod + TF\\nDistributed TF\\nRay + TF\\nFigure 13: Images per second reached when distributing the\\ntraining of a ResNet-101 TensorFlow model (from the ofﬁcial\\nTF benchmark). All experiments were run on p3.16xl instances\\nconnected by 25Gbps Ethernet, and workers allocated 4 GPUs\\nper node as done in Horovod [53]. We note some measurement\\ndeviations from previously reported, likely due to hardware\\ndifferences and recent TensorFlow performance improvements.\\nWe used OpenMPI 3.0, TF 1.8, and NCCL2 for all runs.\\n5.2.1 Distributed Training\\nWe implement data-parallel synchronous SGD leverag-\\ning the Ray actor abstraction to represent model replicas.\\nModel weights are synchronized via allreduce (5.1) or pa-\\nrameter server, both implemented on top of the Ray API.\\nIn Figure 13, we evaluate the performance of the\\nRay (synchronous) parameter-server SGD implementa-\\ntion against state-of-the-art implementations [ 53], us-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='In Figure 13, we evaluate the performance of the\\nRay (synchronous) parameter-server SGD implementa-\\ntion against state-of-the-art implementations [ 53], us-\\ning the same TensorFlow model and synthetic data gen-\\nerator for each experiment. We compare only against\\nTensorFlow-based systems to accurately measure the over-\\nhead imposed by Ray, rather than differences between the\\ndeep learning frameworks themselves. In each iteration,\\nmodel replica actors compute gradients in parallel, send\\nthe gradients to a sharded parameter server, then read the\\nsummed gradients from the parameter server for the next\\niteration.\\nFigure 13 shows that Ray matches the performance of\\nHorovod and is within 10% of distributed TensorFlow\\n(in distributed replicated mode). This is due to\\nthe ability to express the same application-level optimiza-\\ntions found in these specialized systems in Ray’s general-\\npurpose API. A key optimization is the pipelining of gra-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the ability to express the same application-level optimiza-\\ntions found in these specialized systems in Ray’s general-\\npurpose API. A key optimization is the pipelining of gra-\\ndient computation, transfer, and summation within a sin-\\ngle iteration. To overlap GPU computation with network\\ntransfer, we use a custom TensorFlow operator to write\\ntensors directly to Ray’s object store.\\n5.2.2 Serving\\nModel serving is an important component of end-to-end\\napplications. Ray focuses primarily on the embedded\\nserving of models to simulators running within the same\\ndynamic task graph (e.g., within an RL application on\\nRay). In contrast, systems like Clipper [ 19] focus on\\nserving predictions to external clients.\\nIn this setting, low latency is critical for achieving high\\nutilization. To show this, in Table 3 we compare the\\nSystem Small Input Larger Input\\nClipper 4400 ±15 states/sec 290 ±1.3 states/sec\\nRay 6200 ±21 states/sec 6900 ±150 states/sec'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='utilization. To show this, in Table 3 we compare the\\nSystem Small Input Larger Input\\nClipper 4400 ±15 states/sec 290 ±1.3 states/sec\\nRay 6200 ±21 states/sec 6900 ±150 states/sec\\nTable 3: Throughput comparisons for Clipper [19], a dedicated\\nserving system, and Ray for two embedded serving workloads.\\nWe use a residual network and a small fully connected network,\\ntaking 10ms and 5ms to evaluate, respectively. The server is\\nqueried by clients that each send states of size 4KB and 100KB\\nrespectively in batches of 64.\\nserver throughput achieved using a Ray actor to serve\\na policy versus using the open source Clipper system\\nover REST. Here, both client and server processes are co-\\nlocated on the same machine (a p3.8xlarge instance). This\\nis often the case for RL applications but not for the general\\nweb serving workloads addressed by systems like Clipper.\\nDue to its low-overhead serialization and shared memory\\nabstractions, Ray achieves an order of magnitude higher'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='web serving workloads addressed by systems like Clipper.\\nDue to its low-overhead serialization and shared memory\\nabstractions, Ray achieves an order of magnitude higher\\nthroughput for a small fully connected policy model that\\ntakes in a large input and is also faster on a more expensive\\nresidual network policy model, similar to one used in\\nAlphaGo Zero, that takes smaller input.\\n5.2.3 Simulation\\nSimulators used in RL produce results with variable\\nlengths (“timesteps”) that, due to the tight loop with train-\\ning, must be used as soon as they are available. The task\\nheterogeneity and timeliness requirements make simu-\\nlations hard to support efﬁciently in BSP-style systems.\\nTo demonstrate, we compare (1) an MPI implementation\\nthat submits 3n parallel simulation runs on n cores in 3\\nrounds, with a global barrier between rounds §, to (2) a\\nRay program that issues the same 3n tasks while concur-\\nrently gathering simulation results back to the driver. Ta-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='rounds, with a global barrier between rounds §, to (2) a\\nRay program that issues the same 3n tasks while concur-\\nrently gathering simulation results back to the driver. Ta-\\nble 4 shows that both systems scale well, yet Ray achieves\\nup to 1.8×throughput. This motivates a programming\\nmodel that can dynamically spawn and collect the results\\nof ﬁne-grained simulation tasks.\\nSystem, programming model 1 CPU 16 CPUs 256 CPUs\\nMPI, bulk synchronous 22.6K 208K 2.16M\\nRay, asynchronous tasks 22.3K 290K 4.03M\\nTable 4: Timesteps per second for the Pendulum-v0 simulator\\nin OpenAI Gym [ 13]. Ray allows for better utilization when\\nrunning heterogeneous simulations at scale.\\n§Note that experts can use MPI’s asynchronous primitives to get\\naround barriers—at the expense of increased program complexity —we\\nnonetheless chose such an implementation to simulate BSP.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='5.3 RL Applications\\nWithout a system that can tightly couple the training, sim-\\nulation, and serving steps, reinforcement learning algo-\\nrithms today are implemented as one-off solutions that\\nmake it difﬁcult to incorporate optimizations that, for ex-\\nample, require a different computation structure or that\\nutilize different architectures. Consequently, with imple-\\nmentations of two representative reinforcement learning\\napplications in Ray, we are able to match and even out-\\nperform custom systems built speciﬁcally for these algo-\\nrithms. The primary reason is the ﬂexibility of Ray’s pro-\\ngramming model, which can express application-level op-\\ntimizations that would require substantial engineering ef-\\nfort to port to custom-built systems, but are transparently\\nsupported by Ray’s dynamic task graph execution engine.\\n5.3.1 Evolution Strategies\\nTo evaluate Ray on large-scale RL workloads, we imple-\\nment the evolution strategies (ES) algorithm and com-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='supported by Ray’s dynamic task graph execution engine.\\n5.3.1 Evolution Strategies\\nTo evaluate Ray on large-scale RL workloads, we imple-\\nment the evolution strategies (ES) algorithm and com-\\npare to the reference implementation [49]—a system spe-\\ncially built for this algorithm that relies on Redis for mes-\\nsaging and low-level multiprocessing libraries for data-\\nsharing. The algorithm periodically broadcasts a new pol-\\nicy to a pool of workers and aggregates the results of\\nroughly 10000 tasks (each performing 10 to 1000 simula-\\ntion steps).\\nAs shown in Figure 14a, an implementation on Ray\\nscales to 8192 cores. Doubling the cores available yields\\nan average completion time speedup of 1.6×. Conversely,\\nthe special-purpose system fails to complete at 2048 cores,\\nwhere the work in the system exceeds the processing\\ncapacity of the application driver. To avoid this issue, the\\nRay implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='capacity of the application driver. To avoid this issue, the\\nRay implementation uses an aggregation tree of actors,\\nreaching a median time of 3.7 minutes, more than twice\\nas fast as the best published result (10 minutes).\\nInitial parallelization of a serial implementation using\\nRay required modifying only 7 lines of code. Performance\\nimprovement through hierarchical aggregation was easy\\nto realize with Ray’s support for nested tasks and actors.\\nIn contrast, the reference implementation had several hun-\\ndred lines of code dedicated to a protocol for communi-\\ncating tasks and data between workers, and would require\\nfurther engineering to support optimizations like hierar-\\nchical aggregation.\\n5.3.2 Proximal Policy Optimization\\nWe implement Proximal Policy Optimization (PPO) [51]\\nin Ray and compare to a highly-optimized reference im-\\nplementation [5] that uses OpenMPI communication prim-\\nitives. The algorithm is an asynchronous scatter-gather,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='in Ray and compare to a highly-optimized reference im-\\nplementation [5] that uses OpenMPI communication prim-\\nitives. The algorithm is an asynchronous scatter-gather,\\nwhere new tasks are assigned to simulation actors as they\\n256 1024 8192\\nNumber of CPUs\\n0\\n10\\n20\\n30\\n40\\n50\\n60\\n70\\n80\\n90Mean time to solve (minutes)\\nx x x\\nReference ES\\nRay ES\\n(a) Evolution Strategies\\n8x1 64x8 512x64\\nCPUs x GPUs\\n0\\n100\\n200\\n300\\n400\\n500Mean time to solve (minutes)\\nMPI PPO\\nRay PPO (b) PPO\\nFigure 14: Time to reach a score of 6000 in the Humanoid-\\nv1 task [ 13]. (a) The Ray ES implementation scales well to\\n8192 cores and achieves a median time of 3.7 minutes, over\\ntwice as fast as the best published result. The special-purpose\\nsystem failed to run beyond 1024 cores. ES is faster than PPO\\non this benchmark, but shows greater runtime variance. (b)\\nThe Ray PPO implementation outperforms a specialized MPI\\nimplementation [5] with fewer GPUs, at a fraction of the cost.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='on this benchmark, but shows greater runtime variance. (b)\\nThe Ray PPO implementation outperforms a specialized MPI\\nimplementation [5] with fewer GPUs, at a fraction of the cost.\\nThe MPI implementation required 1 GPU for every 8 CPUs,\\nwhereas the Ray version required at most 8 GPUs (and never\\nmore than 1 GPU per 8 CPUs).\\nreturn rollouts to the driver. Tasks are submitted un-\\ntil 320000 simulation steps are collected (each task pro-\\nduces between 10 and 1000 steps). The policy update per-\\nforms 20 steps of SGD with a batch size of 32768. The\\nmodel parameters in this example are roughly 350KB.\\nThese experiments were run using p2.16xlarge (GPU) and\\nm4.16xlarge (high CPU) instances.\\nAs shown in Figure 14b, the Ray implementation out-\\nperforms the optimized MPI implementation in all exper-\\niments, while using a fraction of the GPUs. The reason\\nis that Ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='iments, while using a fraction of the GPUs. The reason\\nis that Ray is heterogeneity-aware and allows the user to\\nutilize asymmetric architectures by expressing resource\\nrequirements at the granularity of a task or actor. The Ray\\nimplementation can then leverage TensorFlow’s single-\\nprocess multi-GPU support and can pin objects in GPU\\nmemory when possible. This optimization cannot be eas-\\nily ported to MPI due to the need to asynchronously gather\\nrollouts to a single GPU process. Indeed, [5] includes two\\ncustom implementations of PPO, one using MPI for large\\nclusters and one that is optimized for GPUs but that is re-\\nstricted to a single node. Ray allows for an implementa-\\ntion suitable for both scenarios.\\nRay’s ability to handle resource heterogeneity also de-\\ncreased PPO’s cost by a factor of 4.5 [4], since CPU-only\\ntasks can be scheduled on cheaper high-CPU instances.\\nIn contrast, MPI applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tasks can be scheduled on cheaper high-CPU instances.\\nIn contrast, MPI applications often exhibit symmetric ar-\\nchitectures, in which all processes run the same code and\\nrequire identical resources, in this case preventing the\\nuse of CPU-only machines for scale-out. Furthermore,\\nthe MPI implementation requires on-demand instances\\nsince it does not transparently handle failure. Assum-\\ning 4×cheaper spot instances, Ray’s fault tolerance and\\nresource-aware scheduling together cut costs by 18×.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='6 Related Work\\nDynamic task graphs. Ray is closely related to\\nCIEL [40] and Dask [ 48]. All three support dynamic\\ntask graphs with nested tasks and implement the futures\\nabstraction. CIEL also provides lineage-based fault toler-\\nance, while Dask, like Ray, fully integrates with Python.\\nHowever, Ray differs in two aspects that have important\\nperformance consequences. First, Ray extends the task\\nmodel with an actor abstraction. This is necessary for\\nefﬁcient stateful computation in distributed training and\\nserving, to keep the model data collocated with the com-\\nputation. Second, Ray employs a fully distributed and de-\\ncoupled control plane and scheduler, instead of relying on\\na single master storing all metadata. This is critical for ef-\\nﬁciently supporting primitives like allreduce without sys-\\ntem modiﬁcation. At peak performance for 100MB on 16\\nnodes, allreduce on Ray (Section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. Meanwhile, Dask reports a maxi-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tem modiﬁcation. At peak performance for 100MB on 16\\nnodes, allreduce on Ray (Section 5.1) submits 32 rounds\\nof 16 tasks in 200ms. Meanwhile, Dask reports a maxi-\\nmum scheduler throughput of 3k tasks/s on 512 cores [3].\\nWith a centralized scheduler, each round of allreduce\\nwould then incur a minimum of ∼5ms of scheduling\\ndelay, translating to up to2×worse completion time (Fig-\\nure 12b). Even with a decentralized scheduler, coupling\\nthe control plane information with the scheduler leaves\\nthe latter on the critical path for data transfer, adding an\\nextra roundtrip to every round of allreduce.\\nDataﬂow systems. Popular dataﬂow systems, such\\nas MapReduce [ 20], Spark [ 65], and Dryad [ 28] have\\nwidespread adoption for analytics and ML workloads,\\nbut their computation model is too restrictive for a ﬁne-\\ngrained and dynamic simulation workload. Spark and\\nMapReduce implement the BSP execution model, which\\nassumes that tasks within the same stage perform the'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='grained and dynamic simulation workload. Spark and\\nMapReduce implement the BSP execution model, which\\nassumes that tasks within the same stage perform the\\nsame computation and take roughly the same amount of\\ntime. Dryad relaxes this restriction but lacks support for\\ndynamic task graphs. Furthermore, none of these systems\\nprovide an actor abstraction, nor implement a distributed\\nscalable control plane and scheduler. Finally, Naiad [39]\\nis a dataﬂow system that provides improved scalability\\nfor some workloads, but only supports static task graphs.\\nMachine learning frameworks. TensorFlow [7] and\\nMXNet [ 18] target deep learning workloads and efﬁ-\\nciently leverage both CPUs and GPUs. While they\\nachieve great performance for training workloads consist-\\ning of static DAGs of linear algebra operations, they have\\nlimited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. TensorFlow Fold [33] provides some support for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='limited support for the more general computation required\\nto tightly couple training with simulation and embedded\\nserving. TensorFlow Fold [33] provides some support for\\ndynamic task graphs, as well as MXNet through its inter-\\nnal C++ APIs, but neither fully supports the ability to mod-\\nify the DAG during execution in response to task progress,\\ntask completion times, or faults. TensorFlow and MXNet\\nin principle achieve generality by allowing the program-\\nmer to simulate low-level message-passing and synchro-\\nnization primitives, but the pitfalls and user experience in\\nthis case are similar to those of MPI. OpenMPI [22] can\\nachieve high performance, but it is relatively hard to pro-\\ngram as it requires explicit coordination to handle hetero-\\ngeneous and dynamic task graphs. Furthermore, it forces\\nthe programmer to explicitly handle fault tolerance.\\nActor systems. Orleans [14] and Akka [1] are two ac-\\ntor frameworks well suited to developing highly available'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the programmer to explicitly handle fault tolerance.\\nActor systems. Orleans [14] and Akka [1] are two ac-\\ntor frameworks well suited to developing highly available\\nand concurrent distributed systems. However, compared\\nto Ray, they provide less support for recovery from data\\nloss. To recover stateful actors, the Orleans developer\\nmust explicitly checkpoint actor state and intermediate re-\\nsponses. Stateless actors in Orleans can be replicated for\\nscale-out, and could therefore act as tasks, but unlike in\\nRay, they have no lineage. Similarly, while Akka explic-\\nitly supports persisting actor state across failures, it does\\nnot provide efﬁcient fault tolerance for stateless computa-\\ntion (i.e., tasks). For message delivery, Orleans provides\\nat-least-once and Akka provides at-most-once semantics.\\nIn contrast, Ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe GCS and both arguments and results are immutable.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='In contrast, Ray provides transparent fault tolerance and\\nexactly-once semantics, as each method call is logged in\\nthe GCS and both arguments and results are immutable.\\nWe ﬁnd that in practice these limitations do not affect the\\nperformance of our applications. Erlang [10] and C++ Ac-\\ntor Framework [17], two other actor-based systems, have\\nsimilarly limited support for fault tolerance.\\nGlobal control store and scheduling. The concept\\nof logically centralizing the control plane has been pre-\\nviously proposed in software deﬁned networks (SDNs)\\n[16], distributed ﬁle systems (e.g., GFS [ 23]), resource\\nmanagement (e.g., Omega [52]), and distributed frame-\\nworks (e.g., MapReduce [ 20], BOOM [ 9]), to name a\\nfew. Ray draws inspiration from these pioneering efforts,\\nbut provides signiﬁcant improvements. In contrast with\\nSDNs, BOOM, and GFS, Ray decouples the storage of\\nthe control plane information (e.g., GCS) from the logic\\nimplementation (e.g., schedulers). This allows both stor-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='SDNs, BOOM, and GFS, Ray decouples the storage of\\nthe control plane information (e.g., GCS) from the logic\\nimplementation (e.g., schedulers). This allows both stor-\\nage and computation layers to scale independently, which\\nis key to achieving our scalability targets. Omega uses\\na distributed architecture in which schedulers coordinate\\nvia globally shared state. To this architecture, Ray adds\\nglobal schedulers to balance load across local schedulers,\\nand targets ms-level, not second-level, task scheduling.\\nRay implements a unique distributed bottom-up sched-\\nuler that is horizontally scalable, and can handle dynami-\\ncally constructed task graphs. Unlike Ray, most existing\\ncluster computing systems [20, 64, 40] use a centralized\\nscheduler architecture. While Sparrow [45] is decentral-\\nized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. Mesos [ 26] im-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='ized, its schedulers make independent decisions, limiting\\nthe possible scheduling policies, and all tasks of a job are\\nhandled by the same global scheduler. Mesos [ 26] im-\\nplements a two-level hierarchical scheduler, but its top-\\nlevel scheduler manages frameworks, not individual tasks.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Canary [47] achieves impressive performance by having\\neach scheduler instance handle a portion of the task graph,\\nbut does not handle dynamic computation graphs.\\nCilk [12] is a parallel programming language whose\\nwork-stealing scheduler achieves provably efﬁcient load-\\nbalancing for dynamic task graphs. However, with no cen-\\ntral coordinator like Ray’s global scheduler, this fully par-\\nallel design is also difﬁcult to extend to support data lo-\\ncality and resource heterogeneity in a distributed setting.\\n7 Discussion and Experiences\\nBuilding Ray has been a long journey. It started two years\\nago with a Spark library to perform distributed training\\nand simulations. However, the relative inﬂexibility of the\\nBSP model, the high per-task overhead, and the lack of an\\nactor abstraction led us to develop a new system. Since we\\nreleased Ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. Here we discuss our experience developing'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='released Ray roughly one year ago, several hundreds of\\npeople have used it and several companies are running it\\nin production. Here we discuss our experience developing\\nand using Ray, and some early user feedback.\\nAPI. In designing the API, we have emphasized mini-\\nmalism. Initially we started with a basic task abstraction.\\nLater, we added the wait() primitive to accommodate roll-\\nouts with heterogeneous durations and the actor abstrac-\\ntion to accommodate third-party simulators and amortize\\nthe overhead of expensive initializations. While the re-\\nsulting API is relatively low-level, it has proven both pow-\\nerful and simple to use. We have already used this API to\\nimplement many state-of-the-art RL algorithms on top of\\nRay, including A3C [36], PPO [51], DQN [37], ES [49],\\nDDPG [55], and Ape-X [ 27]. In most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nRay. Based on early user feedback, we are considering'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='DDPG [55], and Ape-X [ 27]. In most cases it took us\\njust a few tens of lines of code to port these algorithms to\\nRay. Based on early user feedback, we are considering\\nenhancing the API to include higher level primitives and\\nlibraries, which could also inform scheduling decisions.\\nLimitations. Given the workload generality, special-\\nized optimizations are hard. For example, we must make\\nscheduling decisions without full knowledge of the com-\\nputation graph. Scheduling optimizations in Ray might\\nrequire more complex runtime proﬁling. In addition, stor-\\ning lineage for each task requires the implementation of\\ngarbage collection policies to bound storage costs in the\\nGCS, a feature we are actively developing.\\nFault tolerance. We are often asked if fault tolerance\\nis really needed for AI applications. After all, due to the\\nstatistical nature of many AI algorithms, one could sim-\\nply ignore failed rollouts. Based on our experience, our'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='is really needed for AI applications. After all, due to the\\nstatistical nature of many AI algorithms, one could sim-\\nply ignore failed rollouts. Based on our experience, our\\nanswer is “yes”. First, the ability to ignore failures makes\\napplications much easier to write and reason about. Sec-\\nond, our particular implementation of fault tolerance via\\ndeterministic replay dramatically simpliﬁes debugging as\\nit allows us to easily reproduce most errors. This is par-\\nticularly important since, due to their stochasticity, AI al-\\ngorithms are notoriously hard to debug. Third, fault toler-\\nance helps save money since it allows us to run on cheap\\nresources like spot instances on AWS. Of course, this\\ncomes at the price of some overhead. However, we found\\nthis overhead to be minimal for our target workloads.\\nGCS and Horizontal Scalability. The GCS dramati-\\ncally simpliﬁed Ray development and debugging. It en-\\nabled us to query the entire system state while debugging'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='GCS and Horizontal Scalability. The GCS dramati-\\ncally simpliﬁed Ray development and debugging. It en-\\nabled us to query the entire system state while debugging\\nRay itself, instead of having to manually expose internal\\ncomponent state. In addition, the GCS is also the backend\\nfor our timeline visualization tool, used for application-\\nlevel debugging.\\nThe GCS was also instrumental to Ray’s horizontal\\nscalability. In Section 5, we were able to scale by adding\\nmore shards whenever the GCS became a bottleneck. The\\nGCS also enabled the global scheduler to scale by sim-\\nply adding more replicas. Due to these advantages, we\\nbelieve that centralizing control state will be a key design\\ncomponent of future distributed systems.\\n8 Conclusion\\nNo general-purpose system today can efﬁciently support\\nthe tight loop of training, serving, and simulation. To ex-\\npress these core building blocks and meet the demands of\\nemerging AI applications, Ray uniﬁes task-parallel and'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='the tight loop of training, serving, and simulation. To ex-\\npress these core building blocks and meet the demands of\\nemerging AI applications, Ray uniﬁes task-parallel and\\nactor programming models in a single dynamic task graph\\nand employs a scalable architecture enabled by the global\\ncontrol store and a bottom-up distributed scheduler. The\\nprogramming ﬂexibility, high throughput, and low laten-\\ncies simultaneously achieved by this architecture is partic-\\nularly important for emerging artiﬁcial intelligence work-\\nloads, which produce tasks diverse in their resource re-\\nquirements, duration, and functionality. Our evaluation\\ndemonstrates linear scalability up to 1.8 million tasks per\\nsecond, transparent fault tolerance, and substantial perfor-\\nmance improvements on several contemporary RL work-\\nloads. Thus, Ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future AI applications.\\n9 Acknowledgments'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='loads. Thus, Ray provides a powerful combination of ﬂex-\\nibility, performance, and ease of use for the development\\nof future AI applications.\\n9 Acknowledgments\\nThis research is supported in part by NSF CISE Expedi-\\ntions Award CCF-1730628 and gifts from Alibaba, Ama-\\nzon Web Services, Ant Financial, Arm, CapitalOne, Eric-\\nsson, Facebook, Google, Huawei, Intel, Microsoft, Sco-\\ntiabank, Splunk and VMware as well as by NSF grant\\nDGE-1106400. We are grateful to our anonymous review-\\ners and our shepherd, Miguel Castro, for thoughtful feed-\\nback, which helped improve the quality of this paper.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Akka. https://akka.io/.\\n[2] Apache Arrow. https://arrow.apache.org/.\\n[3] Dask Benchmarks. http://matthewrocklin.com/blog/\\nwork/2017/07/03/scaling.\\n[4] EC2 Instance Pricing. https://aws.amazon.com/ec2/\\npricing/on-demand/.\\n[5] OpenAI Baselines: high-quality implementations of reinforce-\\nment learning algorithms. https://github.com/openai/\\nbaselines.\\n[6] TensorFlow Serving. https://www.tensorflow.org/\\nserving/.\\n[7] ABADI , M., B ARHAM , P., C HEN , J., C HEN , Z., D AVIS, A.,\\nDEAN , J., D EVIN , M., G HEMAWAT, S., I RVING , G., I SARD , M.,\\nET AL . TensorFlow: A system for large-scale machine learning.\\nIn Proceedings of the 12th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI). Savannah, Georgia,\\nUSA (2016).\\n[8] A GARWAL , A., B IRD , S., C OZOWICZ , M., H OANG , L., L ANG -\\nFORD , J., L EE, S., L I, J., M ELAMED , D., O SHRI , G., R IBAS ,\\nO., S EN, S., AND SLIVKINS , A. A multiworld testing decision\\nservice. arXiv preprint arXiv:1606.03966 (2016).'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='FORD , J., L EE, S., L I, J., M ELAMED , D., O SHRI , G., R IBAS ,\\nO., S EN, S., AND SLIVKINS , A. A multiworld testing decision\\nservice. arXiv preprint arXiv:1606.03966 (2016).\\n[9] ALVARO, P., C ONDIE , T., C ONWAY, N., E LMELEEGY , K.,\\nHELLERSTEIN , J. M., AND SEARS , R. BOOM Analytics: ex-\\nploring data-centric, declarative programming for the cloud. In\\nProceedings of the 5th European conference on Computer systems\\n(2010), ACM, pp. 223–236.\\n[10] ARMSTRONG , J., V IRDING , R., W IKSTR ¨OM, C., AND\\nWILLIAMS , M. Concurrent programming in ERLANG.\\n[11] BEATTIE , C., L EIBO , J. Z., T EPLYASHIN , D., W ARD , T.,\\nWAINWRIGHT , M., K ¨UTTLER , H., L EFRANCQ , A., G REEN , S.,\\nVALD ´ES, V., SADIK , A., ET AL . DeepMind Lab. arXiv preprint\\narXiv:1612.03801 (2016).\\n[12] BLUMOFE , R. D., AND LEISERSON , C. E. Scheduling mul-\\ntithreaded computations by work stealing. J. ACM 46, 5 (Sept.\\n1999), 720–748.\\n[13] B ROCKMAN , G., C HEUNG , V., PETTERSSON , L., S CHNEIDER ,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='tithreaded computations by work stealing. J. ACM 46, 5 (Sept.\\n1999), 720–748.\\n[13] B ROCKMAN , G., C HEUNG , V., PETTERSSON , L., S CHNEIDER ,\\nJ., S CHULMAN , J., T ANG , J., AND ZAREMBA , W. OpenAI gym.\\narXiv preprint arXiv:1606.01540 (2016).\\n[14] BYKOV, S., G ELLER , A., K LIOT , G., L ARUS , J. R., P ANDYA ,\\nR., AND THELIN , J. Orleans: Cloud computing for everyone. In\\nProceedings of the 2nd ACM Symposium on Cloud Computing\\n(2011), ACM, p. 16.\\n[15] CARBONE , P., E WEN , S., F ´ORA , G., H ARIDI , S., R ICHTER ,\\nS., AND TZOUMAS , K. State management in Apache Flink:\\nConsistent stateful distributed stream processing. Proc. VLDB\\nEndow. 10, 12 (Aug. 2017), 1718–1729.\\n[16] CASADO , M., F REEDMAN , M. J., P ETTIT , J., L UO, J., M CKE-\\nOWN , N., AND SHENKER , S. Ethane: Taking control of the enter-\\nprise. SIGCOMM Comput. Commun. Rev. 37, 4 (Aug. 2007), 1–12.\\n[17] CHAROUSSET , D., S CHMIDT , T. C., H IESGEN , R., AND\\nW ¨AHLISCH , M. Native actors: A scalable software platform for'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='prise. SIGCOMM Comput. Commun. Rev. 37, 4 (Aug. 2007), 1–12.\\n[17] CHAROUSSET , D., S CHMIDT , T. C., H IESGEN , R., AND\\nW ¨AHLISCH , M. Native actors: A scalable software platform for\\ndistributed, heterogeneous environments. In Proceedings of the\\n2013 workshop on Programming based on actors, agents, and de-\\ncentralized control (2013), ACM, pp. 87–96.\\n[18] CHEN , T., L I, M., L I, Y., L IN, M., W ANG , N., W ANG , M.,\\nXIAO , T., X U, B., Z HANG , C., AND ZHANG , Z. MXNet: A\\nﬂexible and efﬁcient machine learning library for heterogeneous\\ndistributed systems. In NIPS Workshop on Machine Learning\\nSystems (LearningSys’16)(2016).\\n[19] CRANKSHAW , D., W ANG , X., Z HOU , G., F RANKLIN , M. J.,\\nGONZALEZ , J. E., AND STOICA , I. Clipper: A low-latency\\nonline prediction serving system. In 14th USENIX Symposium\\non Networked Systems Design and Implementation (NSDI 17)\\n(Boston, MA, 2017), USENIX Association, pp. 613–627.\\n[20] DEAN , J., AND GHEMAWAT, S. MapReduce: Simpliﬁed data'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='on Networked Systems Design and Implementation (NSDI 17)\\n(Boston, MA, 2017), USENIX Association, pp. 613–627.\\n[20] DEAN , J., AND GHEMAWAT, S. MapReduce: Simpliﬁed data\\nprocessing on large clusters. Commun. ACM 51, 1 (Jan. 2008),\\n107–113.\\n[21] DENNIS , J. B., AND MISUNAS , D. P. A preliminary architecture\\nfor a basic data-ﬂow processor. In Proceedings of the 2Nd An-\\nnual Symposium on Computer Architecture (New York, NY , USA,\\n1975), ISCA ’75, ACM, pp. 126–132.\\n[22] GABRIEL , E., F AGG , G. E., B OSILCA , G., A NGSKUN , T., D ON-\\nGARRA , J. J., S QUYRES , J. M., S AHAY, V., K AMBADUR , P.,\\nBARRETT , B., L UMSDAINE , A., C ASTAIN , R. H., D ANIEL ,\\nD. J., G RAHAM , R. L., AND WOODALL , T. S. Open MPI: Goals,\\nconcept, and design of a next generation MPI implementation. In\\nProceedings, 11th European PVM/MPI Users’ Group Meeting\\n(Budapest, Hungary, September 2004), pp. 97–104.\\n[23] GHEMAWAT, S., G OBIOFF , H., AND LEUNG , S.-T. The Google\\nﬁle system. 29–43.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Proceedings, 11th European PVM/MPI Users’ Group Meeting\\n(Budapest, Hungary, September 2004), pp. 97–104.\\n[23] GHEMAWAT, S., G OBIOFF , H., AND LEUNG , S.-T. The Google\\nﬁle system. 29–43.\\n[24] GONZALEZ , J. E., X IN, R. S., D AVE, A., C RANKSHAW , D.,\\nFRANKLIN , M. J., AND STOICA , I. GraphX: Graph processing\\nin a distributed dataﬂow framework. In Proceedings of the 11th\\nUSENIX Conference on Operating Systems Design and Implemen-\\ntation (Berkeley, CA, USA, 2014), OSDI’14, USENIX Associa-\\ntion, pp. 599–613.\\n[25] GU*, S., H OLLY *, E., L ILLICRAP , T., AND LEVINE , S. Deep re-\\ninforcement learning for robotic manipulation with asynchronous\\noff-policy updates. In IEEE International Conference on Robotics\\nand Automation (ICRA 2017) (2017).\\n[26] HINDMAN , B., K ONWINSKI , A., Z AHARIA , M., G HODSI , A.,\\nJOSEPH , A. D., K ATZ, R., S HENKER , S., AND STOICA , I.\\nMesos: A platform for ﬁne-grained resource sharing in the data\\ncenter. In Proceedings of the 8th USENIX Conference on Net-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='JOSEPH , A. D., K ATZ, R., S HENKER , S., AND STOICA , I.\\nMesos: A platform for ﬁne-grained resource sharing in the data\\ncenter. In Proceedings of the 8th USENIX Conference on Net-\\nworked Systems Design and Implementation (Berkeley, CA, USA,\\n2011), NSDI’11, USENIX Association, pp. 295–308.\\n[27] HORGAN , D., Q UAN , J., B UDDEN , D., B ARTH -MARON , G.,\\nHESSEL , M., VAN HASSELT , H., AND SILVER , D. Distributed\\nprioritized experience replay. International Conference on Learn-\\ning Representations (2018).\\n[28] ISARD , M., B UDIU , M., Y U, Y., B IRRELL , A., AND FETTERLY ,\\nD. Dryad: Distributed data-parallel programs from sequential\\nbuilding blocks. In Proceedings of the 2nd ACM SIGOPS/EuroSys\\nEuropean Conference on Computer Systems 2007 (New York, NY ,\\nUSA, 2007), EuroSys ’07, ACM, pp. 59–72.\\n[29] JIA, Y., SHELHAMER , E., D ONAHUE , J., K ARAYEV, S., L ONG ,\\nJ., G IRSHICK , R., G UADARRAMA , S., AND DARRELL , T. Caffe:\\nConvolutional architecture for fast feature embedding. arXiv'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[29] JIA, Y., SHELHAMER , E., D ONAHUE , J., K ARAYEV, S., L ONG ,\\nJ., G IRSHICK , R., G UADARRAMA , S., AND DARRELL , T. Caffe:\\nConvolutional architecture for fast feature embedding. arXiv\\npreprint arXiv:1408.5093 (2014).\\n[30] JORDAN , M. I., AND MITCHELL , T. M. Machine learning:\\nTrends, perspectives, and prospects. Science 349, 6245 (2015),\\n255–260.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[31] LEIBIUSKY , J., E ISBRUCH , G., AND SIMONASSI , D. Getting\\nStarted with Storm. O’Reilly Media, Inc., 2012.\\n[32] LI, M., A NDERSEN , D. G., P ARK , J. W., S MOLA , A. J.,\\nAHMED , A., J OSIFOVSKI , V., LONG , J., S HEKITA , E. J., AND\\nSU, B.-Y. Scaling distributed machine learning with the parame-\\nter server. In Proceedings of the 11th USENIX Conference on Op-\\nerating Systems Design and Implementation (Berkeley, CA, USA,\\n2014), OSDI’14, pp. 583–598.\\n[33] L OOKS , M., H ERRESHOFF , M., H UTCHINS , D., AND NORVIG ,\\nP. Deep learning with dynamic computation graphs.arXiv preprint\\narXiv:1702.02181 (2017).\\n[34] LOW, Y., G ONZALEZ , J., K YROLA , A., B ICKSON , D.,\\nGUESTRIN , C., AND HELLERSTEIN , J. GraphLab: A new frame-\\nwork for parallel machine learning. In Proceedings of the Twenty-\\nSixth Conference on Uncertainty in Artiﬁcial Intelligence (Arling-\\nton, Virginia, United States, 2010), UAI’10, pp. 340–349.\\n[35] MALEWICZ , G., A USTERN , M. H., B IK, A. J., D EHNERT , J. C.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Sixth Conference on Uncertainty in Artiﬁcial Intelligence (Arling-\\nton, Virginia, United States, 2010), UAI’10, pp. 340–349.\\n[35] MALEWICZ , G., A USTERN , M. H., B IK, A. J., D EHNERT , J. C.,\\nHORN , I., L EISER , N., AND CZAJKOWSKI , G. Pregel: A system\\nfor large-scale graph processing. In Proceedings of the 2010 ACM\\nSIGMOD International Conference on Management of Data(New\\nYork, NY , USA, 2010), SIGMOD ’10, ACM, pp. 135–146.\\n[36] MNIH , V., BADIA , A. P., M IRZA , M., G RAVES , A., L ILLICRAP ,\\nT. P., HARLEY , T., S ILVER , D., AND KAVUKCUOGLU , K. Asyn-\\nchronous methods for deep reinforcement learning. In Interna-\\ntional Conference on Machine Learning (2016).\\n[37] MNIH , V., K AVUKCUOGLU , K., S ILVER , D., R USU , A. A.,\\nVENESS , J., B ELLEMARE , M. G., G RAVES , A., R IEDMILLER ,\\nM., F IDJELAND , A. K., O STROVSKI , G., ET AL . Human-level\\ncontrol through deep reinforcement learning. Nature 518, 7540\\n(2015), 529–533.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='M., F IDJELAND , A. K., O STROVSKI , G., ET AL . Human-level\\ncontrol through deep reinforcement learning. Nature 518, 7540\\n(2015), 529–533.\\n[38] MURRAY, D. A Distributed Execution Engine Supporting Data-\\ndependent Control Flow. University of Cambridge, 2012.\\n[39] MURRAY, D. G., M CSHERRY, F., I SAACS , R., I SARD , M.,\\nBARHAM , P., AND ABADI , M. Naiad: A timely dataﬂow system.\\nIn Proceedings of the Twenty-Fourth ACM Symposium on Operat-\\ning Systems Principles (New York, NY , USA, 2013), SOSP ’13,\\nACM, pp. 439–455.\\n[40] MURRAY, D. G., S CHWARZKOPF , M., S MOWTON , C., S MITH ,\\nS., M ADHAVAPEDDY , A., AND HAND , S. CIEL: A universal exe-\\ncution engine for distributed data-ﬂow computing. In Proceedings\\nof the 8th USENIX Conference on Networked Systems Design and\\nImplementation (Berkeley, CA, USA, 2011), NSDI’11, USENIX\\nAssociation, pp. 113–126.\\n[41] NAIR , A., S RINIVASAN , P., B LACKWELL , S., A LCICEK , C.,\\nFEARON , R., M ARIA , A. D., P ANNEERSHELVAM , V., SULEY -'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Association, pp. 113–126.\\n[41] NAIR , A., S RINIVASAN , P., B LACKWELL , S., A LCICEK , C.,\\nFEARON , R., M ARIA , A. D., P ANNEERSHELVAM , V., SULEY -\\nMAN , M., B EATTIE , C., P ETERSEN , S., L EGG , S., M NIH , V.,\\nKAVUKCUOGLU , K., AND SILVER , D. Massively parallel meth-\\nods for deep reinforcement learning, 2015.\\n[42] NG, A., C OATES , A., D IEL , M., G ANAPATHI , V., S CHULTE , J.,\\nTSE, B., B ERGER , E., AND LIANG , E. Autonomous inverted he-\\nlicopter ﬂight via reinforcement learning. Experimental Robotics\\nIX (2006), 363–372.\\n[43] NISHIHARA , R., M ORITZ , P., WANG , S., T UMANOV , A., P AUL ,\\nW., SCHLEIER -SMITH , J., L IAW, R., N IKNAMI , M., J ORDAN ,\\nM. I., AND STOICA , I. Real-time machine learning: The missing\\npieces. In Workshop on Hot Topics in Operating Systems(2017).\\n[44] OPEN AI. OpenAI Dota 2 1v1 bot. https://openai.com/\\nthe-international/, 2017.\\n[45] OUSTERHOUT , K., W ENDELL , P., Z AHARIA , M., AND STOICA ,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[44] OPEN AI. OpenAI Dota 2 1v1 bot. https://openai.com/\\nthe-international/, 2017.\\n[45] OUSTERHOUT , K., W ENDELL , P., Z AHARIA , M., AND STOICA ,\\nI. Sparrow: Distributed, low latency scheduling. In Proceedings\\nof the Twenty-Fourth ACM Symposium on Operating Systems\\nPrinciples (New York, NY , USA, 2013), SOSP ’13, ACM, pp. 69–\\n84.\\n[46] PASZKE , A., G ROSS , S., C HINTALA , S., C HANAN , G., Y ANG ,\\nE., D EVITO , Z., L IN, Z., D ESMAISON , A., A NTIGA , L., AND\\nLERER , A. Automatic differentiation in PyTorch.\\n[47] QU, H., M ASHAYEKHI , O., T EREI , D., AND LEVIS , P. Canary:\\nA scheduling architecture for high performance cloud computing.\\narXiv preprint arXiv:1602.01412 (2016).\\n[48] ROCKLIN , M. Dask: Parallel computation with blocked algo-\\nrithms and task scheduling. In Proceedings of the 14th Python in\\nScience Conference (2015), K. Huff and J. Bergstra, Eds., pp. 130\\n– 136.\\n[49] S ALIMANS , T., H O, J., C HEN , X., AND SUTSKEVER , I. Evolu-'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Science Conference (2015), K. Huff and J. Bergstra, Eds., pp. 130\\n– 136.\\n[49] S ALIMANS , T., H O, J., C HEN , X., AND SUTSKEVER , I. Evolu-\\ntion strategies as a scalable alternative to reinforcement learning.\\narXiv preprint arXiv:1703.03864 (2017).\\n[50] SANFILIPPO , S. Redis: An open source, in-memory data structure\\nstore. https://redis.io/, 2009.\\n[51] SCHULMAN , J., W OLSKI , F., D HARIWAL , P., R ADFORD , A.,\\nAND KLIMOV, O. Proximal policy optimization algorithms. arXiv\\npreprint arXiv:1707.06347 (2017).\\n[52] SCHWARZKOPF , M., K ONWINSKI , A., A BD-EL-MALEK , M.,\\nAND WILKES , J. Omega: Flexible, scalable schedulers for large\\ncompute clusters. In Proceedings of the 8th ACM European Con-\\nference on Computer Systems (New York, NY , USA, 2013), Eu-\\nroSys ’13, ACM, pp. 351–364.\\n[53] SERGEEV , A., AND DEL BALSO , M. Horovod: fast and\\neasy distributed deep learning in tensorﬂow. arXiv preprint\\narXiv:1802.05799 (2018).\\n[54] SILVER , D., H UANG , A., M ADDISON , C. J., G UEZ , A.,'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='easy distributed deep learning in tensorﬂow. arXiv preprint\\narXiv:1802.05799 (2018).\\n[54] SILVER , D., H UANG , A., M ADDISON , C. J., G UEZ , A.,\\nSIFRE , L., V AN DEN DRIESSCHE , G., S CHRITTWIESER , J.,\\nANTONOGLOU , I., P ANNEERSHELVAM , V., L ANCTOT , M.,\\nET AL . Mastering the game of Go with deep neural networks and\\ntree search. Nature 529, 7587 (2016), 484–489.\\n[55] SILVER , D., L EVER , G., H EESS , N., D EGRIS , T., W IERSTRA ,\\nD., AND RIEDMILLER , M. Deterministic policy gradient algo-\\nrithms. In ICML (2014).\\n[56] SUTTON , R. S., AND BARTO , A. G. Reinforcement Learning:\\nAn Introduction. MIT press Cambridge, 1998.\\n[57] THAKUR , R., R ABENSEIFNER , R., AND GROPP, W. Optimiza-\\ntion of collective communication operations in MPICH. The Inter-\\nnational Journal of High Performance Computing Applications\\n19, 1 (2005), 49–66.\\n[58] TIAN , Y., GONG , Q., S HANG , W., W U, Y., AND ZITNICK , C. L.\\nELF: An extensive, lightweight and ﬂexible research platform'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='19, 1 (2005), 49–66.\\n[58] TIAN , Y., GONG , Q., S HANG , W., W U, Y., AND ZITNICK , C. L.\\nELF: An extensive, lightweight and ﬂexible research platform\\nfor real-time strategy games. Advances in Neural Information\\nProcessing Systems (NIPS) (2017).\\n[59] TODOROV , E., E REZ , T., AND TASSA , Y. Mujoco: A physics\\nengine for model-based control. In Intelligent Robots and Systems\\n(IROS), 2012 IEEE/RSJ International Conference on(2012), IEEE,\\npp. 5026–5033.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='[60] VAN DEN BERG , J., M ILLER , S., D UCKWORTH , D., H U, H.,\\nWAN, A., F U, X.-Y., G OLDBERG , K., AND ABBEEL , P. Su-\\nperhuman performance of surgical tasks by robots using iterative\\nlearning from human-guided demonstrations. In Robotics and Au-\\ntomation (ICRA), 2010 IEEE International Conference on (2010),\\nIEEE, pp. 2074–2081.\\n[61] VAN RENESSE , R., AND SCHNEIDER , F. B. Chain replication for\\nsupporting high throughput and availability. In Proceedings of the\\n6th Conference on Symposium on Opearting Systems Design &\\nImplementation - Volume 6 (Berkeley, CA, USA, 2004), OSDI’04,\\nUSENIX Association.\\n[62] VENKATARAMAN , S., P ANDA , A., O USTERHOUT , K., G HODSI ,\\nA., A RMBRUST , M., R ECHT , B., F RANKLIN , M., AND STOICA ,\\nI. Drizzle: Fast and adaptable stream processing at scale. In\\nProceedings of the Twenty-Sixth ACM Symposium on Operating\\nSystems Principles (2017), SOSP ’17, ACM.\\n[63] WHITE , T. Hadoop: The Deﬁnitive Guide. O’Reilly Media, Inc.,\\n2012.'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.17', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-10-02T00:16:18+00:00', 'author': '', 'keywords': '', 'moddate': '2018-10-02T00:16:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.17 (TeX Live 2016) kpathsea version 6.2.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': '..\\\\data\\\\pdf\\\\ray-distributed-framework-AI-app.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17', 'source_file': 'ray-distributed-framework-AI-app.pdf', 'file_type': 'pdf'}, page_content='Proceedings of the Twenty-Sixth ACM Symposium on Operating\\nSystems Principles (2017), SOSP ’17, ACM.\\n[63] WHITE , T. Hadoop: The Deﬁnitive Guide. O’Reilly Media, Inc.,\\n2012.\\n[64] ZAHARIA , M., C HOWDHURY , M., D AS, T., D AVE, A., M A, J.,\\nMCCAULEY, M., F RANKLIN , M. J., S HENKER , S., AND STO-\\nICA , I. Resilient distributed datasets: A fault-tolerant abstrac-\\ntion for in-memory cluster computing. In Proceedings of the 9th\\nUSENIX conference on Networked Systems Design and Implemen-\\ntation (2012), USENIX Association, pp. 2–2.\\n[65] ZAHARIA , M., X IN, R. S., W ENDELL , P., DAS, T., A RMBRUST ,\\nM., D AVE, A., M ENG , X., R OSEN , J., V ENKATARAMAN , S.,\\nFRANKLIN , M. J., G HODSI , A., G ONZALEZ , J., S HENKER , S.,\\nAND STOICA , I. Apache Spark: A uniﬁed engine for big data\\nprocessing. Commun. ACM 59, 11 (Oct. 2016), 56–65.'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Scaling Transformer-Based Novel View Synthesis Models with\\nToken Disentanglement and Synthetic Data\\nNithin Gopalakrishnan Nair1∗ Srinivas Kaza2∗ Xuan Luo2 Vishal M. Patel1\\nStephen Lombardi2 Jungyeon Park2\\n1 Johns Hopkins University 2 Google\\n{ngopala2,vpatel36}@jhu.edu{srinivaskaza,xuluo,salombardi,jungyeonp}@google.com\\nhttps://scaling3dnvs.github.io\\nLVSM\\nOURS\\nLVSM\\nOURS\\nLVSM\\nOURS\\nFigure 1.Overview.Our method performs feed-forward novel-view synthesis from a series of input images, such as the pairs shown\\nabove. We demonstrate strong results in terms of quality and generalization capacity, performing well across a variety of common novel-\\nview synthesis datasets, including scenes that are out-of-distribution.\\nAbstract\\nLarge transformer-based models have made significant\\nprogress in generalizable novel view synthesis (NVS) from\\nsparse input views, generating novel viewpoints without the\\nneed for test-time optimization. However, these models'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 0, 'page_label': '1', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='progress in generalizable novel view synthesis (NVS) from\\nsparse input views, generating novel viewpoints without the\\nneed for test-time optimization. However, these models\\nare constrained by the limited diversity of publicly avail-\\nable scene datasets, making most real-world (in-the-wild)\\nscenes out-of-distribution. To overcome this, we incorpo-\\nrate synthetic training data generated from diffusion mod-\\nels, which improves generalization across unseen domains.\\nWhile synthetic data offers scalability, we identify artifacts\\nintroduced during data generation as a key bottleneck af-\\nfecting reconstruction quality. To address this, we propose\\na token disentanglement process within the transformer ar-\\nchitecture, enhancing feature separation and ensuring more\\neffective learning. This refinement not only improves re-\\narXiv:2509.06950v1  [cs.GR]  8 Sep 2025'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='construction quality over standard transformers but also\\nenables scalable training with synthetic data. As a result,\\nour method outperforms existing models on both in-dataset\\nand cross-dataset evaluations, achieving state-of-the-art re-\\nsults across multiple benchmarks while significantly reduc-\\ning computational costs.\\n1. Introduction\\nNovel view synthesis (NVS) [20, 27] is a well-studied and\\nimportant problem in computer vision, where the task is to\\ngenerate unseen perspectives of a scene from a given set of\\nimages. Many approaches utilize volumetric [2, 5, 27, 28]\\nor differentiable rendering [20] to optimize for each scene\\nindividually, achieving high-quality NVS from arbitrary\\nviewpoints. More recently, advancements have enabled\\ntraining a single model that generalizes to novel scenes\\nwithout requiring per-scene optimization. Most existing\\nmethods address NVS by incorporating hand-crafted 3D\\npriors and architectural biases [4, 16, 39]. While these de-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='without requiring per-scene optimization. Most existing\\nmethods address NVS by incorporating hand-crafted 3D\\npriors and architectural biases [4, 16, 39]. While these de-\\nsign choices provide structure, they limit scalability with\\ndata and hinder generalization.\\nRecently, Large View Synthesis Model (LVSM) [19]\\nproposed a promising foundation for an NVS model scal-\\nable with large datasets. LVSM introduces an architec-\\nture that doesn’t require 3D inductive biases for scene re-\\nconstruction. It employs a decoder-only transformer ar-\\nchitecture that achieves state-of-the-art results by a sig-\\nnificant margin, with the performance improving with in-\\ncreased compute. However, we observed during our exper-\\niments that the decoder-only design causes an inherent fea-\\nture alignment problem which causes the target and source\\nfeatures to look similar at all layers. Thus, part of the trans-\\nformer’s computational capacity is spent modifying source'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ture alignment problem which causes the target and source\\nfeatures to look similar at all layers. Thus, part of the trans-\\nformer’s computational capacity is spent modifying source\\ntoken information that is ultimately discarded at the end\\nof the transformer block, reducing efficiency. This design\\nchoice also makes LVSM susceptible to unwanted noise\\nor compression artifacts that may be present in the source\\nviews. In addition, we noticed that LVSM presents limited\\ncross-domain performance when tested on datasets outside\\nthe training dataset domains.\\nMoreover, these issues are not unique to LVSM; many\\nNVS models face similar challenges due to data scarcity\\nin 3D vision. All existing multi-view 3D scene datasets\\n[24, 25, 49] combined contain fewer than 100,000 scenes,\\nseverely limiting the performance of NVS models on in-\\nthe-wild cases beyond the training distribution. One pos-\\nsible solution for alleviating this 3D data scarcity is using'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='severely limiting the performance of NVS models on in-\\nthe-wild cases beyond the training distribution. One pos-\\nsible solution for alleviating this 3D data scarcity is using\\nsynthetic data from generative models. Recent research has\\nexplored adapting pre-trained image [33, 34] and video dif-\\nfusion models [14, 15] for multi-view dataset generation\\n*Equal contribution. Nair designed the methodology, conducted pre-\\nrebuttal experiments, and drafted the initial manuscript. Kaza helped ad-\\nvise the project, led the rebuttal, and conducted camera-ready experiments.\\n[10, 26, 36, 44]. However, previous feed-forward mod-\\nels trained using synthetic data perform worse than those\\ntrained with real data. We hypothesize that the inability of\\nsynthetic data to improve reconstruction quality stems from\\ntwo types of degradation artifacts in scenes generated by\\ndiffusion models [15, 29, 38] (1) artifacts influenced by the\\ninitial noise of the diffusion process and (2) artifacts intro-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='two types of degradation artifacts in scenes generated by\\ndiffusion models [15, 29, 38] (1) artifacts influenced by the\\ninitial noise of the diffusion process and (2) artifacts intro-\\nduced during decoding, as most diffusion-based scene syn-\\nthesis models operate in latent space and rely on a diffusion\\nV AE [33]. We address both issues, leading to improved per-\\nformance when using synthetic data. We provide a detailed\\nexplanation of our data pipeline in Section 4.2.\\nIn this work, we tackle a key challenge in developing\\na feed-forward NVS model that performs well on out-of-\\ndistribution data – the need for a scalable and efficient\\ntransformer-based NVS architecture. We introduce the To-\\nken Distentangled (Tok-D) transformer block, which ap-\\nplies layer-wise modulation of source and target tokens, ex-\\nplicitly distinguishing the two at each layer. These model\\nmodifications improve out-of-distribution training, which\\nintroduces the possibility of training on synthetic data. We'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='plicitly distinguishing the two at each layer. These model\\nmodifications improve out-of-distribution training, which\\nintroduces the possibility of training on synthetic data. We\\nuse the CAT3D model to generate a large dataset of syn-\\nthetic multi-view samples. We then employ a novel data\\ngeneration strategy that significantly improves the quality\\nof these synthetic samples. We show that the Tok-D trans-\\nformer block can be trained with synthetic data augmenta-\\ntion, unlike the baseline LVSM method which suffers from\\nthe inclusion of synthetic data.\\n• We enhance the scalability of transformer architectures\\nfor NVS, enabling more efficient modeling.\\n• We introduce a new training scheme that is less suscepti-\\nble to artifacts from synthetic data.\\n• We improve the training efficiency of transformer for\\nNVS by introducing a new transformer block.\\n• Our approach achieves state-of-the-art results across mul-\\ntiple benchmarks for scene level NVS.\\n2. Related Works'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 1, 'page_label': '2', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='NVS by introducing a new transformer block.\\n• Our approach achieves state-of-the-art results across mul-\\ntiple benchmarks for scene level NVS.\\n2. Related Works\\n2.1. Offline Novel View Synthesis\\nThe advent of neural rendering in recent years has substan-\\ntially improved the quality of NVS. Early neural scene rep-\\nresentations focused on the 4D plenoptic function [11, 23]\\nthat represents the lightfield of a scene [1, 37, 39]. Other\\nmethods modeled the geometry of the scene (e.g. as a\\nsigned distance function) separately from material proper-\\nties [40, 45]. Either way, a differentiable rendering process\\nwas used to render these neural representations into 2D im-\\nages [27]. Most of these methods focused on fitting neu-\\nral fields to sparse observations of a scene at test time—\\nwe refer to this as test-time or offline optimization. There\\nis a substantial amount of heterogeneity in these methods,\\nboth in terms of the rendering method and the scene repre-\\n2'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Tok-D Transformer Blocks\\nSource Patchify Patchify\\nSource tokens\\nTarget tokens\\nMulti-View Diﬀusion Model\\n   Input View\\n                           Generated Views\\nSynthetic Data Generation NVS Model Training\\nUnPatchify\\nFigure 2.An illustration of the architecture.We use CAT3D, a multi-view diffusion model, to generate synthetic views conditioned on\\nrandom spline camera trajectories and a random image. From the two random views form the generated views as the source views and\\nthe input conditioning view to be the target of our large reconstruction network. Our large reconstruction model uses a special transformer\\nblock which we name Tok-D Transformer. When real data is available, we just use the reconstruction transformer.\\nsentation used. Multi-layer perceptrons (MLPs) [27], vox-\\nels [9, 26], hashing-based representations [3, 28], triplanes\\n[5], and, most recently, Gaussian splats [17, 20, 21, 31]\\nhave been used as scene representations. These meth-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='els [9, 26], hashing-based representations [3, 28], triplanes\\n[5], and, most recently, Gaussian splats [17, 20, 21, 31]\\nhave been used as scene representations. These meth-\\nods have trade-offs between reconstruction quality, training\\ntime, inference time, memory/space requirements, capacity\\nto model view-dependent effects, etc. Some of these offline\\nmethods can even fit dynamic scenes. These test-time opti-\\nmization methods demonstrate compelling results given the\\nsparsity of the observations provided. However, they often\\nstruggle to incorporate priors learned from larger datasets.\\n2.2. Online Novel View Synthesis\\nSometimes referred to as “feed-forward” or “generaliz-\\nable” NVS models, these methods attempt to directly pro-\\nduce 3D representations from input images. Early efforts\\ninclude the image-based rendering-inspired IBRNet [41],\\nwhich directly produces 2D images based on epipolar cor-\\nrespondences on the viewing ray. The Large Reconstruc-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='include the image-based rendering-inspired IBRNet [41],\\nwhich directly produces 2D images based on epipolar cor-\\nrespondences on the viewing ray. The Large Reconstruc-\\ntion Model (LRM) [16] family of methods attempt to pro-\\nduce a triplane that represents an object, in some cases with\\nnear-real time performance. PixelSplat [4], MVSplat [4],\\nand GS-LRM [47] attempt to predict 3DGS [20] representa-\\ntions, which exploit the sparse Gaussian splat representation\\nand fast rasterization to achieve quasi-interactive inference.\\nThese methods are trained on large datasets of real-world\\nscenes, which helps them outperform even test-time opti-\\nmization methods. Quark [8] couples an easily-rasterizable\\nlayered depth map representation with a render-and-refine\\nstrategy to achieve state-of-the-art quality at a much higher\\nresolution. Other efforts in this space include GPNR [39]\\nand SRT [35], which are parameterized in a similar fash-\\nion to IBRNet [41] and attempt to scale up the image and'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='resolution. Other efforts in this space include GPNR [39]\\nand SRT [35], which are parameterized in a similar fash-\\nion to IBRNet [41] and attempt to scale up the image and\\nray transformers. LRF [22] attempts to perform 3D recon-\\nstruction in the latent space of a V AE, bypassing learning\\n3D representation altogether [48]. Finally, the LVSM [19]\\nremoves all 3D priors by simply using one transformer to\\nperform NVS. LVSM performs favorably compared to both\\ngeometry-free and geometry-based feed-forward models.\\n2.3. Synthetic Data\\nRecent efforts have leveraged synthetic data to train exist-\\ning feed-forward NVS methods and investigate its efficacy\\nas a training dataset. However, it is important to note that\\nthe synthetic data in many of these efforts are generated\\nprocedurally from systems like Blender, whereas ours are\\ngenerated from a multi-view diffusion model. Two recent\\nworks LRM-Zero [43] and MegaSynth [18] are examples\\nof models trained either entirely or mostly on procedurally'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 2, 'page_label': '3', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='generated from a multi-view diffusion model. Two recent\\nworks LRM-Zero [43] and MegaSynth [18] are examples\\nof models trained either entirely or mostly on procedurally\\ngenerated synthetic data. In LRM-Zero, they demonstrate\\nthat the LRM model can be trained entirely on synthetic\\ndata. However, the synthetic-data-only model shows a sub-\\nstantial decrease in reconstruction quality compared to the\\nreal-world-data equivalent. Improving training data diver-\\nsity using synthetic data for 4D generation has also been\\nexplored in CAT4D [42].\\n3. Background\\nLVSM is a feed-forward NVS method that has no 3D in-\\nductive bias. Since our model builds upon its architecture,\\n3'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Feedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\nEmbedding \\nLayer\\n𝐑d\\n𝐑k\\nPre-Modulate\\nLinear Layer\\n𝐑6d\\nStyle \\nembed\\nPost-Modulate\\nPre-Modulate\\nPost-Modulate\\n 0\\n 1\\nStyle Tokens\\nFeedforward \\nNetwork\\nMulti-head \\nAttention\\nLayernorm\\n 0\\n 1\\nEmbedding \\nLayer\\n 𝐑d\\n𝐑k\\nModulate\\nLinear Layer\\n𝐑2d\\nStyle Tokens\\nStyle \\nembed\\nFigure 3.An illustration of the Tok-D transformer block.Our transformer blocks that differentiates between source and target tokens.\\nTok-D transformer modulates the input to all transformer blocks. Tok-D plus transformer modulates the attention and MLP layers.\\nwe outline the details here for clarity. Whereidenotes the\\nimage index andjdenotes the token index, source images\\npatches are written asIs\\nij ∈R p×p×3, source Pl¨ucker coordi-\\nnates patchesP s\\nij ∈R p×p×6, and target Pl¨ucker coordinates\\nPt\\nj ∈R p×p×6. The source images and pl ¨ucker embeddings\\nare tokenized together using a linear layer embedder.\\nSij =Linear([I s\\nij, Ps\\nij]) (1)'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ij ∈R p×p×6, and target Pl¨ucker coordinates\\nPt\\nj ∈R p×p×6. The source images and pl ¨ucker embeddings\\nare tokenized together using a linear layer embedder.\\nSij =Linear([I s\\nij, Ps\\nij]) (1)\\nThe target Pl ¨ucker coordinates are also embedded using a\\nlinear layer.\\nTij =Linear(P t\\nij) (2)\\nFinally, the transformer network is trained to reconstruct the\\ntarget output tokensOt\\nj from the Pl¨ucker patch embeddings.\\nOt\\nj =M(T j|Sij) (3)\\nThe target output tokens are detokenized using a linear\\nlayer which is converted to target image embeddingsT j ∈\\nRp×p×3\\nTj =Linear([O t\\nj]) (4)\\nThe target patches are unpatchified to get the target image\\nT∈R H×W×3 (see Figure 2). The training is supervised\\nusing MSE loss and perceptual loss designed to reconstruct.\\nTransformer BlockConsider a transformer block at\\nlayerl, which includes aMulti-head Self Attentionlayer\\n(SelfAttnl), a Feed-forward network (FFN l), and a Layer\\nNorm operation (LNl). For an input[x s\\nl ,x t\\nl], wherex s\\nl and\\nxt'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='layerl, which includes aMulti-head Self Attentionlayer\\n(SelfAttnl), a Feed-forward network (FFN l), and a Layer\\nNorm operation (LNl). For an input[x s\\nl ,x t\\nl], wherex s\\nl and\\nxt\\nl represent the source and target tokens, the data flow as\\nfollows:\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +SelfAttnl([xs\\nl ,x t\\nl])(5)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] +FFNl(LNl([xs\\nl ,x t\\nl])).\\nGiven the basic self attention based transformer blocks in\\nLVSM. At the end of the optimization process there arises a\\nneed for all token outputs of a particular layer to be aligned\\nsince they are processed by the same set of weights. Hence,\\nLVSM inherently has a chance to infuse noise or atifacts\\nthat maybe present in the source images to the target. More-\\nover this alignment also causes some part of the computa-\\ntional power of the model being used to model source token\\ninformation although those tokens are discarded at the last\\nlayer. Hence, we call for a need to distinguish between the'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tional power of the model being used to model source token\\ninformation although those tokens are discarded at the last\\nlayer. Hence, we call for a need to distinguish between the\\nsource and target tokens of the transformer network.\\n4. Method\\nOur proposed method consists of two major contributions.\\nFirst, ourToken-Disentangled (Tok-D)transformer block\\nis specialized for NVS and distinguishes information from\\nthe source and target views, leading to more efficient allo-\\ncation of representation capacity. Second, to address the\\nscarcity of multi-view data, we generate synthetic data us-\\ning CAT3D [10] and propose a model training scheme that\\nis robust to artifacts in this synthetic data. In this section,\\nwe describe each component in detail.\\n4.1. Token-Disentangled Transformer\\nIn LVSM, the transformer blocks process source and target\\ntokens in the same manner, even though the source consists\\nof images and Pl ¨ucker rays, while the target includes only'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='In LVSM, the transformer blocks process source and target\\ntokens in the same manner, even though the source consists\\nof images and Pl ¨ucker rays, while the target includes only\\nPl¨ucker rays. Additionally, source and target image quality\\ncan differ when training with synthetic data. To address this,\\nwe introduce theToken-Disentangled (Tok-D) Transformer\\nblock (see Figure 3), which enables differentiated process-\\ning of source and target tokens through modulation. The\\nTok-D Transformer uses an indicator variable (δ), where\\nδ= 1for target tokens andδ= 0for source tokens, to\\nmodulate tokens based on their origin. This mechanism ex-\\ntracts distinct style vectors and computes specific scale and\\nbias parameters for each layer and token type, allowing for\\nprecise and adaptive token modulation.\\nstyle=Linear(Embed(δ))(6)\\nModl(x) = (1 +σl)x+µ l,where[σ l, µl] =Linearl(style)\\n[xs\\nl ,x t\\nl] =Mods,t\\nl ([xs\\nl ,x t\\nl]) = [Mods\\nl (xs\\nl ),Mod t\\nl(xt\\nl)]'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 3, 'page_label': '4', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='precise and adaptive token modulation.\\nstyle=Linear(Embed(δ))(6)\\nModl(x) = (1 +σl)x+µ l,where[σ l, µl] =Linearl(style)\\n[xs\\nl ,x t\\nl] =Mods,t\\nl ([xs\\nl ,x t\\nl]) = [Mods\\nl (xs\\nl ),Mod t\\nl(xt\\nl)]\\nModulating the input of each transformer block improves\\nperforamnce. Drawing inspiration from DiT [30], we\\n4'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='extend this modulation to the Attention and MLP lay-\\ners, achieving further improvements. This modulation is\\ntermedpre-modulationif applied before a layer andpost-\\nmodulationif after. Pre-modulation includes both scaling\\nand shifting, and post-modulation involves only scaling.\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl1 ([xs\\nl ,x t\\nl])(7)\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl1, σt\\nl1]⊙SelfAttn([ ˆxs\\nl , ˆxt\\nl])\\n[ˆxs\\nl , ˆxt\\nl] =Mods,t\\nl2 ([xs\\nl ,x t\\nl])\\n[xs\\nl ,x t\\nl] = [xs\\nl ,x t\\nl] + [σs\\nl2, σt\\nl2]⊙FFN l(LNl([ˆxs\\nl , ˆxt\\nl]))\\nwhere⊙denotes element-wise multiplication which scales\\nthe corresponding source and target tokens.\\nOur Tok-D transformer block enhances the distinction\\nbetween source and target tokens, as reflected in their dis-\\ntinct feature representations (Figure 6, Section 5.4). This\\nspecialization highlights the superior representational ca-\\npacity of our model. Furthermore, when trained on syn-\\nthetic data (Section 4.2), out-of-distribution artifacts can'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='specialization highlights the superior representational ca-\\npacity of our model. Furthermore, when trained on syn-\\nthetic data (Section 4.2), out-of-distribution artifacts can\\nintroduce quality disparities between source and target to-\\nkens. By leveraging its token-aware architecture, our model\\ndemonstrates greater robustness to these artifacts, resulting\\nin improved performance, as shown in Section 5.3.\\n4.2. Synthetic Data Generation & Training Scheme\\nTraining a naive transformer model with synthetic data can\\nlead to degraded performance rather than improvement due\\nto two key factors: (1) The model struggles to distinguish\\nbetween tokens from source images and target images, al-\\nlowing artifacts from one to propagate into the other dur-\\ning alignment. (2) The model is trained to generate novel\\nviews from sparse input views, and if the target is a syn-\\nthetic image with artifacts, it may learn a distribution bi-\\nased toward unrealistic images. While these issues might'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='views from sparse input views, and if the target is a syn-\\nthetic image with artifacts, it may learn a distribution bi-\\nased toward unrealistic images. While these issues might\\nnot arise with perfect synthetic data, in-practice synthetic\\ndatasets often contain noise, making the model vulnerable\\nto errors through either mechanism. However, for image-to-\\nmultiview synthesis models like CAT3D, we propose a sim-\\nple yet effective solution: assigning the conditioned image\\nas the target view and the generated views as input views.\\nFormally letI c, Cc denote the input image and camera\\nconditioning used for the multiview diffusion model. We\\nsample additional random spline camera trajectory poses\\nCtgt relative to this particular view, and use the state-of-\\nthe-art multi-view diffusion model CAT3D to generate the\\ntarget viewsI src conditioned on the input conditioning and\\ntarget poses\\nIgen ∼DM(I gen|Cgen, Cc, Ic) (8)\\nHere DM represents inferencing through the state of the art'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='target viewsI src conditioned on the input conditioning and\\ntarget poses\\nIgen ∼DM(I gen|Cgen, Cc, Ic) (8)\\nHere DM represents inferencing through the state of the art\\ndiffusion model, After obtaining the generated views, we\\nsample 2 generated viewsI src\\nIsrc, Csrc ∼I gen, Cgen (9)\\nand their camera poses as the source imagesI src, Csrc\\nand utilize the conditioned image and its camera as the tar-\\ngetI c, Cc. Sampling the source and target images this way\\nforces the transformer to always generate a realistic image,\\nmaking our model robust to artifacts from synthetic data.\\n5. Experiments\\n5.1. Implementation Details\\nTraining detailsWe perform all experiments on 8 H100\\nGPUs. We use the AdamW optimizer withβparameters\\n0.9and0.95, and we use weight decay with a rate of0.05\\nfor all layers except the normalization layers. Moreover, we\\nuse a linear learning rate scheduler with with a peak learn-\\ning rate of2e −4, and a warmup of 2500 iterations. In total,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='for all layers except the normalization layers. Moreover, we\\nuse a linear learning rate scheduler with with a peak learn-\\ning rate of2e −4, and a warmup of 2500 iterations. In total,\\nall experiments have100ktraining iterations. In addition,\\nwe use exponential moving averaging (EMA) with a rate of\\n0.99for stabilizing the training process. Although previous\\nworks required gradient clipping for a stable training pro-\\ncess, our training processes were smooth without a need for\\nan explicit gradient clipping.\\nTraining and Evaluation DatasetsFor scene-level synthe-\\nsis model training, we use Re10K [49], ACID [25] and\\nDL3DV [24] with their originally released train and test\\nsplits. We also perform an experiment where the model\\nis trained together with a mix of all of these datasets. For\\nscene-level synthesis, we follow LVSM and train using 2\\ninput views and test using 6 target views fed one at a time.\\nFor DL3DV dataset evaluation, we choose the farthest cam-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='scene-level synthesis, we follow LVSM and train using 2\\ninput views and test using 6 target views fed one at a time.\\nFor DL3DV dataset evaluation, we choose the farthest cam-\\nera from a randomly selected target view as the input view.\\nThe training and evaluation of DL3DV dataset for in dis-\\ntribution metrics is done using 2 input views and 2 target\\nviews. For cross dataset testing, we use 2 input views and 6\\ntarget views for DL3DV dataset. We use a batch size of 64\\nfor our experiments.\\nSynthetic DataFor generating the synthetic data we use the\\nstate-of-the-art 3D generation model CAT3D. CAT3D was\\ntrained using a single scene dataset Re10K and three object-\\nbased datasets: Objaverse [7], MVImgNet [46] and Co3D\\n[32]. To create synthetic data, we use two variants: one with\\n1 conditioning view and 7 generated views, and another\\nwith 3 conditioning views and 5 generated views. We match\\nthe focal lengths of Re10K and DL3DV during generation.'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 4, 'page_label': '5', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='1 conditioning view and 7 generated views, and another\\nwith 3 conditioning views and 5 generated views. We match\\nthe focal lengths of Re10K and DL3DV during generation.\\nFor the camera trajectory, we sample a random spline tra-\\njectory with a random position rotation matrix, converting it\\ninto ray maps before passing it into the network. As CAT3D\\nis originally trained with a resolution of 512, we convert the\\nimages and camera parameters to a resolution of256before\\npassing them through our network.\\n5'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Input Views LVSM Ours GT\\nFigure 4.Qualitative results on in-distribution datasets.We illustrate the cases Tok-D transformer works better than LVSM. We notice\\nthat we obtain substantial improvement in cases where the novel views needs to reconstruct regions present only in one of the views as\\nshown in the highlighted regions in the images. The results presented here are taken from our in-distribution trained model. We present\\ntwo diffrent views to show that this problem is persistent across views.\\nTable 1.Quantitative comparisons for in-distribution scene synthesis at 256 resolution.LVSM and our method are trained with a\\nbatch size of 64. LVSM results are taken from the original paper rather than our re-implementation. Our method outperforms the previous\\nSOTA method across all exisiting datasets. ( , , ) denotes the first, second and third best results.\\nMethod Venue RealEstate10k [49] ACID [25] DL3DV [24]\\nPSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Method Venue RealEstate10k [49] ACID [25] DL3DV [24]\\nPSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nGPNR [39] CVPR’23 24.11 0.793 0.255 25.28 0.764 0.332 - - -\\nPixelSplat [4] CVPR’24 25.89 0.858 0.142 28.14 0.839 0.533 - - -\\nMVSplat [6] ECCV’25 26.39 0.869 0.128 28.25 0.843 0.144 17.54 0.529 0.402\\nDepthSplat [44] CVPR’25 27.44 0.887 0.119 - - - 19.05 0.610 0.313\\nLVSM [19] ICLR’25 28.89 0.894 0.108 29.19 0.836 0.095 19.91 0.600 0.273\\nOurs 30.02 0.919 0.058 29.47 0.846 0.086 21.55 0.643 0.208\\n5.2. Scene Synthesis\\nWe evaluate our method qualitatively and quantitatively\\nfor scene synthesis using very recent feed-forward meth-\\nods GPNR, PixelSplat, MVSplat, DepthSplat and LVSM.\\nThese methods were chosen because they outperform con-\\nventional approaches in 2-view reconstruction. Quantita-\\ntive results are shown in Table 1. We observe that Tok-D-\\nPlus outperforms LVSM by 1.2 dB on the Re10K evaluation\\nbenchmark when both models are trained with 8 GPUs. Fur-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tive results are shown in Table 1. We observe that Tok-D-\\nPlus outperforms LVSM by 1.2 dB on the Re10K evaluation\\nbenchmark when both models are trained with 8 GPUs. Fur-\\nthermore, despite using only 8 GPUs, our method still sur-\\npasses LVSM trained with 64 GPUs by a margin of 0.2 dB.\\nMoreover we obtain an improvement of 1.6dB over LVSM\\nin a more diverse scene-level dataset, DL3DV [24] dataset\\nas well. We also observe that our performance improvement\\nis0.2in ACID dataset. We emphasize that this happens be-\\ncause ACID has a relatively smaller training and testing set\\nand the dataset is generally clean and easier to reconstruct.\\nWe also provide the corresponding qualitative comparisons\\non Re10K and DL3DV dataset in Figure 4 . Comparing the\\nmain results we find that our method usually outperforms\\nLVSM when the generated content is only visible in one of\\nthe source views. When the camera is far from both views\\nand the information is present only in one of the views, our'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='LVSM when the generated content is only visible in one of\\nthe source views. When the camera is far from both views\\nand the information is present only in one of the views, our\\nmethod is still able to extract the relevant content from the\\ncorresponding input image. As can be seen from rows 1\\nand 2, the reconstruction form LVSM fails to reconstruct\\nobjects present in only one of the views, whereas Tok-D\\ntransformer can effectively reconstruct these regions.\\n5.3. Cross-Dataset Scene Synthesis\\nTo analyze the generalization capacity of our method, we\\nevaluate our method trained with Re10K dataset on two dif-\\nferent datasets: ACID and DL3DV [24]. ACID is a dataset\\nwith aerial views similar to Re10K. DL3DV [24] is a di-\\nverse dataset comprising natural scenes and various indoor\\nand outdoor settings. The scene geometry and appearance\\nof DL3DV [24] is very different from Re10k. We test the\\nRe10K and ACID datasets at a resolution of 256×265. For'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 5, 'page_label': '6', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='and outdoor settings. The scene geometry and appearance\\nof DL3DV [24] is very different from Re10k. We test the\\nRe10K and ACID datasets at a resolution of 256×265. For\\ntesting on DL3DV [24], we choose a resolution of 256×448\\nto maintain the original aspect ratio in the DL3DV [24]\\ndataset and well as maintain consistent evaluation settings\\nwith DepthSplat. We choose 2 source views and 6 tar-\\nget views for all of these datasets. Looking closely at the\\nquantitative results on Table 1 and Table 2, we find that the\\nmodel trained on Re10K underperformed the in-distribution\\ntrained model by a small margin. The drop is higher in the\\ncase of DL3DV due to resolution and diversity differences\\nin the datasets. Next we add a small portion of synthetic\\n6'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='LVSM Ours GTInput\\nFigure 5.Out-of-distribution Evaluation:We evaluate our the version of our method fine-tuned on synthetic data and LVSM on DL3DV\\nand ACID (i.e. out-of-distribution datasets). We also evaluate the model with resolutions that were not used during training. We notice that\\nLVSM’s visual quality degrades when substantial camera motion reveals previously-occluded regions.\\nTable 2.Quantitative comparisons for scaling up with synthetic data.We evaluate LVSM and our method, which are both trained with\\na batch size of 64. A mixture of synthesized DL3DV and Re10K data is used for the synthetic tab. For MVSplat and DepthSplat we include\\nthe numbers reported in their papers\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K[49] Synthetic PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nMVSplat [6] ✓ 26.39 0.869 0.128 28.15 0.147 0.841 17.72 0.534 0.371\\nDepthsplat [44] ✓ 27.44 0.887 0.119 - - - 18.90 0.640 0.317'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='MVSplat [6] ✓ 26.39 0.869 0.128 28.15 0.147 0.841 17.72 0.534 0.371\\nDepthsplat [44] ✓ 27.44 0.887 0.119 - - - 18.90 0.640 0.317\\nLVSM [19] ✓ 28.89 0.894 0.108 28.29 0.809 0.104 20.52 0.621 0.223\\nLVSM [19] ✓ ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nOurs ✓ 30.02 0.910 0.058 29.31 0.838 0.091 21.18 0.652 0.205\\nOurs ✓ ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\ndata comprising about half the size of Re10K dataset and\\nperform training with the new framework. We also retrain\\nLVSM for the same setting. We find thatLVSM’s perfor-\\nmance drops rather than improving when synthetic data is\\nadded. We emphasize that this arises due to the introduc-\\ntion of artifacts during feature alignment. In contrast, we\\nobserve an improvement in quality on our method when a\\nsmall amount of synthetic data is added.\\n5.4. Analysis and Discussion\\nVisualization of source and target features.To visually\\nillustrate the representation alignment problem mentioned'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='small amount of synthetic data is added.\\n5.4. Analysis and Discussion\\nVisualization of source and target features.To visually\\nillustrate the representation alignment problem mentioned\\nin the previous sections, we visualize the 3 channel PCA\\nof each transformer block output after unpatchifying for all\\n24 layers of LVSM and our method in Figure 6. The first\\nrow shows the first 6 layer outputs, second row shows layer\\n6-12, and so on. We can see that for a particular scene the\\nsource and target layer tokens are aligned at all layers even\\nthough the training objective is to reconstruct the target.\\nThis causes inefficient usage of the transformer parameters\\nto maintain the source information throughout the layers.\\nMoreover this also makes the model prone tonoise in the\\nsource data. However, with our Tok-D transformer there is\\nno alignment and the source information is infused much\\nearlier, leaving more room for the transformer blocks to re-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 6, 'page_label': '7', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='source data. However, with our Tok-D transformer there is\\nno alignment and the source information is infused much\\nearlier, leaving more room for the transformer blocks to re-\\nconstruct the target. Another important observation is that\\nalthough both source image and Pl¨ucker coordinates are fed\\nas input to the source, the source tokens look similar to the\\nPl¨ucker coordinates. Whereas in our case the image compo-\\nnents in the source PCA components leading to much more\\neffective information extraction from each source token.\\nImpact of additional real data.Incorporating synthetic\\ndata into the training process facilitates the introduction of\\ndiverse scenes and camera motion, enhancing model gener-\\nalizability. While the proposed Tok-D transformer demon-\\n7'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='(a)\\nTarget\\n (b)\\nSource\\n (c) LVSM Target PCA\\n (d) LVSM Source PCA\\n (e) Ours Source PCA\\n (f) Ours Target PCA\\nFigure 6.A visualization of the principal components of transformer layer outputs for source and target of LVSM. The 24 images\\nin each subfigure show the layer output of each layer of the transformer. LVSM features for source and target images looks similar even\\nthough the source is conditioned with image and Pl ¨ucker coordinates and target is conditioned with Pl ¨ucker coordinates alone. This leads\\nto inefficient transformer usage requiring explicit alignment of source and target features across different layers\\nTable 3.Ablation studies on scaling up with more real data.Although including synthetic data in training is helpful for improving\\nquality, including additional real data significantly improves reconstruction quality.\\nMethod Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K [49]+Synthetic DL3DV [24]PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Method Training Dataset RealEstate10k [49] ACID [25] DL3DV [24]\\nRe10K [49]+Synthetic DL3DV [24]PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓ PSNR↑ SSIM↑ LPIPS↓\\nLVSM [19] ✓ 28.49 0.892 0.070 28.16 0.802 0.107 20.21 0.595 0.240\\nLVSM [19] ✓ ✓ 28.10 0.892 0.073 28.79 0.826 0.096 21.37 0.665 0.196\\nOurs ✓ 29.97 0.920 0.058 29.37 0.839 0.091 21.27 0.657 0.202\\nOurs ✓ ✓ 29.78 0.917 0.0604 30.13 0.857 0.082 23.14 0.726 0.156\\nTable 4.Ablation analysisWe analyze the performance improve-\\nment of our design choices.PreandPostdemonstrate the effects\\nof including or not including pre/post-modulation.\\nPre Post Whole Attn MLP PSNR↑ SSIM↑ LPIPS↓\\n28.50 0.893 0.070\\n✓ ✓ 29.69 0.911 0.063\\n✓ ✓ ✓ 28.51 0.894 0.070\\n✓ ✓ ✓ ✓ 30.02 0.918 0.058\\nstrates reduced sensitivity to synthetic data artifacts and in-\\ncreased generative diversity, its photorealistic reconstruc-\\ntion performance remains comparable to the baseline model\\ntrained solely on real data. To investigate the impact of'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='creased generative diversity, its photorealistic reconstruc-\\ntion performance remains comparable to the baseline model\\ntrained solely on real data. To investigate the impact of\\naugmenting the training dataset with additional real data,\\nwe integrated the DL3DV dataset into the existing exper-\\nimental setup. This modification resulted in a significant\\nimprovement in photorealistic reconstruction, as evidenced\\nby a substantial increase in PSNR on the ACID dataset. Fur-\\nthermore, the relative performance gains observed with our\\nmodel, compared to LVSM, were considerably greater, sug-\\ngesting a reduced susceptibility to noise.\\n5.5. Ablation Studies\\nWe analyze the impact of various design choices in the net-\\nwork. Specifically, we examine three aspects: (1) The effect\\nof modulation in different parts of the network, (2) The role\\nof EMA in performance, (3) Number of input views.\\nImpact of modulation at different locations of Tok-D\\ntransformer.We examine the effect of modulating differ-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='of EMA in performance, (3) Number of input views.\\nImpact of modulation at different locations of Tok-D\\ntransformer.We examine the effect of modulating differ-\\nent parts of the network. For this, we consider four differ-\\nent cases. We present the corresponding results in Table 4.\\nHaving a common modulation premodulation worked better\\nthan separate premodulation for both layers.\\nImpact of EMA.We also observe that performing Expo-\\nnential moving average (EMA) [13] during training results\\nin a performance boost for the base model. For the sake of\\nTable 5.Effect of EMA on runtime performance and quality.\\nComparison performed on Re10k.\\nMethod TrainRenderGFLOPs No EMA With EMA(ms) (ms) PSNR SSIM LPIPSPSNR SSIM LPIPS\\nLVSM-1024706.1171.6 2896.8827.68 0.88 0.07728.65 0.90 0.070Ours 734.6174.4 2900.7828.75 0.90 0.06430.02 0.92 0.058\\nTable 6.Effect of adding more source views. Our method works\\nwell as additional source views are introduced.\\nMethod 2 views 4 views 8 views'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Table 6.Effect of adding more source views. Our method works\\nwell as additional source views are introduced.\\nMethod 2 views 4 views 8 views\\nPSNR SSIM LPIPSPSNR SSIM LPIPSPSNR SSIM LPIPS\\nOurs 30.02 0.92 0.058 31.51 0.94 0.048 33.09 0.94 0.042\\nconsistency, we show the results of our model and our re-\\nimplementation of LVSM with 1024 channels trained with\\nand without EMA in Table 5.\\nImpact of number of source frames.Our model scales\\nwith the number of input views and results in better re-\\nconstruction quality when more input views are fed to the\\nmodel to the model as presented in Table 6.\\n6. Conclusion\\nIn this paper, we introduce a new approach to scaling up\\nNVS by addressing two key limitations in existing mod-\\nels: efficiency and diversity. To enhance the efficiency\\nof transformer-based NVS models, we propose the Token-\\nDisentangled (Tok-D) Transformer, which reduces redun-\\ndancies and improves data efficiency, enabling higher re-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 7, 'page_label': '8', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='of transformer-based NVS models, we propose the Token-\\nDisentangled (Tok-D) Transformer, which reduces redun-\\ndancies and improves data efficiency, enabling higher re-\\nconstruction quality with less compute. Additionally, the\\nTok-D Transformer mitigates training artifacts through its\\ndisentangling property, allowing for effective scaling us-\\ning synthetic data. Incorporating synthetic data into train-\\ning significantly improves cross-dataset performance com-\\npared to existing models. By integrating the Tok-D Trans-\\nformer and synthetic data, we achieve state-of-the-art re-\\nsults across three large-scale NVS benchmarks, surpassing\\nprevious methods with lower computational cost and by a\\nsubstantial margin.\\n8'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='References\\n[1] Benjamin Attal, Jia-Bin Huang, Michael Zollh ¨ofer, Johannes\\nKopf, and Changil Kim. Learning neural light fields with\\nray-space embedding. InProceedings of the IEEE/CVF Con-\\nference on Computer Vision and Pattern Recognition, pages\\n19819–19829, 2022. 2\\n[2] Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased\\ngrid-based neural radiance fields. InProceedings of the\\nIEEE/CVF International Conference on Computer Vision,\\npages 19697–19705, 2023. 2\\n[3] Jonathan T. Barron, Ben Mildenhall, Dor Verbin, Pratul P.\\nSrinivasan, and Peter Hedman. Zip-nerf: Anti-aliased grid-\\nbased neural radiance fields.ICCV, 2023. 3\\n[4] David Charatan, Sizhe Lester Li, Andrea Tagliasacchi, and\\nVincent Sitzmann. pixelsplat: 3d gaussian splats from image\\npairs for scalable generalizable 3d reconstruction. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 19457–19467, 2024. 2, 3, 6'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='pairs for scalable generalizable 3d reconstruction. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 19457–19467, 2024. 2, 3, 6\\n[5] Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, and\\nHao Su. Tensorf: Tensorial radiance fields. InEuropean\\nConference on Computer Vision (ECCV), 2022. 2, 3\\n[6] Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang,\\nMarc Pollefeys, Andreas Geiger, Tat-Jen Cham, and Jianfei\\nCai. Mvsplat: Efficient 3d gaussian splatting from sparse\\nmulti-view images. InEuropean Conference on Computer\\nVision, pages 370–386. Springer, 2024. 6, 7\\n[7] Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs,\\nOscar Michel, Eli VanderBilt, Ludwig Schmidt, Kiana\\nEhsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse:\\nA universe of annotated 3d objects. InProceedings of\\nthe IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 13142–13153, 2023. 5\\n[8] John Flynn, Michael Broxton, Lukas Murmann, Lucy Chai,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='the IEEE/CVF Conference on Computer Vision and Pattern\\nRecognition, pages 13142–13153, 2023. 5\\n[8] John Flynn, Michael Broxton, Lukas Murmann, Lucy Chai,\\nMatthew DuVall, Cl ´ement Godard, Kathryn Heal, Srinivas\\nKaza, Stephen Lombardi, Xuan Luo, et al. Quark: Real-time,\\nhigh-resolution, and general neural view synthesis.ACM\\nTransactions on Graphics (TOG), 43(6):1–20, 2024. 3\\n[9] Sara Fridovich-Keil, Alex Yu, Matthew Tancik, Qinhong\\nChen, Benjamin Recht, and Angjoo Kanazawa. Plenoxels:\\nRadiance fields without neural networks. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 5501–5510, 2022. 3\\n[10] Ruiqi Gao, Aleksander Holynski, Philipp Henzler, Arthur\\nBrussee, Ricardo Martin Brualla, Pratul Srinivasan, Jonathan\\nBarron, and Ben Poole. Cat3d: Create anything in 3d with\\nmulti-view diffusion models.Advances in Neural Informa-\\ntion Processing Systems, 37:75468–75494, 2024. 2, 4\\n[11] Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='multi-view diffusion models.Advances in Neural Informa-\\ntion Processing Systems, 37:75468–75494, 2024. 2, 4\\n[11] Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, and\\nMichael F. Cohen. The lumigraph. InProceedings of the\\n23rd Annual Conference on Computer Graphics and Inter-\\nactive Techniques, page 43–54, New York, NY , USA, 1996.\\nAssociation for Computing Machinery. 2\\n[12] Albert Gu and Tri Dao. Mamba: Linear-time sequence mod-\\neling with selective state spaces, 2024. 12\\n[13] David Haynes, Steven Corns, and Ganesh Kumar Venayag-\\namoorthy. An exponential moving average algorithm. In\\n2012 IEEE Congress on Evolutionary Computation, pages\\n1–8. IEEE, 2012. 8\\n[14] Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and\\nQifeng Chen. Latent video diffusion models for high-fidelity\\nlong video generation.arXiv preprint arXiv:2211.13221,\\n2022. 2\\n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-\\nfusion probabilistic models.Advances in neural information'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='long video generation.arXiv preprint arXiv:2211.13221,\\n2022. 2\\n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-\\nfusion probabilistic models.Advances in neural information\\nprocessing systems, 33:6840–6851, 2020. 2\\n[16] Yicong Hong, Kai Zhang, Jiuxiang Gu, Sai Bi, Yang Zhou,\\nDifan Liu, Feng Liu, Kalyan Sunkavalli, Trung Bui, and Hao\\nTan. LRM: Large reconstruction model for single image to\\n3d. InThe Twelfth International Conference on Learning\\nRepresentations, 2024. 2, 3\\n[17] Binbin Huang, Zehao Yu, Anpei Chen, Andreas Geiger, and\\nShenghua Gao. 2d gaussian splatting for geometrically accu-\\nrate radiance fields. InSpecial Interest Group on Computer\\nGraphics and Interactive Techniques Conference Conference\\nPapers, page 1–11. ACM, 2024. 3\\n[18] Hanwen Jiang, Zexiang Xu, Desai Xie, Ziwen Chen, Haian\\nJin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Ji-\\nuxiang Gu, Qixing Huang, Georgios Pavlakos, and Hao Tan.\\nMegasynth: Scaling up 3d scene reconstruction with syn-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Jin, Fujun Luan, Zhixin Shu, Kai Zhang, Sai Bi, Xin Sun, Ji-\\nuxiang Gu, Qixing Huang, Georgios Pavlakos, and Hao Tan.\\nMegasynth: Scaling up 3d scene reconstruction with syn-\\nthesized data. InProceedings of the IEEE/CVF Conference\\non Computer Vision and Pattern Recognition (CVPR), pages\\n16441–16452, 2025. 3\\n[19] Haian Jin, Hanwen Jiang, Hao Tan, Kai Zhang, Sai Bi,\\nTianyuan Zhang, Fujun Luan, Noah Snavely, and Zexiang\\nXu. LVSM: A large view synthesis model with minimal 3d\\ninductive bias. InThe Thirteenth International Conference\\non Learning Representations, 2025. 2, 3, 6, 7, 8\\n[20] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk ¨uhler,\\nand George Drettakis. 3d gaussian splatting for real-time\\nradiance field rendering.ACM Trans. Graph., 42(4):139–1,\\n2023. 2, 3\\n[21] Shakiba Kheradmand, Delio Vicini, George Kopanas,\\nDmitry Lagun, Kwang Moo Yi, Mark Matthews, and An-\\ndrea Tagliasacchi. Stochasticsplats: Stochastic rasterization\\nfor sorting-free 3d gaussian splatting, 2025. 3'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Dmitry Lagun, Kwang Moo Yi, Mark Matthews, and An-\\ndrea Tagliasacchi. Stochasticsplats: Stochastic rasterization\\nfor sorting-free 3d gaussian splatting, 2025. 3\\n[22] Diederik P Kingma, Max Welling, et al. Auto-encoding vari-\\national bayes, 2013. 3\\n[23] Marc Levoy and Pat Hanrahan. Light field rendering. In\\nProceedings of the 23rd Annual Conference on Computer\\nGraphics and Interactive Techniques, page 31–42, New\\nYork, NY , USA, 1996. Association for Computing Machin-\\nery. 2\\n[24] Lu Ling, Yichen Sheng, Zhi Tu, Wentian Zhao, Cheng Xin,\\nKun Wan, Lantao Yu, Qianyu Guo, Zixun Yu, Yawen Lu,\\net al. Dl3dv-10k: A large-scale scene dataset for deep\\nlearning-based 3d vision. InProceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition,\\npages 22160–22169, 2024. 2, 5, 6, 7, 8\\n[25] Andrew Liu, Richard Tucker, Varun Jampani, Ameesh\\nMakadia, Noah Snavely, and Angjoo Kanazawa. Infinite na-\\nture: Perpetual view generation of natural scenes from a sin-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 8, 'page_label': '9', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[25] Andrew Liu, Richard Tucker, Varun Jampani, Ameesh\\nMakadia, Noah Snavely, and Angjoo Kanazawa. Infinite na-\\nture: Perpetual view generation of natural scenes from a sin-\\ngle image. InProceedings of the IEEE/CVF International\\nConference on Computer Vision, pages 14458–14467, 2021.\\n2, 5, 6, 7, 8\\n9'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[26] Lingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, and\\nChristian Theobalt. Neural sparse voxel fields.Advances\\nin Neural Information Processing Systems, 33:15651–15663,\\n2020. 2, 3\\n[27] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,\\nJonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:\\nRepresenting scenes as neural radiance fields for view syn-\\nthesis. InEuropean conference on computer vision, 2020. 2,\\n3\\n[28] Thomas M ¨uller, Alex Evans, Christoph Schied, and Alexan-\\nder Keller. Instant neural graphics primitives with a mul-\\ntiresolution hash encoding.ACM transactions on graphics\\n(TOG), 41(4):1–15, 2022. 2, 3\\n[29] Alexander Quinn Nichol and Prafulla Dhariwal. Improved\\ndenoising diffusion probabilistic models. InInternational\\nconference on machine learning, pages 8162–8171. PMLR,\\n2021. 2\\n[30] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. InProceedings of the IEEE/CVF inter-\\nnational conference on computer vision, pages 4195–4205,\\n2023. 4'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='2021. 2\\n[30] William Peebles and Saining Xie. Scalable diffusion models\\nwith transformers. InProceedings of the IEEE/CVF inter-\\nnational conference on computer vision, pages 4195–4205,\\n2023. 4\\n[31] Lukas Radl, Michael Steiner, Mathias Parger, Alexan-\\nder Weinrauch, Bernhard Kerbl, and Markus Steinberger.\\nStopThePop: Sorted Gaussian Splatting for View-Consistent\\nReal-time Rendering.ACM Transactions on Graphics, 4\\n(43), 2024. 3\\n[32] Jeremy Reizenstein, Roman Shapovalov, Philipp Henzler,\\nLuca Sbordone, Patrick Labatut, and David Novotny. Com-\\nmon objects in 3d: Large-scale learning and evaluation\\nof real-life 3d category reconstruction. InProceedings of\\nthe IEEE/CVF international conference on computer vision,\\npages 10901–10911, 2021. 5\\n[33] Robin Rombach, Andreas Blattmann, Dominik Lorenz,\\nPatrick Esser, and Bj ¨orn Ommer. High-resolution image\\nsynthesis with latent diffusion models. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Patrick Esser, and Bj ¨orn Ommer. High-resolution image\\nsynthesis with latent diffusion models. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 10684–10695, 2022. 2\\n[34] Chitwan Saharia, William Chan, Saurabh Saxena, Lala\\nLi, Jay Whang, Emily L Denton, Kamyar Ghasemipour,\\nRaphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans,\\net al. Photorealistic text-to-image diffusion models with deep\\nlanguage understanding.Advances in neural information\\nprocessing systems, 35:36479–36494, 2022. 2\\n[35] Mehdi SM Sajjadi, Henning Meyer, Etienne Pot, Urs\\nBergmann, Klaus Greff, Noha Radwan, Suhani V ora, Mario\\nLuˇci´c, Daniel Duckworth, Alexey Dosovitskiy, et al. Scene\\nrepresentation transformer: Geometry-free novel view syn-\\nthesis through set-latent scene representations. InProceed-\\nings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 6229–6238, 2022. 3\\n[36] Yichun Shi, Peng Wang, Jianglong Ye, Long Mai, Kejie Li,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition, pages 6229–6238, 2022. 3\\n[36] Yichun Shi, Peng Wang, Jianglong Ye, Long Mai, Kejie Li,\\nand Xiao Yang. MVDream: Multi-view diffusion for 3d gen-\\neration. InThe Twelfth International Conference on Learn-\\ning Representations, 2024. 2\\n[37] Vincent Sitzmann, Semon Rezchikov, Bill Freeman, Josh\\nTenenbaum, and Fredo Durand. Light field networks: Neu-\\nral scene representations with single-evaluation rendering.\\nAdvances in Neural Information Processing Systems, 34:\\n19313–19325, 2021. 2\\n[38] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-\\nhishek Kumar, Stefano Ermon, and Ben Poole. Score-based\\ngenerative modeling through stochastic differential equa-\\ntions. InInternational Conference on Learning Represen-\\ntations, 2021. 2\\n[39] Mohammed Suhail, Carlos Esteves, Leonid Sigal, and\\nAmeesh Makadia. Generalizable patch-based neural render-\\ning. InEuropean Conference on Computer Vision, pages'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='tations, 2021. 2\\n[39] Mohammed Suhail, Carlos Esteves, Leonid Sigal, and\\nAmeesh Makadia. Generalizable patch-based neural render-\\ning. InEuropean Conference on Computer Vision, pages\\n156–174. Springer, 2022. 2, 3, 6\\n[40] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku\\nKomura, and Wenping Wang. Neus: Learning neural im-\\nplicit surfaces by volume rendering for multi-view recon-\\nstruction.Advances in Neural Information Processing Sys-\\ntems, 34:27171–27183, 2021. 2\\n[41] Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul P\\nSrinivasan, Howard Zhou, Jonathan T Barron, Ricardo\\nMartin-Brualla, Noah Snavely, and Thomas Funkhouser. Ibr-\\nnet: Learning multi-view image-based rendering. InPro-\\nceedings of the IEEE/CVF conference on computer vision\\nand pattern recognition, pages 4690–4699, 2021. 3\\n[42] Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi\\nZheng, Jonathan T Barron, and Aleksander Holynski. Cat4d:\\nCreate anything in 4d with multi-view video diffusion mod-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[42] Rundi Wu, Ruiqi Gao, Ben Poole, Alex Trevithick, Changxi\\nZheng, Jonathan T Barron, and Aleksander Holynski. Cat4d:\\nCreate anything in 4d with multi-view video diffusion mod-\\nels. InProceedings of the Computer Vision and Pattern\\nRecognition Conference, pages 26057–26068, 2025. 3\\n[43] Desai Xie, Sai Bi, Zhixin Shu, Kai Zhang, Zexiang Xu, Yi\\nZhou, Soren Pirk, Arie Kaufman, Xin Sun, and Hao Tan.\\nLRM-zero: Training large reconstruction models with syn-\\nthesized data. InThe Thirty-eighth Annual Conference on\\nNeural Information Processing Systems, 2024. 3\\n[44] Haofei Xu, Songyou Peng, Fangjinhua Wang, Hermann\\nBlum, Daniel Barath, Andreas Geiger, and Marc Pollefeys.\\nDepthsplat: Connecting gaussian splatting and depth. InPro-\\nceedings of the IEEE/CVF Conference on Computer Vision\\nand Pattern Recognition (CVPR), pages 16453–16463, 2025.\\n2, 6, 7\\n[45] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V ol-\\nume rendering of neural implicit surfaces, 2021. 2'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='and Pattern Recognition (CVPR), pages 16453–16463, 2025.\\n2, 6, 7\\n[45] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. V ol-\\nume rendering of neural implicit surfaces, 2021. 2\\n[46] Xianggang Yu, Mutian Xu, Yidan Zhang, Haolin Liu,\\nChongjie Ye, Yushuang Wu, Zizheng Yan, Chenming Zhu,\\nZhangyang Xiong, Tianyou Liang, et al. Mvimgnet: A\\nlarge-scale dataset of multi-view images. InProceedings of\\nthe IEEE/CVF conference on computer vision and pattern\\nrecognition, pages 9150–9161, 2023. 5\\n[47] Kai Zhang, Sai Bi, Hao Tan, Yuanbo Xiangli, Nanxuan Zhao,\\nKalyan Sunkavalli, and Zexiang Xu. Gs-lrm: Large recon-\\nstruction model for 3d gaussian splatting.European Confer-\\nence on Computer Vision, 2024. 3\\n[48] Chaoyi Zhou, Xi Liu, Feng Luo, and Siyu Huang. Latent\\nradiance fields with 3d-aware 2d representations. InThe\\nThirteenth International Conference on Learning Represen-\\ntations, 2025. 3\\n[49] Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 9, 'page_label': '10', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='radiance fields with 3d-aware 2d representations. InThe\\nThirteenth International Conference on Learning Represen-\\ntations, 2025. 3\\n[49] Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe,\\nand Noah Snavely. Stereo magnification: learning view syn-\\nthesis using multiplane images.ACM Trans. Graph., 37(4),\\n2018. 2, 5, 6, 7, 8\\n10'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='[50] Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang,\\nWenyu Liu, and Xinggang Wang. Vision mamba: Efficient\\nvisual representation learning with bidirectional state space\\nmodel, 2024. 12\\n7. Design choices\\nWe provide further details of the exact transformer model\\nused here.Transformer blocksWe find the claims regard-\\ning the naive transformer architecture to be unstable for im-\\nage generative tasks to be true. We use QK-Norm to stabi-\\nlize the transformer block. We use24transformer blocks\\nwith an embedding dimension of1024. In addition to this,\\ndifferent from LVSM, we use attention biases at all layers\\nand include the bias for the last transformer block, as we\\nfind this design choice particularly stable with linear learn-\\ning rate decay. We use a patch size of 8 for all experiments.\\n7.1. Enhancing 3D generative models for 3D consis-\\ntent generation\\nThe use of diffusion models has been widely explored for\\ngenerating 3D scenes. Multiple works in the literature'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='7.1. Enhancing 3D generative models for 3D consis-\\ntent generation\\nThe use of diffusion models has been widely explored for\\ngenerating 3D scenes. Multiple works in the literature\\nadapt pretrained text-to-image and image-to-video models\\nfor 3D-consistent scene generation. Most of these works\\ncondition the diffusion model on camera parameters and\\nlearn the conditional distribution of multiple views given the\\ncamera poses. Given the ability to cherry-pick and sample\\nthrough the diffusion model multiple times, these models\\nproduce high-quality results. However, existing 3D scene\\ngeneration models cannot mass-produce synthetic data for\\nfine-tuning substream models for high-fidelity generation.\\nUntil now, no generalizable models with high-fidelity re-\\nsults have been proposed that can directly utilize the data\\ngenerated by diffusion models. We argue that this draw-\\nback is caused by a lack of analysis of the inference-time\\ngeneration process of diffusion models. Although extensive'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='generated by diffusion models. We argue that this draw-\\nback is caused by a lack of analysis of the inference-time\\ngeneration process of diffusion models. Although extensive\\nstudies have been performed on different training strategies\\nfor 3D-consistent generation using diffusion models, much\\nless effort has been put into improving inference-time gen-\\neration quality.\\nMost 3D generative models generateNviews of a scene,\\neach of dimension(H×W×C), in parallel to preserve\\n3D consistency. The generation process starts with random\\nisotropic Gaussian noise of dimensionN×H×W×C,\\nwhich undergoes a diffusion process ofTsteps. This either\\nconverts it into a latent representation, which is then de-\\ncoded by a V AE decoder to produce multiview images, or\\ngenerates images directly. These multiview images are fur-\\nther used to train a NeRF or a Gaussian Splat model to gen-\\nerate novel views of the scene. When the diffusion model\\ngenerates high-quality, 3D-consistent images, this frame-'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='ther used to train a NeRF or a Gaussian Splat model to gen-\\nerate novel views of the scene. When the diffusion model\\ngenerates high-quality, 3D-consistent images, this frame-\\nwork works perfectly. However, in reality, diffusion models\\nare sensitive to input noise. Even for the simple case of\\nimage generation, different noise inputs produce different\\nquality results. Recent works have shed light on inference-\\ntime scaling laws for generation, claiming that the quality of\\ndiffusion model outputs can be controlled by selecting the\\ncorrect input noise via rejection sampling. Similar claims\\nhave been made for video generation models, where per-\\nformance improves significantly by refining the input noise\\nschedule.\\nTo understand this, consider a toy example: Suppose we\\nwant to generate an image (I 1) using the diffusion model\\nconditioned on a text prompt. Starting with Gaussian noise\\nN1, if we want to generate another image (I2) close to (I1),'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='want to generate an image (I 1) using the diffusion model\\nconditioned on a text prompt. Starting with Gaussian noise\\nN1, if we want to generate another image (I2) close to (I1),\\nthe desired noise is most likely closer toN1. Previous works\\nhave demonstrated enhanced video generation results by se-\\nlecting starting noises that are close across different frames.\\nIn our case, we use the image-to-multiview variant of\\nCAT3D as the base model for generating multiview images.\\nFor choosing the initial noise, we follow a specific heuris-\\ntic. Specifically, we ensure that the noise across different\\nviews remains 3D-consistent. CAT3D is a multiview diffu-\\nsion model that generates eight views simultaneously, con-\\nditioned on the camera poses. CAT3D allows conditioning\\non a particular view to generate the remaining views. Given\\nthe view to be conditioned, we select a random noise for\\nthis view, denoted asV 1, with its noise represented asN 1'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='on a particular view to generate the remaining views. Given\\nthe view to be conditioned, we select a random noise for\\nthis view, denoted asV 1, with its noise represented asN 1\\nand the corresponding rotation-translation matrices denoted\\nasR 1, t1. To estimate the starting noise for other views, we\\nperform a warping operation onN 1, denoted by:\\nNi =warp(N 1, inv([Ri, ti])[R1, t1]) (10)\\nwhere the warp operation transforms the coordinates of\\nN1 toN i. However, we noticed that such a warping op-\\neration fails in regions outside the scene. To handle these\\ncases while enhancing consistency, we marginally modify\\nthe noise. Specifically, for these cases, we assign the noise\\nas:\\nN2 =αN 1 + (1−α)N(0, I) (11)\\nThus, our effective starting noise is defined as:\\nNfinal =\\n(\\nN1,overlapping regions\\nN2,non overlapping regions\\nWe perform the effective noising operation parallely with\\nrespect to the reference view. First we take view 1, warp to\\nview 2. then add noise, then we Although we use CAT3D,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 10, 'page_label': '11', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='We perform the effective noising operation parallely with\\nrespect to the reference view. First we take view 1, warp to\\nview 2. then add noise, then we Although we use CAT3D,\\nour method is generalizable across any 3D scene generation\\nmodel.\\nUnderstanding the value that synthetic data from gen-\\nerative models can bring, we propose a method to en-\\nhance diffusion-based 3D generative models to produce\\nhigh-quality, 3D-consistent results.\\n11'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='7.2. Loss functions\\nSimilar to LVSM, we utilize Mean Square Error (MSE) loss\\nfor training our network. Instead of using Perceptual Loss,\\nwe utilize LPIPS loss for training. Given the ground-truth\\ntarget view of dimension ˆI∈R H×W×C and the recon-\\nstructed target viewI, the effective objective function used\\nfor optimization is defined as:\\nL=MSE(I, ˆI) +λ·LP IP S(I,ˆI) (12)\\nwhereλis a scaling factor set to0.5for all experiments.\\n7.3. Emergent Properties\\nOne surprisingemergent propertyof our newly proposed\\ntransformer block is its ability to disentangle the source\\nand target tokens, which allows it to scale better for syn-\\nthetic data compared to a naive transformer block. We\\npresent these results in Figure X, where we observe sig-\\nnificant improvements. We hypothesize that this emergent\\nproperty arises because synthetic data is generally prone to\\nartifacts and out-of-distribution noise. When transformer\\nblocks cannot distinguish between source and target tokens,'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='property arises because synthetic data is generally prone to\\nartifacts and out-of-distribution noise. When transformer\\nblocks cannot distinguish between source and target tokens,\\nthe model learns using both real and synthetic data, leading\\nto reconstructions that inherit these artifacts. However, in\\nour case, only the relevant information from clean images\\nis used for backpropagation, allowing the model to utilize\\nuseful context from synthetic data while discarding artifacts\\nduring token fusion for target view generation.\\n8. Limitations\\nOur model struggles when regions occluded in the source\\nimages become visible in the target view. As shown in Fig-\\nure 17, when a new object enters the scene, the model hallu-\\ncinates the affected region. We argue that this phenomenon\\nis inherently ill-posed and lacks a definitive solution. Ad-\\nditionally, the model uses a token size of 8 for all blocks,\\nresulting in 1024 tokens per source image, which demands'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 11, 'page_label': '12', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='is inherently ill-posed and lacks a definitive solution. Ad-\\nditionally, the model uses a token size of 8 for all blocks,\\nresulting in 1024 tokens per source image, which demands\\nsignificant memory. We leave further architectural opti-\\nmizations, such as hierarchical transformers and more ef-\\nficient networks like linear attention and state-space models\\n(e.g., Mamba [12], [50]), for future work.\\n9. Failure cases of our method\\nWe notice that our method contains two main failure modes\\n(1) when an new object comes into the view in between the\\nconditioned frames. (2) When too many shiny artifacts are\\npresent in the image\\n12'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 12, 'page_label': '13', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 7.Figure illustrating results from DL3DV dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n13'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 13, 'page_label': '14', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 8.Figure illustrating results from Re10k dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n14'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 14, 'page_label': '15', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 9.Figure illustrating results from ACID dataset trained with our synthetic data. The first 2 images represent the input views.\\nthird presents results of LVSM, Fourth represents our results and fifth the ground truth\\n15'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 15, 'page_label': '16', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 10.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 11.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n16'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 16, 'page_label': '17', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 12.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 13.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\n17'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 17, 'page_label': '18', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 14.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 15.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and\\n18'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 18, 'page_label': '19', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 16.Figure illustrating the regions where our method works better than LVSM for Re10K dataset. The figures are in the order\\nRow 1:- LVSM, Row 2:- OURS Row 3:- GT, Row 4:- Difference between LVSM and Ours\\nFigure 17.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n19'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 19, 'page_label': '20', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 18.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 19.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\n20'),\n",
       " Document(metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'author': 'Nithin Gopalakrishnan Nair; Srinivas Kaza; Xuan Luo; Vishal M. Patel; Stephen Lombardi; Jungyeon Park', 'doi': 'https://doi.org/10.48550/arXiv.2509.06950', 'license': 'http://creativecommons.org/licenses/by/4.0/', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.28 (TeX Live 2025) kpathsea version 6.4.1', 'title': 'Scaling Transformer-Based Novel View Synthesis Models with Token Disentanglement and Synthetic Data', 'trapped': '/False', 'arxivid': 'https://arxiv.org/abs/2509.06950v1', 'source': '..\\\\data\\\\pdf\\\\scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'total_pages': 21, 'page': 20, 'page_label': '21', 'source_file': 'scaling-transformer-based-synthesis-models-token-disentanglement.pdf', 'file_type': 'pdf'}, page_content='Figure 20.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene. Figure ordering is OURS, GT, DIFF\\nFigure 21.Figure illustrating failure cases of our method. Our method fails to perform well if there are occluded objects coming into\\nthe scene moreover, our method also fails to reconstruct properly when there are some shiny obejcts in the scene. Figure ordering is OURS,\\nGT, DIFF\\n21')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f7b6977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding for 238 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 8/8 [00:17<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (238, 384)\n",
      "Adding 238 documents to vector store...\n",
      "Successfully added 238 documents to vector store\n",
      "Total documents in collection 1372\n"
     ]
    }
   ],
   "source": [
    "### Convert the text to embeddings\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "## Generate the Embeddings\n",
    "\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "## store int the vector database\n",
    "vectorstore.add_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ebeac",
   "metadata": {},
   "source": [
    "### Retriever Pipeline From VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca25906",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    \"\"\"Handles query-based retrieval from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Initialize the retriever\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating query embeddings\n",
    "        \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k: int = 5, score_threshold: float = 0.0) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}'\")\n",
    "        print(f\"Top K: {top_k}, Score threshold: {score_threshold}\")\n",
    "        \n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k\n",
    "            )\n",
    "            \n",
    "            # Process results\n",
    "            retrieved_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # Convert distance to similarity score (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "                    \n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                \n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "            \n",
    "            return retrieved_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return []\n",
    "\n",
    "rag_retriever=RAGRetriever(vectorstore,embedding_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e83bd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RAGRetriever at 0x1959f63dfd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fa8b34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is attention is all you need'\n",
      "Top K: 5, Score threshold: 0.0\n",
      "Generating embedding for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_1724cf99_12',\n",
       "  'content': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3',\n",
       "  'metadata': {'content_length': 216,\n",
       "   'total_pages': 15,\n",
       "   'author': '',\n",
       "   'subject': '',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'trapped': '/False',\n",
       "   'creationdate': '2024-04-10T21:11:43+00:00',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf',\n",
       "   'doc_index': 12,\n",
       "   'page_label': '3',\n",
       "   'moddate': '2024-04-10T21:11:43+00:00',\n",
       "   'title': '',\n",
       "   'file_type': 'pdf',\n",
       "   'keywords': '',\n",
       "   'producer': 'pdfTeX-1.40.25',\n",
       "   'page': 2,\n",
       "   'source_file': 'attention-is-all-you-need.pdf'},\n",
       "  'similarity_score': 0.13995462656021118,\n",
       "  'distance': 0.8600453734397888,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_edcbacf0_12',\n",
       "  'content': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3',\n",
       "  'metadata': {'author': '',\n",
       "   'creationdate': '2024-04-10T21:11:43+00:00',\n",
       "   'moddate': '2024-04-10T21:11:43+00:00',\n",
       "   'source_file': 'attention-is-all-you-need.pdf',\n",
       "   'file_type': 'pdf',\n",
       "   'keywords': '',\n",
       "   'page': 2,\n",
       "   'page_label': '3',\n",
       "   'total_pages': 15,\n",
       "   'trapped': '/False',\n",
       "   'doc_index': 12,\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'title': '',\n",
       "   'producer': 'pdfTeX-1.40.25',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf',\n",
       "   'subject': '',\n",
       "   'content_length': 216},\n",
       "  'similarity_score': 0.13995462656021118,\n",
       "  'distance': 0.8600453734397888,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_d5503e2c_77',\n",
       "  'content': 'We are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/',\n",
       "  'metadata': {'trapped': '/False',\n",
       "   'moddate': '2024-04-10T21:11:43+00:00',\n",
       "   'file_type': 'pdf',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'creationdate': '2024-04-10T21:11:43+00:00',\n",
       "   'total_pages': 15,\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf',\n",
       "   'subject': '',\n",
       "   'producer': 'pdfTeX-1.40.25',\n",
       "   'title': '',\n",
       "   'doc_index': 77,\n",
       "   'source_file': 'attention-is-all-you-need.pdf',\n",
       "   'content_length': 489,\n",
       "   'author': '',\n",
       "   'keywords': '',\n",
       "   'page_label': '10',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       "   'page': 9},\n",
       "  'similarity_score': 0.011137723922729492,\n",
       "  'distance': 0.9888622760772705,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_d425e0cd_77',\n",
       "  'content': 'We are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/',\n",
       "  'metadata': {'producer': 'pdfTeX-1.40.25',\n",
       "   'title': '',\n",
       "   'trapped': '/False',\n",
       "   'source_file': 'attention-is-all-you-need.pdf',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf',\n",
       "   'total_pages': 15,\n",
       "   'content_length': 489,\n",
       "   'creationdate': '2024-04-10T21:11:43+00:00',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'file_type': 'pdf',\n",
       "   'page_label': '10',\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       "   'moddate': '2024-04-10T21:11:43+00:00',\n",
       "   'author': '',\n",
       "   'keywords': '',\n",
       "   'page': 9,\n",
       "   'subject': '',\n",
       "   'doc_index': 77},\n",
       "  'similarity_score': 0.011137723922729492,\n",
       "  'distance': 0.9888622760772705,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_9c862db0_87',\n",
       "  'content': '[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V . Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-',\n",
       "  'metadata': {'file_type': 'pdf',\n",
       "   'subject': '',\n",
       "   'page': 10,\n",
       "   'creationdate': '2024-04-10T21:11:43+00:00',\n",
       "   'trapped': '/False',\n",
       "   'total_pages': 15,\n",
       "   'doc_index': 87,\n",
       "   'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       "   'source_file': 'attention-is-all-you-need.pdf',\n",
       "   'title': '',\n",
       "   'moddate': '2024-04-10T21:11:43+00:00',\n",
       "   'content_length': 458,\n",
       "   'page_label': '11',\n",
       "   'author': '',\n",
       "   'keywords': '',\n",
       "   'producer': 'pdfTeX-1.40.25',\n",
       "   'creator': 'LaTeX with hyperref',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need.pdf'},\n",
       "  'similarity_score': 0.010438323020935059,\n",
       "  'distance': 0.9895616769790649,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"What is attention is all you need\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56213d6",
   "metadata": {},
   "source": [
    "### Integrating VectorDB Context pipeline with LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880068f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple RAG pipeline with Groq LM\n",
    "\n",
    "from  langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "### Initialize the Groq LLM (setting API Key in environment)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key, model_name=\"openai/gpt-oss-120b\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "## 2. Simple RAG funciton: retrieve context + generate response\n",
    "def rag_simple (query, retriever, llm, top_k=3):\n",
    "    ## retriever the context\n",
    "    results=retriever.retrieve(query, top_k=top_k)\n",
    "    context=\"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question concisely.\"\n",
    "    \n",
    "    ## generate the answer using GROQ LLM\n",
    "    prompt=f\"\"\"Use the following contenxt to answer the question concisely\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "    \n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f1d97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is attention mechanism?'\n",
      "Top K: 3, Score threshold: 0.0\n",
      "Generating embedding for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 35.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attention mechanism is a function that, given a **query** vector and a set of **key‑value** vector pairs, computes an output vector as a weighted sum of the values. The weights are determined by how similar (or relevant) each key is to the query, allowing the model to focus on the most pertinent information—often across long distances in the input sequence.\n"
     ]
    }
   ],
   "source": [
    "answer=rag_simple(\"What is attention mechanism?\",rag_retriever,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659e927",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bbf27e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is attention is all you need'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embedding for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 43.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: “**Attention Is All You Need**” is the 2017 paper that introduced the Transformer architecture. It showed that a model built solely on self‑attention mechanisms—without recurrent or convolutional layers—can achieve state‑of‑the‑art performance on tasks like machine translation, establishing attention as the primary building block for modern NLP models.\n",
      "Sources: [{'source': 'attention-is-all-you-need.pdf', 'page': 2, 'score': 0.13995462656021118, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3...'}, {'source': 'attention-is-all-you-need.pdf', 'page': 2, 'score': 0.13995462656021118, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3...'}]\n",
      "Confidence: 0.13995462656021118\n",
      "Context Preview: 3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set \n"
     ]
    }
   ],
   "source": [
    "# --- Enhanced RAG Pipeline Features ---\n",
    "def rag_advanced(query, retriever, llm, top_k=5, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "    results = retriever.retrieve(query, top_k=top_k, score_threshold=min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources': [], 'confidence': 0.0, 'context': ''}\n",
    "    \n",
    "    # Prepare context and sources\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page', 'unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300] + '...'\n",
    "    } for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = context\n",
    "    return output\n",
    "\n",
    "# Example usage:\n",
    "result = rag_advanced(\"what is attention is all you need\", rag_retriever, llm, top_k=3, min_score=0.1, return_context=True)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])\n",
    "print(\"Confidence:\", result['confidence'])\n",
    "print(\"Context Preview:\", result['context'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d34af0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is attention is all you need'\n",
      "Top K: 3, Score threshold: 0.1\n",
      "Generating embedding for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 2 documents (after filtering)\n",
      "Streaming answer:\n",
      "Use the following context to answer the question concisely.\n",
      "Context:\n",
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "3.2 Attention\n",
      "An attention functi"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "Question: what is attention is all you need\n",
      "\n",
      "Answer:\n",
      "\n",
      "Final Answer: “Attention Is All You Need” is the 2017 paper that introduced the Transformer model—a neural architecture that replaces recurrence and convolution with solely attention mechanisms, using self‑attention to capture relationships between all tokens in a sequence.\n",
      "\n",
      "Citations:\n",
      "[1] attention-is-all-you-need.pdf (page 2)\n",
      "[2] attention-is-all-you-need.pdf (page 2)\n",
      "Summary: The 2017 paper “Attention Is All You Need” introduced the Transformer model, which relies exclusively on attention mechanisms instead of recurrence or convolution. It uses self‑attention to directly capture relationships among all tokens in a sequence.\n",
      "History: {'question': 'what is attention is all you need', 'answer': '“Attention\\u202fIs\\u202fAll\\u202fYou\\u202fNeed” is the 2017 paper that introduced the Transformer model—a neural architecture that replaces recurrence and convolution with solely attention mechanisms, using self‑attention to capture relationships between all tokens in a sequence.', 'sources': [{'source': 'attention-is-all-you-need.pdf', 'page': 2, 'score': 0.13995462656021118, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}, {'source': 'attention-is-all-you-need.pdf', 'page': 2, 'score': 0.13995462656021118, 'preview': '3.2 Attention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere...'}], 'summary': 'The 2017 paper “Attention\\u202fIs\\u202fAll\\u202fYou\\u202fNeed” introduced the Transformer model, which relies exclusively on attention mechanisms instead of recurrence or convolution. It uses self‑attention to directly capture relationships among all tokens in a sequence.'}\n"
     ]
    }
   ],
   "source": [
    "# --- Advanced RAG Pipeline: Streaming, Citations, History, Summarization ---\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "\n",
    "class AdvancedRAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "        self.history = []  # Store query history\n",
    "\n",
    "    def query(self, question: str, top_k: int = 5, min_score: float = 0.2, stream: bool = False, summarize: bool = False) -> Dict[str, Any]:\n",
    "        # Retrieve relevant documents\n",
    "        results = self.retriever.retrieve(question, top_k=top_k, score_threshold=min_score)\n",
    "        if not results:\n",
    "            answer = \"No relevant context found.\"\n",
    "            sources = []\n",
    "            context = \"\"\n",
    "        else:\n",
    "            context = \"\\n\\n\".join([doc['content'] for doc in results])\n",
    "            sources = [{\n",
    "                'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "                'page': doc['metadata'].get('page', 'unknown'),\n",
    "                'score': doc['similarity_score'],\n",
    "                'preview': doc['content'][:120] + '...'\n",
    "            } for doc in results]\n",
    "            # Streaming answer simulation\n",
    "            prompt = f\"\"\"Use the following context to answer the question concisely.\\nContext:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "            if stream:\n",
    "                print(\"Streaming answer:\")\n",
    "                for i in range(0, len(prompt), 80):\n",
    "                    print(prompt[i:i+80], end='', flush=True)\n",
    "                    time.sleep(0.05)\n",
    "                print()\n",
    "            response = self.llm.invoke([prompt.format(context=context, question=question)])\n",
    "            answer = response.content\n",
    "\n",
    "        # Add citations to answer\n",
    "        citations = [f\"[{i+1}] {src['source']} (page {src['page']})\" for i, src in enumerate(sources)]\n",
    "        answer_with_citations = answer + \"\\n\\nCitations:\\n\" + \"\\n\".join(citations) if citations else answer\n",
    "\n",
    "        # Optionally summarize answer\n",
    "        summary = None\n",
    "        if summarize and answer:\n",
    "            summary_prompt = f\"Summarize the following answer in 2 sentences:\\n{answer}\"\n",
    "            summary_resp = self.llm.invoke([summary_prompt])\n",
    "            summary = summary_resp.content\n",
    "\n",
    "        # Store query history\n",
    "        self.history.append({\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'sources': sources,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "        return {\n",
    "            'question': question,\n",
    "            'answer': answer_with_citations,\n",
    "            'sources': sources,\n",
    "            'summary': summary,\n",
    "            'history': self.history\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "adv_rag = AdvancedRAGPipeline(rag_retriever, llm)\n",
    "result = adv_rag.query(\"what is attention is all you need\", top_k=3, min_score=0.1, stream=True, summarize=True)\n",
    "print(\"\\nFinal Answer:\", result['answer'])\n",
    "print(\"Summary:\", result['summary'])\n",
    "print(\"History:\", result['history'][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
